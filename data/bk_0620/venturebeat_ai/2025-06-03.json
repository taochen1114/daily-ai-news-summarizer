[
  {
    "id": "169bac1c3dc36a4ef8c83f594fc53147",
    "title": "How S&P is using deep web scraping, ensemble learning and Snowflake architecture to collect 5X more data on SMEs",
    "url": "https://venturebeat.com/data-infrastructure/how-sp-is-using-deep-web-scraping-ensemble-learning-and-snowflake-architecture-to-collect-5x-more-data-on-smes/",
    "authors": "Taryn Plumb",
    "published_date": "2025-06-02T21:45:06+00:00",
    "source": "VentureBeat AI",
    "summary": "S&P利用深度網頁爬蟲、集成學習和Snowflake架構，收集中小企業（SMEs）5倍的數據量。他們開發了RiskGauge平台，從超過2億個網站中提取數據，經過多種演算法處理後生成風險評分，大幅提升對SMEs的覆蓋率。這項技術改善了數據的準確性和覆蓋範圍，有助於機構投資者、銀行等對企業信用評估。",
    "content": "How S&P is using deep web scraping, ensemble learning and Snowflake architecture to collect 5X more data on SMEs | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nHow S&P is using deep web scraping, ensemble learning and Snowflake architecture to collect 5X more data on SMEs\nTaryn Plumb\n@taryn_plumb\nJune 2, 2025 2:45 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nVentureBeat/Ideogram\nJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage.\nLearn More\nThe investing world has a significant problem when it comes to data about small and medium-sized enterprises (SMEs). This has nothing to do with data quality or accuracy — it’s the lack of any data at all.\nAssessing SME creditworthiness has been notoriously challenging because small enterprise financial data is not public, and therefore very difficult to access.\nS&P Global Market Intelligence\n, a division of S&P Global and a foremost provider of credit ratings and benchmarks, claims to have solved this longstanding problem. The company’s technical team built\nRiskGauge\n, an AI-powered platform that crawls otherwise elusive data from over 200 million websites, processes it through numerous algorithms and generates risk scores.\nBuilt on Snowflake architecture, the platform has increased S&P’s coverage of SMEs by 5X.\n“Our objective was expansion and efficiency,” explained Moody Hadi, S&P Global’s head of risk solutions’ new product development. “The project has improved the accuracy and coverage of the data, benefiting clients.”\nRiskGauge’s underlying architecture\nCounterparty credit management essentially assesses a company’s creditworthiness and risk based on several factors, including financials, probability of default and risk appetite. S&P Global Market Intelligence provides these insights to institutional investors, banks, insurance companies, wealth managers and others.\n“Large and financial corporate entities lend to suppliers, but they need to know how much to lend, how frequently to monitor them, what the duration of the loan would be,” Hadi explained. “They rely on third parties to come up with a trustworthy credit score.”\nBut there has long been a gap in SME coverage. Hadi pointed out that, while large public companies like IBM, Microsoft, Amazon, Google and the rest are required to disclose their quarterly financials, SMEs don’t have that obligation, thus limiting financial transparency. From an investor perspective, consider that there are about 10 million SMEs in the U.S., compared to roughly 60,000 public companies.\nS&P Global Market Intelligence claims it now has all of those covered: Previously, the firm only had data on about 2 million, but RiskGauge expanded that to 10 million.\nThe platform, which went into production in January, is based on a system built by Hadi’s team that pulls firmographic data from unstructured web content, combines it with anonymized third-party datasets, and applies machine learning (ML) and\nadvanced algorithms\nto generate credit scores.\nThe company uses\nSnowflake\nto mine company pages and process them into firmographics drivers (market segmenters) that are then fed into RiskGauge.\nThe platform’s data pipeline consists of:\nCrawlers/web scrapers\nA pre-processing layer\nMiners\nCurators\nRiskGauge scoring\nSpecifically, Hadi’s team uses Snowflake’s data warehouse and Snowpark Container Services in the middle of the pre-processing, mining and curation steps.\nAt the end of this process, SMEs are scored based on a combination of financial, business and market risk; 1 being the highest, 100 the lowest. Investors also receive reports on RiskGauge detailing financials, firmographics, business credit reports, historical performance and key developments. They can also compare companies to their peers.\nHow S&P is collecting valuable company data\nHadi explained that RiskGauge employs a multi-layer scraping process that pulls various details from a company’s web domain, such as basic ‘contact us’ and landing pages and news-related information. The miners go down several URL layers to scrape relevant data.\n“As you can imagine, a person can’t do this,” said Hadi. “It is going to be very time-consuming for a human, especially when you’re dealing with 200 million web pages.” Which, he noted, results in several terabytes of website information.\nAfter data is collected, the next step is to run algorithms that remove anything that isn’t text; Hadi noted that the system is not interested in JavaScript or even HTML tags. Data is cleaned so it becomes human-readable, not code. Then, it’s loaded into\nSnowflake\nand several data miners are run against the pages.\nEnsemble algorithms are critical to the prediction process; these types of algorithms combine predictions from several individual models (base models or ‘weak learners’ that are essentially a little better than random guessing) to validate company information such as name, business description, sector, location, and operational activity. The system also factors in any polarity in sentiment around announcements disclosed on the site.\n“After we crawl a site, the algorithms hit different components of the pages pulled, and they vote and come back with a recommendation,” Hadi explained. “There is no human in the loop in this process, the algorithms are basically competing with each other. That helps with the efficiency to increase our coverage.”\nFollowing that initial load, the system monitors site activity, automatically running weekly scans. It doesn’t update information weekly; only when it detects a change, Hadi added. When performing subsequent scans, a hash key tracks the landing page from the previous crawl, and the system generates another key; if they are identical, no changes were made, and no action is required. However, if the hash keys don’t match, the system will be triggered to update company information.\nThis continuous scraping is important to ensure the system remains as up-to-date as possible. “If they’re updating the site often, that tells us they’re alive, right?,” Hadi noted.\nChallenges with processing speed, giant datasets, unclean websites\nThere were challenges to overcome when building out the system, of course, particularly due to the sheer size of datasets and the need for quick processing. Hadi’s team had to make trade-offs to balance accuracy and speed.\n“We kept optimizing different algorithms to run faster,” he explained. “And tweaking; some algorithms we had were really good, had high accuracy, high precision, high recall, but they were computationally too costly.”\nWebsites do not always conform to standard formats, requiring flexible scraping methods.\n“You hear a lot about designing websites with an exercise like this, because when we originally started, we thought, ‘Hey, every website should conform to a sitemap or XML,’” said Hadi. “And guess what? Nobody follows that.”\nThey didn’t want to hard code or incorporate robotic process automation (RPA) into the system because sites vary so widely, Hadi said, and they knew the most important information they needed was in the text. This led to the creation of a system that only pulls necessary components of a site, then cleanses it for the actual text and discards code and any JavaScript or TypeScript.\nAs Hadi noted, “the biggest challenges were around performance and tuning and the fact that websites by design are not clean.”\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nWhere Enterprise AI Gets Real — Join Us at VB Transform 2025\nJoin top leaders in San Francisco from June 24–25 to solve real challenges, share proven strategies, and shape the future of AI at VB Transform 2025.\nLearn More\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe insights you need without the noise\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-03T08:20:54.787284",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-03T08:21:04.762580",
    "audio_file": "169bac1c3dc36a4ef8c83f594fc53147.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/169bac1c3dc36a4ef8c83f594fc53147.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-06-03T08:21:13.440281"
  },
  {
    "id": "a9643b0c034a46e6613bd55cb21e3b0c",
    "title": "Google quietly launches AI Edge Gallery, letting Android phones run AI without the cloud",
    "url": "https://venturebeat.com/ai/google-quietly-launches-ai-edge-gallery-letting-android-phones-run-ai-without-the-cloud/",
    "authors": "Michael Nuñez",
    "published_date": "2025-06-02T20:46:25+00:00",
    "source": "VentureBeat AI",
    "summary": "Google推出了一個新應用程式叫做AI Edge Gallery，讓Android手機可以在沒有網路的情況下運行人工智慧模型。這個應用程式讓使用者可以在手機上執行複雜的AI任務，像是圖像分析、文字生成等，而且所有資料處理都在本地進行，不需要連網。這代表Google在推動邊緣運算和注重隱私的AI部署方面邁出了重要一步。這個應用程式是開源的，可以從GitHub下載，讓更多人可以使用先進的AI功能，同時解決了人們對基於雲端的AI服務日益增長的隱私擔憂。",
    "content": "Google quietly launches AI Edge Gallery, letting Android phones run AI without the cloud | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nGoogle quietly launches AI Edge Gallery, letting Android phones run AI without the cloud\nMichael Nuñez\n@MichaelFNunez\nJune 2, 2025 1:46 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCredit: VentureBeat made with Midjourney\nJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage.\nLearn More\nGoogle\nhas quietly released an\nexperimental Android application\nthat enables users to run sophisticated artificial intelligence models directly on their smartphones without requiring an internet connection, marking a significant step in the company’s push toward edge computing and privacy-focused AI deployment.\nThe app, called\nAI Edge Gallery\n, allows users to download and execute AI models from the popular Hugging Face platform entirely on their devices, enabling tasks such as image analysis, text generation, coding assistance, and multi-turn conversations while keeping all data processing local.\nThe application, released under an open-source\nApache 2.0 license\nand available through GitHub rather than official app stores, represents Google’s latest effort to democratize access to advanced AI capabilities while addressing growing privacy concerns about cloud-based artificial intelligence services.\n“The Google AI Edge Gallery is an experimental app that puts the power of cutting-edge Generative AI models directly into your hands, running entirely on your Android devices,” Google explains in the app’s\nuser guide\n. “Dive into a world of creative and practical AI use cases, all running locally, without needing an internet connection once the model is loaded.”\nGoogle’s AI Edge Gallery app shows the main interface, model selection from Hugging Face, and configuration options for processing acceleration. (Credit: Google)\nHow Google’s lightweight AI models deliver cloud-level performance on mobile devices\nThe application builds on\nGoogle’s LiteRT platform\n, formerly known as\nTensorFlow Lite\n, and\nMediaPipe frameworks\n, which are specifically optimized for running AI models on resource-constrained mobile devices. The system supports models from multiple machine learning frameworks, including\nJAX\n,\nKeras\n,\nPyTorch\n, and\nTensorFlow\n.\nAt the heart of the offering is Google’s\nGemma 3 model\n, a compact 529-megabyte language model that can process up to 2,585 tokens per second during prefill inference on mobile GPUs. This performance enables sub-second response times for tasks like text generation and image analysis, making the experience comparable to cloud-based alternatives.\nThe app includes three core capabilities: AI Chat for multi-turn conversations, Ask Image for visual question-answering, and Prompt Lab for single-turn tasks such as text summarization, code generation, and content rewriting. Users can switch between different models to compare performance and capabilities, with real-time benchmarks showing metrics like time-to-first-token and decode speed.\n“Int4 quantization cuts model size by up to 4x over bf16, reducing memory use and latency,” Google noted in\ntechnical documentation\n, referring to optimization techniques that make larger models feasible on mobile hardware.\nThe AI Chat feature provides detailed responses and displays real-time performance metrics including token speed and latency. (Credit: Google)\nWhy on-device AI processing could revolutionize data privacy and enterprise security\nThe local processing approach addresses growing concerns about data privacy in AI applications, particularly in industries handling sensitive information. By keeping data on-device, organizations can maintain compliance with privacy regulations while leveraging AI capabilities.\nThis shift represents a fundamental reimagining of the AI privacy equation. Rather than treating privacy as a constraint that limits AI capabilities, on-device processing transforms privacy into a competitive advantage. Organizations no longer need to choose between powerful AI and data protection — they can have both. The elimination of network dependencies also means that intermittent connectivity, traditionally a major limitation for AI applications, becomes irrelevant for core functionality.\nThe approach is particularly valuable for sectors like healthcare and finance, where data sensitivity requirements often limit cloud AI adoption. Field applications such as equipment diagnostics and remote work scenarios also benefit from the offline capabilities.\nHowever, the shift to on-device processing introduces new security considerations that organizations must address. While the data itself becomes more secure by never leaving the device, the focus shifts to protecting the devices themselves and the AI models they contain. This creates new attack vectors and requires different security strategies than traditional cloud-based AI deployments. Organizations must now consider device fleet management, model integrity verification, and protection against adversarial attacks that could compromise local AI systems.\nGoogle’s platform strategy takes aim at Apple and Qualcomm’s mobile AI dominance\nGoogle’s move comes amid intensifying competition in the mobile AI space. Apple’s\nNeural Engine\n, embedded across iPhones, iPads, and Macs, already powers real-time language processing and computational photography on-device. Qualcomm’s\nAI Engine\n, built into Snapdragon chips, drives voice recognition and smart assistants in Android smartphones, while Samsung uses embedded\nneural processing units\nin Galaxy devices.\nHowever, Google’s approach differs significantly from competitors by focusing on platform infrastructure rather than proprietary features. Rather than competing directly on specific AI capabilities, Google is positioning itself as the foundation layer that enables all mobile AI applications. This strategy echoes successful platform plays from technology history, where controlling the infrastructure proves more valuable than controlling individual applications.\nThe timing of this platform strategy is particularly shrewd. As mobile AI capabilities become commoditized, the real value shifts to whoever can provide the tools, frameworks, and distribution mechanisms that developers need. By open-sourcing the technology and making it widely available, Google ensures broad adoption while maintaining control over the underlying infrastructure that powers the entire ecosystem.\nWhat early testing reveals about mobile AI’s current challenges and limitations\nThe application currently faces several limitations that underscore its experimental nature. Performance varies significantly based on device hardware, with high-end devices like the\nPixel 8 Pro\nhandling larger models smoothly while mid-tier devices may experience higher latency.\nTesting revealed accuracy issues with some tasks. The app occasionally provided incorrect responses to specific questions, such as incorrectly identifying crew counts for fictional spacecraft or misidentifying comic book covers. Google acknowledges these limitations, with the AI itself stating during testing that it was “still under development and still learning.”\nInstallation remains cumbersome, requiring users to enable developer mode on Android devices and manually install the application via\nAPK files\n. Users must also create Hugging Face accounts to\ndownload models\n, adding friction to the onboarding process.\nThe hardware constraints highlight a fundamental challenge facing mobile AI: the tension between model sophistication and device limitations. Unlike cloud environments where computational resources can be scaled almost infinitely, mobile devices must balance AI performance against battery life, thermal management, and memory constraints. This forces developers to become experts in efficiency optimization rather than simply leveraging raw computational power.\nThe Ask Image tool analyzes uploaded photos, solving math problems and calculating restaurant receipts. (Credit: Google)\nThe quiet revolution that could reshape AI’s future lies in your pocket\nGoogle’s\nEdge AI Gallery\nmarks more than just another experimental app release. The company has fired the opening shot in what could become the biggest shift in artificial intelligence since cloud computing emerged two decades ago. While tech giants spent years constructing massive data centers to power AI services, Google now bets the future belongs to the billions of smartphones people already carry.\nThe move goes beyond technical innovation. Google wants to fundamentally change how users relate to their personal data. Privacy breaches dominate headlines weekly, and regulators worldwide crack down on data collection practices. Google’s shift toward local processing offers companies and consumers a clear alternative to the surveillance-based business model that has powered the internet for years.\nGoogle timed this strategy carefully. Companies struggle with AI governance rules while consumers grow increasingly wary about data privacy. Google positions itself as the foundation for a more distributed AI system rather than competing head-to-head with Apple’s tightly integrated hardware or Qualcomm’s specialized chips. The company builds the infrastructure layer that could run the next wave of AI applications across all devices.\nCurrent problems with the app — difficult installation, occasional wrong answers, and varying performance across devices — will likely disappear as Google refines the technology. The bigger question is whether Google can manage this transition while keeping its dominant position in the AI market.\nThe\nEdge AI Gallery\nreveals Google’s recognition that the centralized AI model it helped build may not last. Google open-sources its tools and makes on-device AI widely available because it believes controlling tomorrow’s AI infrastructure matters more than owning today’s data centers. If the strategy works, every smartphone becomes part of Google’s distributed AI network. That possibility makes this quiet app launch far more important than its experimental label suggests.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nWhere Enterprise AI Gets Real — Join Us at VB Transform 2025\nJoin top leaders in San Francisco from June 24–25 to solve real challenges, share proven strategies, and shape the future of AI at VB Transform 2025.\nLearn More\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-03T08:20:55.010946",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-03T08:21:07.330550",
    "audio_file": "a9643b0c034a46e6613bd55cb21e3b0c.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/a9643b0c034a46e6613bd55cb21e3b0c.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-06-03T08:21:14.694195"
  },
  {
    "id": "b4572ba1e917c15abf59209ae3a92425",
    "title": "OpenAI’s Sora is now available for FREE to all users through Microsoft Bing Video Creator on mobile",
    "url": "https://venturebeat.com/ai/openais-sora-is-now-available-for-free-to-all-users-through-microsoft-bing-video-creator-on-mobile/",
    "authors": "Carl Franzen",
    "published_date": "2025-06-02T19:01:21+00:00",
    "source": "VentureBeat AI",
    "summary": "OpenAI的Sora現在透過微軟Bing影片創作者功能免費提供給所有使用者。Sora是一款AI影片生成工具，之前受到矚目，但近期其他競爭對手也推出類似產品。現在透過Bing影片創作者可以免費使用Sora，而其他途徑需要付費訂閱。這是微軟為用戶提供的最新AI服務之一，讓更多人可以體驗到AI影片生成的樂趣。",
    "content": "OpenAI's Sora is now available for FREE to all users through Microsoft Bing Video Creator on mobile | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nOpenAI’s Sora is now available for FREE to all users through Microsoft Bing Video Creator on mobile\nCarl Franzen\n@carlfranzen\nJune 2, 2025 12:01 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nJoin our daily and weekly newsletters for the latest updates and exclusive content on industry-leading AI coverage.\nLearn More\nOpenAI\n‘s Sora was one of the most hyped releases of the AI era,\nlaunching in December 2024\n, nearly 10 months after it was first\npreviewed to awe-struck reactions\ndue to its — at the time, at least — unprecedented level of realism, camera dynamism, and prompt adherence and 60-second long generation clips.\nHowever, much of the luster has worn off as numerous other AI video generators — from U.S. startups\nRunway\nto\nLuma\nto Chinese competitors\nKling\n,\nHailuo MiniMax\nand\nIsrael’s LTX Studio\n— are all offering generative AI video models and applications for consumers and enterprise users that rival or have already surpassed OpenAI’s offering. Also, we still haven’t gotten 60-second generations from a single Sora prompt (as far as I know, the maximum appears to be 20 seconds).\nBut now OpenAI and its ally/investor/frenemy\nMicrosoft\nare seeking to bring Sora to far more users — for free (at least for a few generations). Today,\nMicrosoft announced that Sora is now being offered through its Bing Video Creator\nfeature on the free Bing mobile app for iOS (Apple iPhone and App Store) and Android (Google Play Store).\nThat’s an incredible value, given that to get it through ChatGPT and OpenAI, you’ll need to pay for a ChatGPT Plus ($20 monthly) or Pro ($200 monthly) subscription.\nBing Video Creator with Sora is the latest in a series of AI-driven offerings from Microsoft, following the release of Bing Image Creator and Copilot.\nAs Microsoft Corporate Vice President (CVP) and Head of Search\nJordi Ribas wrote on X\n: “Two years ago, Bing was the first product to ship image creation for free for our users. Today, I’m excited to share that Bing Video Creator is now available in the Bing mobile app, everywhere that Bing Image Creator is available worldwide. Powered by Sora, Bing Video Creator transforms your text prompts into short videos. Just describe what you want to see and watch your vision come to life.”\nTo introduce Bing Video Creator, Microsoft has released a promotional video ad (embedded above) that showcases how the tool brings creative ideas to life.\nThe ad demonstrates users typing prompts like “Create a hummingbird flapping its wings in ultra slow motion,” “A turtle drifting slowly through a neon coral canyon,” and “A tiny astronaut exploring a giant mushroom planet.” The AI then generates short, vibrant video clips based on these prompts.\nThe video emphasizes how easy it is to create and share these videos, including an example of the astronaut video being shared in a chat and receiving positive reactions.\nFree 5-second vertical video creations on mobile — with horizontal videos coming soon\nBing Video Creator turns text prompts into five-second AI-generated videos. It does not yet support text-to-video or video-to-video generations (which many other rival AI video generators, including OpenAI’s implementation of Sora, do).\nTo use the tool, users can open the Bing Mobile app, tap the menu in the bottom right corner, and select “Video Creator.”\nAlternatively, you can launch the video creation process by typing a prompt directly into the Bing search bar in the app—beginning with “Create a video of…”\nOnce the prompt is entered, Bing Video Creator generates a short video based on the description.\nFor example, a prompt like “In a busy Italian pizza restaurant, a small otter works as a chef and wears a chef’s hat and an apron. He kneads the dough with his paws and is surrounded by other pizza ingredients” would result in an engaging, AI-generated five-second video.\nCurrently, videos are available in 9:16 portrait format — that is, vertical, perfect for TikTok and YouTube Shorts — though\nMicrosoft says it in its announcement blog post\nthat a 16:9 aka landscape or horizontal aspect ratio option is “coming soon.”\nUsers can queue up to three video generations at a time, and each creation is stored for up to 90 days. Once a video is ready, it can be downloaded, shared via email or social media, or accessed through a direct link.\nBing Video Creator will be available worldwide today, except for China and Russia. It’s available now on the Bing Mobile app, and desktop and Copilot Search are also said to be launching “soon.”\nFree to use for 10 fast generations, unlimited slow generations\nBing Video Creator is free for all users.\nEach user is allowed ten “Fast” video generations, which can create videos in seconds.\nAfter using these, users can continue with Standard speed generations — which takes minutes — at no cost, or redeem 100 Microsoft Rewards points for each additional Fast creation.\nThose reward points come from Microsoft’s free, opt-in program that allows users to earn points for everyday activities — like searching with Bing, shopping in the Microsoft Store, or playing games with Xbox Game Pass.\nTo participate, users must sign in with a Microsoft account and activate their\nRewards dashboard here\n.\nBeyond fun videos and social media posts, Bing Video Creator is positioned as a tool for enhancing everyday communication and creativity. Bing’s announcement encourages users to create videos to celebrate special moments, test creative ideas, and communicate more effectively.\nTo help users get the best results, Bing suggests providing descriptive prompts, incorporating action-oriented language and experimenting with tone and style—such as cinematic or playful aesthetics.\nResponsible AI and safety, built-in\nMicrosoft says that Bing Video Creator is designed according to its Responsible AI principles, leveraging C2PA standards for content credentials to help identify AI-generated content.\nThe tool also includes moderation features that automatically block prompts that could generate harmful or unsafe videos.\nImplications for enterprises and technical decision-makers\nAlthough Bing Video Creator is currently framed as a consumer-focused tool, its underlying technology and capabilities could have interesting implications for enterprise users — particularly those involved in AI orchestration, data engineering and AI model deployment.\nFor AI engineers responsible for deploying and fine-tuning large language models, Bing Video Creator highlights the growing maturity of generative AI video beyond text-based models. While not an enterprise product itself, the technology behind it could inspire new ways to incorporate video generation into business workflows, such as creating automated video summaries, training content, or marketing materials.\nFor professionals orchestrating scalable AI pipelines, Bing Video Creator showcases a practical application of generative video that could influence how enterprises think about deploying these models at scale. The tool’s ease of use and rapid responsiveness suggest potential future applications within enterprise workflows, whether for internal training, creative ideation, or customer engagement.\nData engineers might see Bing Video Creator’s simplicity and shareability as a demonstration of how AI can make complex data-driven insights more accessible. While these consumer-grade videos are brief and visually focused, similar technology could be adapted in the future to turn complex datasets or project outcomes into short, engaging video narratives that resonate with non-technical audiences.\nBing Video Creator is part of Bing’s ongoing push to democratize AI creativity. While there’s no word yet on features beyond landscape video support, Bing says it will continue refining and expanding the experience as more users begin exploring video generation.\nFor those ready to try it, Bing invites users to download the Bing Mobile app and begin creating videos today.\nTo learn more about Bing Video Creator and how to start earning Microsoft Rewards points for even faster video creation,\nvisit here\n.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nWhere Enterprise AI Gets Real — Join Us at VB Transform 2025\nJoin top leaders in San Francisco from June 24–25 to solve real challenges, share proven strategies, and shape the future of AI at VB Transform 2025.\nLearn More\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-03T08:20:55.234821",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-03T08:21:08.808211",
    "audio_file": "b4572ba1e917c15abf59209ae3a92425.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/b4572ba1e917c15abf59209ae3a92425.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-06-03T08:21:16.454650"
  }
]