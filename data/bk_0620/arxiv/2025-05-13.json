[
  {
    "id": "2505.05541",
    "title": "Safety by Measurement: A Systematic Literature Review of AI Safety Evaluation Methods",
    "url": "https://arxiv.org/abs/2505.05541",
    "authors": "Markov Grey, Charbel-Rapha\\\"el Segerie",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.05541v1 Announce Type: new  Abstract: As frontier AI systems advance toward transformative capabilities, we need a parallel transformation in how we measure and evaluate these systems to ensure safety and inform governance. While benchmarks have been the primary method for estimating model capabilities, they often fail to establish true upper bounds or predict deployment behavior. This literature review consolidates the rapidly evolving field of AI safety evaluations, proposing a systematic taxonomy around three dimensions: what properties we measure, how we measure them, and how these measurements integrate into frameworks. We show how evaluations go beyond benchmarks by measuring what models can do when pushed to the limit (capabilities), the behavioral tendencies exhibited by default (propensities), and whether our safety measures remain effective even when faced with subversive adversarial AI (control). These properties are measured through behavioral techniques like scaffolding, red teaming and supervised fine-tuning, alongside internal techniques such as representation analysis and mechanistic interpretability. We provide deeper explanations of some safety-critical capabilities like cybersecurity exploitation, deception, autonomous replication, and situational awareness, alongside concerning propensities like power-seeking and scheming. The review explores how these evaluation methods integrate into governance frameworks to translate results into concrete development decisions. We also highlight challenges to safety evaluations - proving absence of capabilities, potential model sandbagging, and incentives for \"safetywashing\" - while identifying promising research directions. By synthesizing scattered resources, this literature review aims to provide a central reference point for understanding AI safety evaluations.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797164",
    "summary": "這篇論文主要探討如何評估人工智慧系統的安全性，提出了一個新的方法論，強調不僅要測試模型的能力，還要考慮其行為傾向和對抗敵對AI的能力。通過各種行為技術和內部技術來評估模型的安全性，並探討這些評估方法如何應用於治理框架中，以做出具體的發展決策。同時指出了安全評估面臨的挑戰，並提出了未來研究方向。這篇文獻回顧旨在成為理解AI安全評估的重要參考來源。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:12.213815",
    "audio_file": "2505.05541.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.05541.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:44.053402"
  },
  {
    "id": "2505.05602",
    "title": "HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics",
    "url": "https://arxiv.org/abs/2505.05602",
    "authors": "Lennart Luettgau, Harry Coppock, Magda Dubois, Christopher Summerfield, Cozmin Ududec",
    "categories": [
      "cs.AI",
      "stat.AP"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.05602v1 Announce Type: new  Abstract: As Large Language Models (LLMs) and other AI systems evolve, robustly estimating their capabilities from inherently stochastic outputs while systematically quantifying uncertainty in these estimates becomes increasingly important. Further, advanced AI evaluations often have a nested hierarchical structure, exhibit high levels of complexity, and come with high costs in testing the most advanced AI systems. To address these challenges, we introduce HiBayES, a generalizable Hierarchical Bayesian modeling framework for AI Evaluation Statistics. HiBayES supports robust inferences in classical question-answer benchmarks and advanced agentic evaluations, particularly in low-data scenarios (e.g., < 20 data points per evaluation). Built on Generalized Linear Models (GLMs), Bayesian data analysis, and formal model comparison, HiBayES provides principled uncertainty quantification and robust parameter estimation. This paper offers a comprehensive introduction to HiBayES, including illustrative examples, comparisons to conventional statistical methods, and practical guidance for implementing multilevel Bayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta version) for out-of-the-box implementation.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797193",
    "summary": "這篇論文介紹了一個名為HiBayES的新方法，可以幫助我們更準確地評估人工智慧系統的能力，尤其是在資料量較少的情況下。這個方法利用貝葉斯統計模型來分析人工智慧系統的表現，讓我們可以更有信心地了解評估結果的不確定性，同時有效估計參數。總結來說，HiBayES提供了一個全面的框架，可以應用在各種人工智慧評估情境下，有助於提升評估的準確性和可靠性。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:14.569517",
    "audio_file": "2505.05602.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.05602.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:45.344763"
  },
  {
    "id": "2505.05612",
    "title": "scDrugMap: Benchmarking Large Foundation Models for Drug Response Prediction",
    "url": "https://arxiv.org/abs/2505.05612",
    "authors": "Qing Wang, Yining Pan, Minghao Zhou, Zijia Tang, Yanfei Wang, Guangyu Wang, Qianqian Song",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.05612v1 Announce Type: new  Abstract: Drug resistance presents a major challenge in cancer therapy. Single cell profiling offers insights into cellular heterogeneity, yet the application of large-scale foundation models for predicting drug response in single cell data remains underexplored. To address this, we developed scDrugMap, an integrated framework featuring both a Python command-line interface and a web server for drug response prediction. scDrugMap evaluates a wide range of foundation models, including eight single-cell models and two large language models, using a curated dataset of over 326,000 cells in the primary collection and 18,800 cells in the validation set, spanning 36 datasets and diverse tissue and cancer types. We benchmarked model performance under pooled-data and cross-data evaluation settings, employing both layer freezing and Low-Rank Adaptation (LoRA) fine-tuning strategies. In the pooled-data scenario, scFoundation achieved the best performance, with mean F1 scores of 0.971 (layer freezing) and 0.947 (fine-tuning), outperforming the lowest-performing model by over 50%. In the cross-data setting, UCE excelled post fine-tuning (mean F1: 0.774), while scGPT led in zero-shot learning (mean F1: 0.858). Overall, scDrugMap provides the first large-scale benchmark of foundation models for drug response prediction in single-cell data and serves as a user-friendly, flexible platform for advancing drug discovery and translational research.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797215",
    "summary": "這篇論文主要介紹了一個名為scDrugMap的新工具，可以幫助預測癌症治療中藥物的反應。他們使用了各種模型，包括單細胞模型和大型語言模型，並在超過326,000個細胞的數據集上進行了評估。研究發現，在預測藥物反應時，某些模型表現優異，有助於提升藥物發現和轉譯研究。這個工具為單細胞數據中藥物反應預測提供了一個大規模的基準，對於推動藥物研發具有重要價值。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:17.367970",
    "audio_file": "2505.05612.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.05612.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:46.531313"
  },
  {
    "id": "2505.05616",
    "title": "Leveraging Large Language Models for enzymatic reaction prediction and characterization",
    "url": "https://arxiv.org/abs/2505.05616",
    "authors": "Lorenzo Di Fruscia, Jana Marie Weber",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.05616v1 Announce Type: new  Abstract: Predicting enzymatic reactions is crucial for applications in biocatalysis, metabolic engineering, and drug discovery, yet it remains a complex and resource-intensive task. Large Language Models (LLMs) have recently demonstrated remarkable success in various scientific domains, e.g., through their ability to generalize knowledge, reason over complex structures, and leverage in-context learning strategies. In this study, we systematically evaluate the capability of LLMs, particularly the Llama-3.1 family (8B and 70B), across three core biochemical tasks: Enzyme Commission number prediction, forward synthesis, and retrosynthesis. We compare single-task and multitask learning strategies, employing parameter-efficient fine-tuning via LoRA adapters. Additionally, we assess performance across different data regimes to explore their adaptability in low-data settings. Our results demonstrate that fine-tuned LLMs capture biochemical knowledge, with multitask learning enhancing forward- and retrosynthesis predictions by leveraging shared enzymatic information. We also identify key limitations, for example challenges in hierarchical EC classification schemes, highlighting areas for further improvement in LLM-driven biochemical modeling.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797234",
    "summary": "這篇研究利用大型語言模型在酶催化反應預測和特性描述上取得重要突破。研究者發現，透過訓練語言模型，可以有效預測酶的功能和化學反應，有助於生物催化、代謝工程和藥物開發等領域的應用。他們的研究結果顯示，這種方法不僅可以提高反應預測的準確性，還能夠在不同數據情況下適應良好。這項研究有助於未來改進基於語言模型的生物化學建模方法。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:19.722379",
    "audio_file": "2505.05616.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.05616.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:47.863245"
  },
  {
    "id": "2505.05684",
    "title": "Prompted Meta-Learning for Few-shot Knowledge Graph Completion",
    "url": "https://arxiv.org/abs/2505.05684",
    "authors": "Han Wu, Jie Yin",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.05684v1 Announce Type: new  Abstract: Few-shot knowledge graph completion (KGC) has obtained significant attention due to its practical applications in real-world scenarios, where new knowledge often emerges with limited available data. While most existing methods for few-shot KGC have predominantly focused on leveraging relational information, rich semantics inherent in KGs have been largely overlooked. To address this gap, we propose a novel prompted meta-learning (PromptMeta) framework that seamlessly integrates meta-semantics with relational information for few-shot KGC. PrompMeta has two key innovations: (1) a meta-semantic prompt pool that captures and consolidates high-level meta-semantics, enabling effective knowledge transfer and adaptation to rare and newly emerging relations. (2) a learnable fusion prompt that dynamically combines meta-semantic information with task-specific relational information tailored to different few-shot tasks. Both components are optimized together with model parameters within a meta-learning framework. Extensive experiments on two benchmark datasets demonstrate the effectiveness of our approach.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797253",
    "summary": "這篇論文提出了一個新的方法，名為「Prompted Meta-Learning for Few-shot Knowledge Graph Completion」，針對少量數據的知識圖譜完整性問題做出創新。他們結合了高層次的語義信息和關係信息，提出了一個「PromptMeta」框架，有效地處理罕見和新興關係，並在兩個基準數據集上進行了豐富的實驗，證明了這種方法的有效性。這個方法有助於更好地應對現實世界中知識不斷變化的挑戰。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:21.939179",
    "audio_file": "2505.05684.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.05684.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:48.878480"
  },
  {
    "id": "2505.05701",
    "title": "Pretraining a Shared Q-Network for Data-Efficient Offline Reinforcement Learning",
    "url": "https://arxiv.org/abs/2505.05701",
    "authors": "Jongchan Park, Mingyu Park, Donghwan Lee",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.05701v1 Announce Type: new  Abstract: Offline reinforcement learning (RL) aims to learn a policy from a static dataset without further interactions with the environment. Collecting sufficiently large datasets for offline RL is exhausting since this data collection requires colossus interactions with environments and becomes tricky when the interaction with the environment is restricted. Hence, how an agent learns the best policy with a minimal static dataset is a crucial issue in offline RL, similar to the sample efficiency problem in online RL. In this paper, we propose a simple yet effective plug-and-play pretraining method to initialize a feature of a $Q$-network to enhance data efficiency in offline RL. Specifically, we introduce a shared $Q$-network structure that outputs predictions of the next state and $Q$-value. We pretrain the shared $Q$-network through a supervised regression task that predicts a next state and trains the shared $Q$-network using diverse offline RL methods. Through extensive experiments, we empirically demonstrate that our method enhances the performance of existing popular offline RL methods on the D4RL, Robomimic and V-D4RL benchmarks. Furthermore, we show that our method significantly boosts data-efficient offline RL across various data qualities and data distributions trough D4RL and ExoRL benchmarks. Notably, our method adapted with only 10% of the dataset outperforms standard algorithms even with full datasets.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797273",
    "summary": "這篇論文提出了一個新方法，透過預訓練共享的Q網絡來增強離線強化學習的數據效率。他們通過預測下一個狀態和Q值來訓練這個共享的Q網絡，並在多個實驗中證明這個方法可以提升現有的離線強化學習方法在各種數據質量和分佈下的表現。值得一提的是，他們的方法只需使用10%的數據集就能超越標準算法，即使是在使用完整數據集時也是如此。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:24.742667",
    "audio_file": "2505.05701.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.05701.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:49.941554"
  },
  {
    "id": "2505.05758",
    "title": "APOLLO: Automated LLM and Lean Collaboration for Advanced Formal Reasoning",
    "url": "https://arxiv.org/abs/2505.05758",
    "authors": "Azim Ospanov, Roozbeh Yousefzadeh",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.05758v1 Announce Type: new  Abstract: Formal reasoning and automated theorem proving constitute a challenging subfield of machine learning, in which machines are tasked with proving mathematical theorems using formal languages like Lean. A formal verification system can check whether a formal proof is correct or not almost instantaneously, but generating a completely correct formal proof with large language models (LLMs) remains a formidable task. The usual approach in the literature is to prompt the LLM many times (up to several thousands) until one of the generated proofs passes the verification system. In this work, we present APOLLO (Automated PrOof repair via LLM and Lean cOllaboration), a modular, model-agnostic pipeline that combines the strengths of the Lean compiler with an LLM's reasoning abilities to achieve better proof-generation results at a low sampling budget. Apollo directs a fully automated process in which the LLM generates proofs for theorems, a set of agents analyze the proofs, fix the syntax errors, identify the mistakes in the proofs using Lean, isolate failing sub-lemmas, utilize automated solvers, and invoke an LLM on each remaining goal with a low top-K budget. The repaired sub-proofs are recombined and reverified, iterating up to a user-controlled maximum number of attempts. On the miniF2F benchmark, we establish a new state-of-the-art accuracy of 75.0% among 7B-parameter models while keeping the sampling budget below one thousand. Moreover, Apollo raises the state-of-the-art accuracy for Goedel-Prover-SFT to 65.6% while cutting sample complexity from 25,600 to a few hundred. General-purpose models (o3-mini, o4-mini) jump from 3-7% to over 40% accuracy. Our results demonstrate that targeted, compiler-guided repair of LLM outputs yields dramatic gains in both efficiency and correctness, suggesting a general paradigm for scalable automated theorem proving.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797291",
    "summary": "這篇論文提出了一個名為APOLLO的系統，結合了Lean編譯器和大型語言模型的能力，以更有效率地生成數學定理的證明。透過自動化的過程，系統能夠修復語法錯誤、找出證明中的錯誤、使用自動求解器，並在預算內完成證明生成。在測試中，APOLLO不僅提高了準確性，還降低了樣本複雜度，顯示出在自動定理證明領域具有潛力的創新方法。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:28.003797",
    "audio_file": "2505.05758.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.05758.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:50.957363"
  },
  {
    "id": "2505.05880",
    "title": "Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams",
    "url": "https://arxiv.org/abs/2505.05880",
    "authors": "Bettina Fazzinga, Sergio Flesca, Filippo Furfaro, Luigi Pontieri, Francesco Scala",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.05880v1 Announce Type: new  Abstract: Monitoring and analyzing process traces is a critical task for modern companies and organizations. In scenarios where there is a gap between trace events and reference business activities, this entails an interpretation problem, amounting to translating each event of any ongoing trace into the corresponding step of the activity instance. Building on a recent approach that frames the interpretation problem as an acceptance problem within an Abstract Argumentation Framework (AAF), one can elegantly analyze plausible event interpretations (possibly in an aggregated form), as well as offer explanations for those that conflict with prior process knowledge. Since, in settings where event-to-activity mapping is highly uncertain (or simply under-specified) this reasoning-based approach may yield lowly-informative results and heavy computation, one can think of discovering a sequencetagging model, trained to suggest highly-probable candidate event interpretations in a context-aware way. However, training such a model optimally may require using a large amount of manually-annotated example traces. Considering the urgent need of developing Green AI solutions enabling environmental and societal sustainability (with reduced labor/computational costs and carbon footprint), we propose a data/computation-efficient neuro-symbolic approach to the problem, where the candidate interpretations returned by the example-driven sequence tagger is refined by the AAF-based reasoner. This allows us to also leverage prior knowledge to compensate for the scarcity of example data, as confirmed by experimental results; clearly, this property is particularly useful in settings where data annotation and model optimization costs are subject to stringent constraints.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797310",
    "summary": "這篇論文結合抽象辯證和機器學習，提出一種有效分析低階流程事件串的方法。他們結合了推理和機器學習，以更有效地解釋事件串，並提供可能的事件解釋。這種方法可以在不確定的情況下提供高度可能的解釋，同時節省了訓練成本和計算成本。這種方法有助於環境和社會的可持續發展，特別適用於資料有限且成本受限制的情況下。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:29.910059",
    "audio_file": "2505.05880.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.05880.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:52.257239"
  },
  {
    "id": "2505.05976",
    "title": "Pseudo-Boolean d-DNNF Compilation for Expressive Feature Modeling Constructs",
    "url": "https://arxiv.org/abs/2505.05976",
    "authors": "Chico Sundermann, Stefan Vill, Elias Kuiter, Sebastian Krieter, Thomas Th\\\"um, Matthias Tichy",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.SE"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.05976v1 Announce Type: new  Abstract: Configurable systems typically consist of reusable assets that have dependencies between each other. To specify such dependencies, feature models are commonly used. As feature models in practice are often complex, automated reasoning is typically employed to analyze the dependencies. Here, the de facto standard is translating the feature model to conjunctive normal form (CNF) to enable employing off-the-shelf tools, such as SAT or #SAT solvers. However, modern feature-modeling dialects often contain constructs, such as cardinality constraints, that are ill-suited for conversion to CNF. This mismatch between the input of reasoning engines and the available feature-modeling dialects limits the applicability of the more expressive constructs. In this work, we shorten this gap between expressive constructs and scalable automated reasoning. Our contribution is twofold: First, we provide a pseudo-Boolean encoding for feature models, which facilitates smaller representations of commonly employed constructs compared to Boolean encoding. Second, we propose a novel method to compile pseudo-Boolean formulas to Boolean d-DNNF. With the compiled d-DNNFs, we can resort to a plethora of efficient analyses already used in feature modeling. Our empirical evaluation shows that our proposal substantially outperforms the state-of-the-art based on CNF inputs for expressive constructs. For every considered dataset representing different feature models and feature-modeling constructs, the feature models can be significantly faster translated to pseudo-Boolean than to CNF. Overall, deriving d-DNNFs from a feature model with the targeted expressive constraints can be substantially accelerated using our pseudo-Boolean approach. Furthermore, our approach is competitive on feature models with only basic constructs.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797328",
    "summary": "這篇論文提出了一種新方法，可以更有效地處理複雜的特徵模型，讓電腦能更快速地分析特徵之間的關係。他們開發了一種偽布林編碼方式，可以比傳統的布林編碼更有效地表示特徵模型中的條件。這個方法不僅可以加速特徵模型的分析，也能處理更多不同類型的特徵模型。研究結果顯示，這種偽布林方法比傳統方法更有效率，對於特徵模型的應用有很大的幫助。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:31.880320",
    "audio_file": "2505.05976.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.05976.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:53.475721"
  },
  {
    "id": "2505.06020",
    "title": "ArtRAG: Retrieval-Augmented Generation with Structured Context for Visual Art Understanding",
    "url": "https://arxiv.org/abs/2505.06020",
    "authors": "Shuai Wang, Ivona Najdenkoska, Hongyi Zhu, Stevan Rudinac, Monika Kackovic, Nachoem Wijnberg, Marcel Worring",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "published_date": "Mon, 12 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.06020v1 Announce Type: new  Abstract: Understanding visual art requires reasoning across multiple perspectives -- cultural, historical, and stylistic -- beyond mere object recognition. While recent multimodal large language models (MLLMs) perform well on general image captioning, they often fail to capture the nuanced interpretations that fine art demands. We propose ArtRAG, a novel, training-free framework that combines structured knowledge with retrieval-augmented generation (RAG) for multi-perspective artwork explanation. ArtRAG automatically constructs an Art Context Knowledge Graph (ACKG) from domain-specific textual sources, organizing entities such as artists, movements, themes, and historical events into a rich, interpretable graph. At inference time, a multi-granular structured retriever selects semantically and topologically relevant subgraphs to guide generation. This enables MLLMs to produce contextually grounded, culturally informed art descriptions. Experiments on the SemArt and Artpedia datasets show that ArtRAG outperforms several heavily trained baselines. Human evaluations further confirm that ArtRAG generates coherent, insightful, and culturally enriched interpretations.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-13T00:50:07.797347",
    "summary": "這篇論文提出了一個名為ArtRAG的新框架，結合結構化知識和檢索增強生成，幫助理解視覺藝術作品。ArtRAG可以從特定領域的文本來源自動構建藝術上下文知識圖，並在推論時選擇相關子圖來引導生成，讓模型能夠產生具有文化背景的藝術描述。研究表明，ArtRAG在SemArt和Artpedia數據集上表現優異，人類評估也確認ArtRAG能夠生成連貫、富有見解和文化豐富的解釋。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-13T00:50:34.420950",
    "audio_file": "2505.06020.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.06020.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-13T00:50:55.064263"
  }
]