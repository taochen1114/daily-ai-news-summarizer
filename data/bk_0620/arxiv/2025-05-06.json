[
  {
    "id": "2505.00733",
    "title": "ROSA: A Knowledge-based Solution for Robot Self-Adaptation",
    "url": "https://arxiv.org/abs/2505.00733",
    "authors": "Gustavo Rezende Silva, Juliane P\\\"a{\\ss}ler, S. Lizeth Tapia Tarifa, Einar Broch Johnsen, Carlos Hern\\'andez Corbato",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.00733v1 Announce Type: new  Abstract: Autonomous robots must operate in diverse environments and handle multiple tasks despite uncertainties. This creates challenges in designing software architectures and task decision-making algorithms, as different contexts may require distinct task logic and architectural configurations. To address this, robotic systems can be designed as self-adaptive systems capable of adapting their task execution and software architecture at runtime based on their context.This paper introduces ROSA, a novel knowledge-based framework for RObot Self-Adaptation, which enables task-and-architecture co-adaptation (TACA) in robotic systems. ROSA achieves this by providing a knowledge model that captures all application-specific knowledge required for adaptation and by reasoning over this knowledge at runtime to determine when and how adaptation should occur. In addition to a conceptual framework, this work provides an open-source ROS 2-based reference implementation of ROSA and evaluates its feasibility and performance in an underwater robotics application. Experimental results highlight ROSA's advantages in reusability and development effort for designing self-adaptive robotic systems.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241690",
    "summary": "這篇論文介紹了一個名為ROSA的新型知識型框架，可以讓機器人在運作時根據環境自主調整任務執行和軟體架構，提升適應性。ROSA透過知識模型在運行時推理，決定何時以及如何進行調整。研究者還提供了基於ROS 2的開源參考實現，並在水下機器人應用中評估其可行性和效能。實驗結果顯示ROSA在設計自適應機器人系統時具有重用性和開發效益的優勢。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:13.265730",
    "audio_file": "2505.00733.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.00733.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:45.377971"
  },
  {
    "id": "2505.00795",
    "title": "Howard's Policy Iteration is Subexponential for Deterministic Markov Decision Problems with Rewards of Fixed Bit-size and Arbitrary Discount Factor",
    "url": "https://arxiv.org/abs/2505.00795",
    "authors": "Dibyangshu Mukherjee, Shivaram Kalyanakrishnan",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.00795v1 Announce Type: new  Abstract: Howard's Policy Iteration (HPI) is a classic algorithm for solving Markov Decision Problems (MDPs). HPI uses a \"greedy\" switching rule to update from any non-optimal policy to a dominating one, iterating until an optimal policy is found. Despite its introduction over 60 years ago, the best-known upper bounds on HPI's running time remain exponential in the number of states -- indeed even on the restricted class of MDPs with only deterministic transitions (DMDPs). Meanwhile, the tightest lower bound for HPI for MDPs with a constant number of actions per state is only linear. In this paper, we report a significant improvement: a subexponential upper bound for HPI on DMDPs, which is parameterised by the bit-size of the rewards, while independent of the discount factor. The same upper bound also applies to DMDPs with only two possible rewards (which may be of arbitrary size).",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241716",
    "summary": "這篇論文提出了一個重要的改進，針對解決馬可夫決策問題的經典算法Howard's Policy Iteration (HPI)。他們成功地找到了一個比指數時間更有效率的方法，特別適用於具有固定位元大小獎勵和任意折扣因子的問題。這項研究有助於提高在特定情況下解決MDPs的效率，對於優化決策過程有重要的意義。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:15.034467",
    "audio_file": "2505.00795.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.00795.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:46.766886"
  },
  {
    "id": "2505.00802",
    "title": "Explanations as Bias Detectors: A Critical Study of Local Post-hoc XAI Methods for Fairness Exploration",
    "url": "https://arxiv.org/abs/2505.00802",
    "authors": "Vasiliki Papanikou, Danae Pla Karidi, Evaggelia Pitoura, Emmanouil Panagiotou, Eirini Ntoutsi",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.00802v1 Announce Type: new  Abstract: As Artificial Intelligence (AI) is increasingly used in areas that significantly impact human lives, concerns about fairness and transparency have grown, especially regarding their impact on protected groups. Recently, the intersection of explainability and fairness has emerged as an important area to promote responsible AI systems. This paper explores how explainability methods can be leveraged to detect and interpret unfairness. We propose a pipeline that integrates local post-hoc explanation methods to derive fairness-related insights. During the pipeline design, we identify and address critical questions arising from the use of explanations as bias detectors such as the relationship between distributive and procedural fairness, the effect of removing the protected attribute, the consistency and quality of results across different explanation methods, the impact of various aggregation strategies of local explanations on group fairness evaluations, and the overall trustworthiness of explanations as bias detectors. Our results show the potential of explanation methods used for fairness while highlighting the need to carefully consider the aforementioned critical aspects.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241738",
    "summary": "這篇論文探討了如何利用解釋性方法來偵測和解釋不公平現象，特別針對對受保護群體的影響。研究提出了一個整合了局部事後解釋方法的流程，用來獲取與公平相關的見解。研究結果顯示，解釋方法在公平性方面有潛力，同時也強調了需要仔細考慮一些關鍵方面，例如不同解釋方法的一致性和結果品質，以及局部解釋的聚合策略對群體公平評估的影響等。這項研究有助於推動負責任的人工智慧系統，提高透明度和公平性。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:17.539640",
    "audio_file": "2505.00802.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.00802.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:48.152349"
  },
  {
    "id": "2505.00827",
    "title": "MIMIC-\\RNum{4}-Ext-22MCTS: A 22 Millions-Event Temporal Clinical Time-Series Dataset with Relative Timestamp for Risk Prediction",
    "url": "https://arxiv.org/abs/2505.00827",
    "authors": "Jing Wang, Xing Niu, Juyong Kim, Jie Shen, Tong Zhang, Jeremy C. Weiss",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.00827v1 Announce Type: new  Abstract: Clinical risk prediction based on machine learning algorithms plays a vital role in modern healthcare. A crucial component in developing a reliable prediction model is collecting high-quality time series clinical events. In this work, we release such a dataset that consists of 22,588,586 Clinical Time Series events, which we term MIMIC-\\RNum{4}-Ext-22MCTS. Our source data are discharge summaries selected from the well-known yet unstructured MIMIC-IV-Note \\cite{Johnson2023-pg}. We then extract clinical events as short text span from the discharge summaries, along with the timestamps of these events as temporal information. The general-purpose MIMIC-IV-Note pose specific challenges for our work: it turns out that the discharge summaries are too lengthy for typical natural language models to process, and the clinical events of interest often are not accompanied with explicit timestamps. Therefore, we propose a new framework that works as follows: 1) we break each discharge summary into manageably small text chunks; 2) we apply contextual BM25 and contextual semantic search to retrieve chunks that have a high potential of containing clinical events; and 3) we carefully design prompts to teach the recently released Llama-3.1-8B \\cite{touvron2023llama} model to identify or infer temporal information of the chunks. We show that the obtained dataset is so informative and transparent that standard models fine-tuned on our dataset are achieving significant improvements in healthcare applications. In particular, the BERT model fine-tuned based on our dataset achieves 10\\% improvement in accuracy on medical question answering task, and 3\\% improvement in clinical trial matching task compared with the classic BERT. The GPT-2 model, fine-tuned on our dataset, produces more clinically reliable results for clinical questions.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241760",
    "summary": "這篇論文介紹了一個新的醫療時間序列資料集 MIMIC-\\RNum{4}-Ext-22MCTS，包含了超過2200萬個臨床事件，有助於進行風險預測。研究團隊提出了一個新的方法，從長篇的出院摘要中提取臨床事件和時間戳記，讓機器學習模型更準確地預測醫療風險。這個資料集的應用讓標準模型在醫療領域有顯著進步，例如基於該資料集微調的BERT模型在醫學問答任務上準確率提升了10%，GPT-2模型在臨床問題上也有更可靠的結果。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:20.221756",
    "audio_file": "2505.00827.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.00827.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:49.558992"
  },
  {
    "id": "2505.00875",
    "title": "Thoughts without Thinking: Reconsidering the Explanatory Value of Chain-of-Thought Reasoning in LLMs through Agentic Pipelines",
    "url": "https://arxiv.org/abs/2505.00875",
    "authors": "Ramesh Manuvinakurike, Emanuel Moss, Elizabeth Anne Watkins, Saurav Sahay, Giuseppe Raffa, Lama Nachman",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.00875v1 Announce Type: new  Abstract: Agentic pipelines present novel challenges and opportunities for human-centered explainability. The HCXAI community is still grappling with how best to make the inner workings of LLMs transparent in actionable ways. Agentic pipelines consist of multiple LLMs working in cooperation with minimal human control. In this research paper, we present early findings from an agentic pipeline implementation of a perceptive task guidance system. Through quantitative and qualitative analysis, we analyze how Chain-of-Thought (CoT) reasoning, a common vehicle for explainability in LLMs, operates within agentic pipelines. We demonstrate that CoT reasoning alone does not lead to better outputs, nor does it offer explainability, as it tends to produce explanations without explainability, in that they do not improve the ability of end users to better understand systems or achieve their goals.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241779",
    "summary": "這篇研究討論了在人工智慧領域中，如何讓模型的內部運作更透明且可操作。他們發現，單靠思維連鎖推理並不能提升模型的輸出品質或可解釋性。研究團隊透過量化和質化分析，探討了在協作型模型中，思維連鎖推理的運作方式。這項研究的重要發現是，單靠思維連鎖推理無法提供更好的解釋，也無法讓使用者更好地理解系統或實現目標。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:22.432483",
    "audio_file": "2505.00875.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.00875.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:50.844249"
  },
  {
    "id": "2505.00876",
    "title": "Car Sensors Health Monitoring by Verification Based on Autoencoder and Random Forest Regression",
    "url": "https://arxiv.org/abs/2505.00876",
    "authors": "Sahar Torkhesari, Behnam Yousefimehr, Mehdi Ghatee",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.00876v1 Announce Type: new  Abstract: Driver assistance systems provide a wide range of crucial services, including closely monitoring the condition of vehicles. This paper showcases a groundbreaking sensor health monitoring system designed for the automotive industry. The ingenious system leverages cutting-edge techniques to process data collected from various vehicle sensors. It compares their outputs within the Electronic Control Unit (ECU) to evaluate the health of each sensor. To unravel the intricate correlations between sensor data, an extensive exploration of machine learning and deep learning methodologies was conducted. Through meticulous analysis, the most correlated sensor data were identified. These valuable insights were then utilized to provide accurate estimations of sensor values. Among the diverse learning methods examined, the combination of autoencoders for detecting sensor failures and random forest regression for estimating sensor values proved to yield the most impressive outcomes. A statistical model using the normal distribution has been developed to identify possible sensor failures proactively. By comparing the actual values of the sensors with their estimated values based on correlated sensors, faulty sensors can be detected early. When a defective sensor is detected, both the driver and the maintenance department are promptly alerted. Additionally, the system replaces the value of the faulty sensor with the estimated value obtained through analysis. This proactive approach was evaluated using data from twenty essential sensors in the Saipa's Quick vehicle's ECU, resulting in an impressive accuracy rate of 99\\%.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241802",
    "summary": "這篇論文介紹了一個創新的汽車感應器健康監控系統，利用機器學習和深度學習技術來評估汽車感應器的狀況。通過比對感應器數據，系統可以提前檢測故障感應器並準確估計感應器數值，進而提醒駕駛員和維修部門。這種主動式方法在實驗中展現出高達99%的準確率，為汽車行業帶來了重要的價值和創新。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:24.489648",
    "audio_file": "2505.00876.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.00876.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:51.844909"
  },
  {
    "id": "2505.00972",
    "title": "Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models",
    "url": "https://arxiv.org/abs/2505.00972",
    "authors": "Yuewen Mei, Tong Nie, Jian Sun, Ye Tian",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.00972v1 Announce Type: new  Abstract: Simulation-based testing is crucial for validating autonomous vehicles (AVs), yet existing scenario generation methods either overfit to common driving patterns or operate in an offline, non-interactive manner that fails to expose rare, safety-critical corner cases. In this paper, we introduce an online, retrieval-augmented large language model (LLM) framework for generating safety-critical driving scenarios. Our method first employs an LLM-based behavior analyzer to infer the most dangerous intent of the background vehicle from the observed state, then queries additional LLM agents to synthesize feasible adversarial trajectories. To mitigate catastrophic forgetting and accelerate adaptation, we augment the framework with a dynamic memorization and retrieval bank of intent-planner pairs, automatically expanding its behavioral library when novel intents arise. Evaluations using the Waymo Open Motion Dataset demonstrate that our model reduces the mean minimum time-to-collision from 1.62 to 1.08 s and incurs a 75% collision rate, substantially outperforming baselines.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241827",
    "summary": "這篇論文提出了一個新方法，利用大型語言模型來即時生成自駕車安全關鍵的行車情境。透過分析其他車輛的行為，系統可以預測潛在的危險意圖，並生成對應的對抗性軌跡，以幫助自駕車應對危險情況。經過實驗驗證，這個方法可以顯著降低碰撞風險，提高自駕車的安全性能。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:26.482292",
    "audio_file": "2505.00972.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.00972.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:52.879539"
  },
  {
    "id": "2505.01009",
    "title": "Improving Large Language Model Planning with Action Sequence Similarity",
    "url": "https://arxiv.org/abs/2505.01009",
    "authors": "Xinran Zhao, Hanie Sedghi, Bernd Bohnet, Dale Schuurmans, Azade Nova",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.01009v1 Announce Type: new  Abstract: Planning is essential for artificial intelligence systems to look ahead and proactively determine a course of actions to reach objectives in the virtual and real world. Recent work on large language models (LLMs) sheds light on their planning capability in various tasks. However, it remains unclear what signals in the context influence the model performance. In this work, we explore how to improve the model planning capability through in-context learning (ICL), specifically, what signals can help select the exemplars. Through extensive experiments, we observe that commonly used problem similarity may result in false positives with drastically different plans, which can mislead the model. In response, we propose to sample and filter exemplars leveraging plan side action sequence similarity (AS). We propose GRASE-DC: a two-stage pipeline that first re-samples high AS exemplars and then curates the selected exemplars with dynamic clustering on AS to achieve a balance of relevance and diversity. Our experimental result confirms that GRASE-DC achieves significant performance improvement on various planning tasks (up to ~11-40 point absolute accuracy improvement with 27.3% fewer exemplars needed on average). With GRASE-DC* + VAL, where we iteratively apply GRASE-DC with a validator, we are able to even boost the performance by 18.9% more.   Extensive analysis validates the consistent performance improvement of GRASE-DC with various backbone LLMs and on both classical planning and natural language planning benchmarks. GRASE-DC can further boost the planning accuracy by ~24 absolute points on harder problems using simpler problems as exemplars over a random baseline. This demonstrates its ability to generalize to out-of-distribution problems.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241847",
    "summary": "這篇論文主要提出了一種新方法，能夠透過在上下文中學習，改善大型語言模型的規劃能力，讓模型在各種任務中能夠更有效地預測未來行動。經過實驗驗證，這個方法能夠顯著提升規劃任務的表現，並且在處理較難的問題時，使用簡單問題作為範例，也能獲得更好的結果。這項研究有助於提升人工智慧系統的預測能力，對於未來的相關應用有相當大的價值。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:28.532819",
    "audio_file": "2505.01009.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.01009.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:53.880183"
  },
  {
    "id": "2505.01028",
    "title": "Adaptive Wizard for Removing Cross-Tier Misconfigurations in Active Directory",
    "url": "https://arxiv.org/abs/2505.01028",
    "authors": "Huy Q. Ngo, Mingyu Guo, Hung Nguyen",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.01028v1 Announce Type: new  Abstract: Security vulnerabilities in Windows Active Directory (AD) systems are typically modeled using an attack graph and hardening AD systems involves an iterative workflow: security teams propose an edge to remove, and IT operations teams manually review these fixes before implementing the removal. As verification requires significant manual effort, we formulate an Adaptive Path Removal Problem to minimize the number of steps in this iterative removal process. In our model, a wizard proposes an attack path in each step and presents it as a set of multiple-choice options to the IT admin. The IT admin then selects one edge from the proposed set to remove. This process continues until the target $t$ is disconnected from source $s$ or the number of proposed paths reaches $B$. The model aims to optimize the human effort by minimizing the expected number of interactions between the IT admin and the security wizard. We first prove that the problem is $\\mathcal{\\#P}$-hard. We then propose a set of solutions including an exact algorithm, an approximate algorithm, and several scalable heuristics. Our best heuristic, called DPR, can operate effectively on larger-scale graphs compared to the exact algorithm and consistently outperforms the approximate algorithm across all graphs. We verify the effectiveness of our algorithms on several synthetic AD graphs and an AD attack graph collected from a real organization.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241865",
    "summary": "這篇研究提出了一個名為「Adaptive Wizard」的方法，幫助管理者在Windows Active Directory系統中快速修復安全漏洞，減少人工審核的工作量。透過一個向IT管理員提供多個選項的精靈，讓管理者能夠快速選擇要移除的漏洞，以降低修復過程中的互動次數。研究團隊提出了一系列解決方案，其中最佳的啟發式算法DPR在處理大型圖表時表現優異，並在多個實驗中驗證了演算法的有效性。這項研究有助於提升AD系統的安全性，減少人力成本。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:32.131913",
    "audio_file": "2505.01028.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.01028.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:55.223937"
  },
  {
    "id": "2505.01073",
    "title": "Retrieval Augmented Learning: A Retrial-based Large Language Model Self-Supervised Learning and Autonomous Knowledge Generation",
    "url": "https://arxiv.org/abs/2505.01073",
    "authors": "Zongyuan Li, Pengfei Li, Runnan Qi, Yanan Ni, Lumin Jiang, Hui Wu, Xuebo Zhang, Kuihua Huang, Xian Guo",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Mon, 05 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.01073v1 Announce Type: new  Abstract: The lack of domain-specific data in the pre-training of Large Language Models (LLMs) severely limits LLM-based decision systems in specialized applications, while post-training a model in the scenarios requires significant computational resources. In this paper, we present Retrial-Augmented Learning (RAL), a reward-free self-supervised learning framework for LLMs that operates without model training. By developing Retrieval-Augmented Generation (RAG) into a module for organizing intermediate data, we realized a three-stage autonomous knowledge generation of proposing a hypothesis, validating the hypothesis, and generating the knowledge. The method is evaluated in the LLM-PySC2 environment, a representative decision-making platform that combines sufficient complexity with domain-specific knowledge requirements. Experiments demonstrate that the proposed method effectively reduces hallucination by generating and utilizing validated knowledge, and increases decision-making performance at an extremely low cost. Meanwhile, the approach exhibits potential in out-of-distribution(OOD) tasks, robustness, and transferability, making it a cost-friendly but effective solution for decision-making problems and autonomous knowledge generation.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-06T09:03:07.241884",
    "summary": "這篇論文提出了一種新的自我監督學習框架，稱為Retrial-Augmented Learning (RAL)，可以幫助大型語言模型在特定應用中生成知識而無需額外訓練。通過引入Retrieval-Augmented Generation (RAG) 模組，實現了三階段的自主知識生成過程，包括提出假設、驗證假設和生成知識。研究結果顯示，這種方法可以有效降低虛幻生成，提升決策性能，同時在成本極低的情況下具有潛力應用於不同領域的任務，是一個具有效果且節省成本的解決方案。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-06T09:03:35.670640",
    "audio_file": "2505.01073.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.01073.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-06T09:03:56.566810"
  }
]