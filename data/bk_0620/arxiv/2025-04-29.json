[
  {
    "id": "2504.18572",
    "title": "BELL: Benchmarking the Explainability of Large Language Models",
    "url": "https://arxiv.org/abs/2504.18572",
    "authors": "Syed Quiser Ahmed, Bharathi Vokkaliga Ganesh, Jagadish Babu P, Karthick Selvaraj, ReddySiva Naga Parvathi Devi, Sravya Kappala",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Tue, 29 Apr 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2504.18572v1 Announce Type: new  Abstract: Large Language Models have demonstrated remarkable capabilities in natural language processing, yet their decision-making processes often lack transparency. This opaqueness raises significant concerns regarding trust, bias, and model performance. To address these issues, understanding and evaluating the interpretability of LLMs is crucial. This paper introduces a standardised benchmarking technique, Benchmarking the Explainability of Large Language Models, designed to evaluate the explainability of large language models.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-04-29T14:03:42.178884",
    "summary": "這篇論文提出了一個新的標準化評估方法，名為「BELL: Benchmarking the Explainability of Large Language Models」，旨在評估大型語言模型的可解釋性。這些語言模型在自然語言處理方面表現出色，但其決策過程常常缺乏透明度，引發了對信任、偏見和模型表現的重大擔憂。透過這個新方法，我們可以更好地了解和評估大型語言模型的可解釋性，有助於提升模型的可信度和使用價值。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-04-29T14:03:48.110411",
    "audio_error": "400 Voice 'zh-CN-Standard-A' does not exist. Is it misspelled?",
    "audio_file": "2504.18572.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2504.18572.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-04-29T14:12:30.309474"
  },
  {
    "id": "2504.18600",
    "title": "QuantBench: Benchmarking AI Methods for Quantitative Investment",
    "url": "https://arxiv.org/abs/2504.18600",
    "authors": "Saizhuo Wang, Hao Kong, Jiadong Guo, Fengrui Hua, Yiyan Qi, Wanyun Zhou, Jiahao Zheng, Xinyu Wang, Lionel M. Ni, Jian Guo",
    "categories": [
      "cs.AI",
      "cs.CE",
      "q-fin.CP"
    ],
    "published_date": "Tue, 29 Apr 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2504.18600v1 Announce Type: new  Abstract: The field of artificial intelligence (AI) in quantitative investment has seen significant advancements, yet it lacks a standardized benchmark aligned with industry practices. This gap hinders research progress and limits the practical application of academic innovations. We present QuantBench, an industrial-grade benchmark platform designed to address this critical need. QuantBench offers three key strengths: (1) standardization that aligns with quantitative investment industry practices, (2) flexibility to integrate various AI algorithms, and (3) full-pipeline coverage of the entire quantitative investment process. Our empirical studies using QuantBench reveal some critical research directions, including the need for continual learning to address distribution shifts, improved methods for modeling relational financial data, and more robust approaches to mitigate overfitting in low signal-to-noise environments. By providing a common ground for evaluation and fostering collaboration between researchers and practitioners, QuantBench aims to accelerate progress in AI for quantitative investment, similar to the impact of benchmark platforms in computer vision and natural language processing.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-04-29T14:03:42.178901",
    "summary": "這篇論文提出了一個名為QuantBench的平台，專門用來評估人工智慧在量化投資領域的方法。這個平台有三大特點：符合業界標準、能整合各種人工智慧演算法、並覆蓋整個量化投資流程。研究發現指出了一些重要的研究方向，包括需要持續學習以應對分配變化、改進金融數據建模方法，以及在低信噪比環境中減少過度擬合的方法。QuantBench的目標是促進研究者和實踐者之間的合作，加速人工智慧在量化投資領域的發展。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-04-29T14:03:50.916059",
    "audio_error": "400 Voice 'zh-CN-Standard-A' does not exist. Is it misspelled?",
    "audio_file": "2504.18600.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2504.18600.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-04-29T14:12:33.236028"
  },
  {
    "id": "2504.18604",
    "title": "A Cognitive-Mechanistic Human Reliability Analysis Framework: A Nuclear Power Plant Case Study",
    "url": "https://arxiv.org/abs/2504.18604",
    "authors": "Xingyu Xiao, Peng Chen, Jiejuan Tong, Shunshun Liu, Hongru Zhao, Jun Zhao, Qianqian Jia, Jingang Liang, Haitao Wang",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Tue, 29 Apr 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2504.18604v1 Announce Type: new  Abstract: Traditional human reliability analysis (HRA) methods, such as IDHEAS-ECA, rely on expert judgment and empirical rules that often overlook the cognitive underpinnings of human error. Moreover, conducting human-in-the-loop experiments for advanced nuclear power plants is increasingly impractical due to novel interfaces and limited operational data. This study proposes a cognitive-mechanistic framework (COGMIF) that enhances the IDHEAS-ECA methodology by integrating an ACT-R-based human digital twin (HDT) with TimeGAN-augmented simulation. The ACT-R model simulates operator cognition, including memory retrieval, goal-directed procedural reasoning, and perceptual-motor execution, under high-fidelity scenarios derived from a high-temperature gas-cooled reactor (HTGR) simulator. To overcome the resource constraints of large-scale cognitive modeling, TimeGAN is trained on ACT-R-generated time-series data to produce high-fidelity synthetic operator behavior datasets. These simulations are then used to drive IDHEAS-ECA assessments, enabling scalable, mechanism-informed estimation of human error probabilities (HEPs). Comparative analyses with SPAR-H and sensitivity assessments demonstrate the robustness and practical advantages of the proposed COGMIF. Finally, procedural features are mapped onto a Bayesian network to quantify the influence of contributing factors, revealing key drivers of operational risk. This work offers a credible and computationally efficient pathway to integrate cognitive theory into industrial HRA practices.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-04-29T14:03:42.178910",
    "summary": "這篇論文提出了一個新的人類可靠度分析框架，將認知理論融入工業安全評估中，並成功應用在核電廠案例研究中。他們結合了人類數位孿生模型和模擬技術，以更準確地估計人為錯誤機率，並找出操作風險的關鍵因素。這項研究的創新之處在於將認知科學應用於工業安全領域，提供了一個可靠且高效的方法，有助於提升工業安全評估的準確性和可擴展性。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-04-29T14:03:53.812344",
    "audio_error": "400 Voice 'zh-CN-Standard-A' does not exist. Is it misspelled?",
    "audio_file": "2504.18604.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2504.18604.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-04-29T14:12:34.935527"
  }
]