[
  {
    "id": "2505.03770",
    "title": "Proceedings of 1st Workshop on Advancing Artificial Intelligence through Theory of Mind",
    "url": "https://arxiv.org/abs/2505.03770",
    "authors": "Mouad Abrini, Omri Abend, Dina Acklin, Henny Admoni, Gregor Aichinger, Nitay Alon, Zahra Ashktorab, Ashish Atreja, Moises Auron, Alexander Aufreiter, Raghav Awasthi, Soumya Banerjee, Joe M. Barnby, Rhea Basappa, Severin Bergsmann, Djallel Bouneffouf, Patrick Callaghan, Marc Cavazza, Thierry Chaminade, Sonia Chernova, Mohamed Chetouan, Moumita Choudhury, Axel Cleeremans, Jacek B. Cywinski, Fabio Cuzzolin, Hokin Deng, N'yoma Diamond, Camilla Di Pasquasio, Guillaume Dumas, Max van Duijn, Mahapatra Dwarikanath, Qingying Gao, Ashok Goel, Rebecca Goldstein, Matthew Gombolay, Gabriel Enrique Gonzalez, Amar Halilovic, Tobias Halmdienst, Mahimul Islam, Julian Jara-Ettinger, Natalie Kastel, Renana Keydar, Ashish K. Khanna, Mahdi Khoramshahi, JiHyun Kim, MiHyeon Kim, YoungBin Kim, Senka Krivic, Nikita Krasnytskyi, Arun Kumar, JuneHyoung Kwon, Eunju Lee, Shane Lee, Peter R. Lewis, Xue Li, Yijiang Li, Michal Lewandowski, Nathan Lloyd, Matthew B. Luebbers, Dezhi Luo, Haiyun Lyu, Dwarikanath Mahapatra, Kamal Maheshwari, Mallika Mainali, Piyush Mathur, Patrick Mederitsch, Shuwa Miura, Manuel Preston de Miranda, Reuth Mirsky, Shreya Mishra, Nina Moorman, Katelyn Morrison, John Muchovej, Bernhard Nessler, Felix Nessler, Hieu Minh Jord Nguyen, Abby Ortego, Francis A. Papay, Antoine Pasquali, Hamed Rahimi, Charumathi Raghu, Amanda Royka, Stefan Sarkadi, Jaelle Scheuerman, Simon Schmid, Paul Schrater, Anik Sen, Zahra Sheikhbahaee, Ke Shi, Reid Simmons, Nishant Singh, Mason O. Smith, Ramira van der Meulen, Anthia Solaki, Haoran Sun, Viktor Szolga, Matthew E. Taylor, Travis Taylor, Sanne Van Waveren, Juan David Vargas, Rineke Verbrugge, Eitan Wagner, Justin D. Weisz, Ximing Wen, William Yeoh, Wenlong Zhang, Michelle Zhao, Shlomo Zilberstein",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.03770v1 Announce Type: new  Abstract: This volume includes a selection of papers presented at the Workshop on Advancing Artificial Intelligence through Theory of Mind held at AAAI 2025 in Philadelphia US on 3rd March 2025. The purpose of this volume is to provide an open access and curated anthology for the ToM and AI research community.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059279",
    "summary": "這篇論文是關於「透過心智理論推動人工智慧」的研究，收錄了在2025年3月3日在美國費城舉辦的AAAI研討會上發表的論文。這個研究的目的是為了提供一個對心智理論和人工智慧研究社群的開放存取和精選選集。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:25.201958",
    "audio_file": "2505.03770.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.03770.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:12:56.003028"
  },
  {
    "id": "2505.03800",
    "title": "Design description of Wisdom Computing Persperctive",
    "url": "https://arxiv.org/abs/2505.03800",
    "authors": "TianYi Yu",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.03800v1 Announce Type: new  Abstract: This course design aims to develop and research a handwriting matrix recognition and step-by-step visual calculation process display system, addressing the issue of abstract formulas and complex calculation steps that students find difficult to understand when learning mathematics. By integrating artificial intelligence with visualization animation technology, the system enhances precise recognition of handwritten matrix content through the introduction of Mamba backbone networks, completes digital extraction and matrix reconstruction using the YOLO model, and simultaneously combines CoordAttention coordinate attention mechanisms to improve the accurate grasp of character spatial positions. The calculation process is demonstrated frame by frame through the Manim animation engine, vividly showcasing each mathematical calculation step, helping students intuitively understand the intrinsic logic of mathematical operations. Through dynamically generating animation processes for different computational tasks, the system exhibits high modularity and flexibility, capable of generating various mathematical operation examples in real-time according to student needs. By innovating human-computer interaction methods, it brings mathematical calculation processes to life, helping students bridge the gap between knowledge and understanding on a deeper level, ultimately achieving a learning experience where \"every step is understood.\" The system's scalability and interactivity make it an intuitive, user-friendly, and efficient auxiliary tool in education.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059308",
    "summary": "這篇論文提出了一個新的數學學習系統，結合人工智慧和視覺動畫技術，幫助學生更直觀地理解數學運算邏輯。透過手寫矩陣辨識、動畫展示計算過程，讓學生能夠一步一步看見數學運算的過程，從而深入理解數學運算的邏輯。這個系統具有高度模塊化和靈活性，能夠根據學生需求實時生成不同的數學運算示例，提升教育輔助工具的直觀性、用戶友好性和效率。透過創新的人機互動方式，幫助學生更深入地理解數學知識，實現\"每一步都被理解\"的學習體驗。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:28.792912",
    "audio_file": "2505.03800.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.03800.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:12:57.489431"
  },
  {
    "id": "2505.03941",
    "title": "GRAML: Dynamic Goal Recognition As Metric Learning",
    "url": "https://arxiv.org/abs/2505.03941",
    "authors": "Matan Shamir, Reuth Mirsky",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.03941v1 Announce Type: new  Abstract: Goal Recognition (GR) is the problem of recognizing an agent's objectives based on observed actions. Recent data-driven approaches for GR alleviate the need for costly, manually crafted domain models. However, these approaches can only reason about a pre-defined set of goals, and time-consuming training is needed for new emerging goals. To keep this model-learning automated while enabling quick adaptation to new goals, this paper introduces GRAML: Goal Recognition As Metric Learning. GRAML uses a Siamese network to treat GR as a deep metric learning task, employing an RNN that learns a metric over an embedding space, where the embeddings for observation traces leading to different goals are distant, and embeddings of traces leading to the same goals are close. This metric is especially useful when adapting to new goals, even if given just one example observation trace per goal. Evaluated on a versatile set of environments, GRAML shows speed, flexibility, and runtime improvements over the state-of-the-art GR while maintaining accurate recognition.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059328",
    "summary": "這篇論文提出了一種名為GRAML的方法，可以在不需耗費大量成本和時間訓練的情況下，辨識出一個代理人的目標。它利用了一種叫做Siamese network的技術，讓機器學習辨識目標的任務更有效率。GRAML在各種環境中都顯示出速度快、靈活性高，並且比現有技術有更好的運行效果，同時保持高準確度。這個方法對於快速適應新目標特別有用，甚至只需要一個範例觀察軌跡。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:30.842864",
    "audio_file": "2505.03941.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.03941.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:12:58.760100"
  },
  {
    "id": "2505.03947",
    "title": "Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents",
    "url": "https://arxiv.org/abs/2505.03947",
    "authors": "Xiang Li, Yiyang Hao, Doug Fulop",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.03947v1 Announce Type: new  Abstract: One of the primary aspirations in reinforcement learning research is developing general-purpose agents capable of rapidly adapting to and mastering novel tasks. While RL gaming agents have mastered many Atari games, they remain slow and costly to train for each game. In this work, we demonstrate that latest reasoning LLMs with out-of-domain RL post-training can play a challenging Atari game called Frogger under a zero-shot setting. We then investigate the effect of in-context learning and the amount of reasoning effort on LLM performance. Lastly, we demonstrate a way to bootstrap traditional RL method with LLM demonstrations, which significantly improves their performance and sample efficiency. Our implementation is open sourced at https://github.com/AlienKevin/frogger.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059364",
    "summary": "這篇論文主要研究如何讓AI代理人在玩一個叫Frogger的電玩遊戲時，不需要事先訓練就能迅速適應並掌握遊戲。研究者使用最新的推理LLMs模型，結合強化學習技術，成功實現了這個零訓練的目標。他們還探討了在不同情境下學習和推理努力的影響，並提出了一種方法，可以用LLM的示範來改善傳統強化學習方法的表現和效率。這項研究有助於提高遊戲代理人的學習速度和效率，同時也提供了開放原始碼供其他研究者參考。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:34.131697",
    "audio_file": "2505.03947.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.03947.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:13:00.416598"
  },
  {
    "id": "2505.03961",
    "title": "The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete",
    "url": "https://arxiv.org/abs/2505.03961",
    "authors": "Gerrit Gro{\\ss}mann, Larisa Ivanova, Sai Leela Poduru, Mohaddeseh Tabrizian, Islam Mesabah, David A. Selby, Sebastian J. Vollmer",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.03961v1 Announce Type: new  Abstract: According to Yuval Noah Harari, large-scale human cooperation is driven by shared narratives that encode common beliefs and values. This study explores whether such narratives can similarly nudge LLM agents toward collaboration. We use a finitely repeated public goods game in which LLM agents choose either cooperative or egoistic spending strategies. We prime agents with stories highlighting teamwork to different degrees and test how this influences negotiation outcomes. Our experiments explore four questions:(1) How do narratives influence negotiation behavior? (2) What differs when agents share the same story versus different ones? (3) What happens when the agent numbers grow? (4) Are agents resilient against self-serving negotiators? We find that story-based priming significantly affects negotiation strategies and success rates. Common stories improve collaboration, benefiting each agent. By contrast, priming agents with different stories reverses this effect, and those agents primed toward self-interest prevail. We hypothesize that these results carry implications for multi-agent system design and AI alignment.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059391",
    "summary": "這篇研究探討故事如何影響人工智慧代理人在合作與競爭中的行為。研究發現，透過不同故事的引導，能夠顯著影響代理人的談判策略和成功率。共同故事有助於促進合作，而不同故事則會導致自私行為占上風。這些結果對多代理系統設計和人工智慧發展有重要啟示。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:35.919722",
    "audio_file": "2505.03961.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.03961.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:13:01.645781"
  },
  {
    "id": "2505.03985",
    "title": "LogiDebrief: A Signal-Temporal Logic based Automated Debriefing Approach with Large Language Models Integration",
    "url": "https://arxiv.org/abs/2505.03985",
    "authors": "Zirong Chen, Ziyan An, Jennifer Reynolds, Kristin Mullen, Stephen Martini, Meiyi Ma",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.03985v1 Announce Type: new  Abstract: Emergency response services are critical to public safety, with 9-1-1 call-takers playing a key role in ensuring timely and effective emergency operations. To ensure call-taking performance consistency, quality assurance is implemented to evaluate and refine call-takers' skillsets. However, traditional human-led evaluations struggle with high call volumes, leading to low coverage and delayed assessments. We introduce LogiDebrief, an AI-driven framework that automates traditional 9-1-1 call debriefing by integrating Signal-Temporal Logic (STL) with Large Language Models (LLMs) for fully-covered rigorous performance evaluation. LogiDebrief formalizes call-taking requirements as logical specifications, enabling systematic assessment of 9-1-1 calls against procedural guidelines. It employs a three-step verification process: (1) contextual understanding to identify responder types, incident classifications, and critical conditions; (2) STL-based runtime checking with LLM integration to ensure compliance; and (3) automated aggregation of results into quality assurance reports. Beyond its technical contributions, LogiDebrief has demonstrated real-world impact. Successfully deployed at Metro Nashville Department of Emergency Communications, it has assisted in debriefing 1,701 real-world calls, saving 311.85 hours of active engagement. Empirical evaluation with real-world data confirms its accuracy, while a case study and extensive user study highlight its effectiveness in enhancing call-taking performance.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059413",
    "summary": "這篇論文介紹了一個名為LogiDebrief的新技術，它結合了信號-時間邏輯和大型語言模型，用來自動化應急通話的回顧。這個系統可以幫助評估應急通話員的表現，確保他們符合標準操作流程。LogiDebrief的三步驟驗證過程包括：(1) 理解上下文，識別不同情況；(2) 使用信號-時間邏輯和大型語言模型檢查通話內容；(3) 自動整合結果生成品質保證報告。這個技術已在實際應用中得到驗證，幫助回顧了1,701通實際通話，節省了311.85小時的時間。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:38.134519",
    "audio_file": "2505.03985.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.03985.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:13:03.145696"
  },
  {
    "id": "2505.03989",
    "title": "An alignment safety case sketch based on debate",
    "url": "https://arxiv.org/abs/2505.03989",
    "authors": "Marie Davidsen Buhl, Jacob Pfau, Benjamin Hilton, Geoffrey Irving",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.03989v1 Announce Type: new  Abstract: If AI systems match or exceed human capabilities on a wide range of tasks, it may become difficult for humans to efficiently judge their actions -- making it hard to use human feedback to steer them towards desirable traits. One proposed solution is to leverage another superhuman system to point out flaws in the system's outputs via a debate. This paper outlines the value of debate for AI safety, as well as the assumptions and further research required to make debate work. It does so by sketching an ``alignment safety case'' -- an argument that an AI system will not autonomously take actions which could lead to egregious harm, despite being able to do so. The sketch focuses on the risk of an AI R\\&amp;D agent inside an AI company sabotaging research, for example by producing false results. To prevent this, the agent is trained via debate, subject to exploration guarantees, to teach the system to be honest. Honesty is maintained throughout deployment via online training. The safety case rests on four key claims: (1) the agent has become good at the debate game, (2) good performance in the debate game implies that the system is mostly honest, (3) the system will not become significantly less honest during deployment, and (4) the deployment context is tolerant of some errors. We identify open research problems that, if solved, could render this a compelling argument that an AI system is safe.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059437",
    "summary": "這篇論文提出利用辯論來確保人工智慧系統的安全性，當AI系統在各種任務上達到或超越人類能力時，人類可能難以有效評估它們的行為。透過辯論，另一個超級系統可以指出系統輸出的缺陷，以確保AI系統不會自主採取可能導致嚴重危害的行動。這篇論文強調了辯論對AI安全性的價值，並提出了必要的假設和進一步研究，以確保辯論的有效性。透過訓練AI代理人進行辯論，並在部署過程中保持誠實，以確保系統的安全性。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:41.085482",
    "audio_file": "2505.03989.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.03989.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:13:04.461022"
  },
  {
    "id": "2505.04019",
    "title": "Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation Forest",
    "url": "https://arxiv.org/abs/2505.04019",
    "authors": "Matteo Ceschin, Leonardo Arrighi, Luca Longo, Sylvio Barbon Junior",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.04019v1 Announce Type: new  Abstract: The need to explain predictive models is well-established in modern machine learning. However, beyond model interpretability, understanding pre-processing methods is equally essential. Understanding how data modifications impact model performance improvements and potential biases and promoting a reliable pipeline is mandatory for developing robust machine learning solutions. Isolation Forest (iForest) is a widely used technique for outlier detection that performs well. Its effectiveness increases with the number of tree-based learners. However, this also complicates the explanation of outlier selection and the decision boundaries for inliers. This research introduces a novel Explainable AI (XAI) method, tackling the problem of global explainability. In detail, it aims to offer a global explanation for outlier detection to address its opaque nature. Our approach is based on the Decision Predicate Graph (DPG), which clarifies the logic of ensemble methods and provides both insights and a graph-based metric to explain how samples are identified as outliers using the proposed Inlier-Outlier Propagation Score (IOP-Score). Our proposal enhances iForest's explainability and provides a comprehensive view of the decision-making process, detailing which features contribute to outlier identification and how the model utilizes them. This method advances the state-of-the-art by providing insights into decision boundaries and a comprehensive view of holistic feature usage in outlier identification. -- thus promoting a fully explainable machine learning pipeline.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059465",
    "summary": "這篇論文提出了一種新的AI方法，可以幫助我們更清楚地理解Isolation Forest（iForest）模型如何找出異常值。他們使用Decision Predicate Graph（DPG）來解釋模型的邏輯，並提供一個新的分數（IOP-Score）來說明異常值是如何被辨識出來的。這個方法不僅提高了iForest的解釋性，還能讓我們更全面地了解模型的決策過程，包括哪些特徵有助於辨識異常值。這項研究有助於推動機器學習的透明度，提供更清晰的解釋，讓我們能夠建立更可靠的機器學習系統。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:43.169778",
    "audio_file": "2505.04019.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.04019.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:13:05.947336"
  },
  {
    "id": "2505.04115",
    "title": "Polynomial-Time Relational Probabilistic Inference in Open Universes",
    "url": "https://arxiv.org/abs/2505.04115",
    "authors": "Luise Ge, Brendan Juba, Kris Nilsson",
    "categories": [
      "cs.AI"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.04115v1 Announce Type: new  Abstract: Reasoning under uncertainty is a fundamental challenge in Artificial Intelligence. As with most of these challenges, there is a harsh dilemma between the expressive power of the language used, and the tractability of the computational problem posed by reasoning. Inspired by human reasoning, we introduce a method of first-order relational probabilistic inference that satisfies both criteria, and can handle hybrid (discrete and continuous) variables. Specifically, we extend sum-of-squares logic of expectation to relational settings, demonstrating that lifted reasoning in the bounded-degree fragment for knowledge bases of bounded quantifier rank can be performed in polynomial time, even with an a priori unknown and/or countably infinite set of objects. Crucially, our notion of tractability is framed in proof-theoretic terms, which extends beyond the syntactic properties of the language or queries. We are able to derive the tightest bounds provable by proofs of a given degree and size and establish completeness in our sum-of-squares refutations for fixed degrees.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059488",
    "summary": "這篇論文提出了一種新方法，可以在人工智慧領域中處理不確定性推論問題，並且同時兼顧了語言表達的豐富性和計算問題的可解性。他們成功將期望值的邏輯擴展到關係設定中，並證明了在有限程度的知識庫中，即使對象集合是未知或無窮的情況下，也可以在多項式時間內進行推論。這種方法不僅擴展了語言或查詢的語法特性，還在證明論理層面上確立了可解性。這對於提高推論效率和準確性有重要意義。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:46.119383",
    "audio_file": "2505.04115.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.04115.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:13:07.384851"
  },
  {
    "id": "2505.04310",
    "title": "Flow Models for Unbounded and Geometry-Aware Distributional Reinforcement Learning",
    "url": "https://arxiv.org/abs/2505.04310",
    "authors": "Simo Alami C., Rim Kaddah, Jesse Read, Marie-Paule Cani",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "published_date": "Thu, 08 May 2025 00:00:00 -0400",
    "source": "ArXiv CS.AI",
    "content": "arXiv:2505.04310v1 Announce Type: new  Abstract: We introduce a new architecture for Distributional Reinforcement Learning (DistRL) that models return distributions using normalizing flows. This approach enables flexible, unbounded support for return distributions, in contrast to categorical approaches like C51 that rely on fixed or bounded representations. It also offers richer modeling capacity to capture multi-modality, skewness, and tail behavior than quantile based approaches. Our method is significantly more parameter-efficient than categorical approaches. Standard metrics used to train existing models like KL divergence or Wasserstein distance either are scale insensitive or have biased sample gradients, especially when return supports do not overlap. To address this, we propose a novel surrogate for the Cram\\`er distance, that is geometry-aware and computable directly from the return distribution's PDF, avoiding the costly CDF computation. We test our model on the ATARI-5 sub-benchmark and show that our approach outperforms PDF based models while remaining competitive with quantile based methods.",
    "content_type": "academic",
    "processed": true,
    "fetch_date": "2025-05-08T14:12:21.059508",
    "summary": "這篇論文提出了一種新的架構，用於處理分布式強化學習，可以更靈活地模擬回報分布，比起傳統方法更有效率。他們的方法不僅支援更多種回報分布，還能更好地捕捉多樣性、偏斜和尾部行為。為了解決現有模型在訓練時的問題，他們提出了一個新的距離替代方法，能更好地處理回報分布的幾何特性。在ATARI-5子基準測試中，他們的方法表現優異，比基於機率密度函數的模型更勝一籌，並與基於分位數的方法競爭激烈。",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-05-08T14:12:48.986749",
    "audio_file": "2505.04310.mp3",
    "audio_path": "/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/data/audio/articles/2505.04310.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-05-08T14:13:08.904671"
  }
]