[
  {
    "id": "ec9fc00a28398619f30c5e5460f917d7",
    "title": "Dunk City Dynasty launches Season 2 with Jayson Tatum and $10K community competition",
    "url": "https://venturebeat.com/games/dunk-city-dynasty-launches-season-2-with-jayson-tatum-and-10k-community-competition/",
    "authors": "Dean Takahashi",
    "published_date": "2025-06-18T07:15:00+00:00",
    "source": "VentureBeat",
    "summary": "NetEase Games推出Dunk City Dynasty第二季，邀請籃球球星Jayson Tatum參與，並舉辦總獎金高達1萬美元的社區比賽。玩家們可以期待更多刺激的籃球遊戲內容，同時有機會參加這場豐富的比賽，贏得豐厚獎金。這次活動不僅增加了遊戲的樂趣，也讓玩家間展開更多互動，是個不容錯過的機會。",
    "content": "NetEase Games is launching Season 2 of Dunk City Dynasty, adding Jayson Tatum and a community competition with a prize pool of $10,000.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.012914",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:11.363092",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 238 credits are required for this request."
  },
  {
    "id": "18b0f490afe27b35d0f510216e5a5183",
    "title": "The Interpretable AI playbook: What Anthropic’s research means for your enterprise LLM strategy",
    "url": "https://venturebeat.com/ai/the-interpretable-ai-playbook-what-anthropics-research-means-for-your-enterprise-llm-strategy/",
    "authors": "Ross Teixeira",
    "published_date": "2025-06-17T23:01:08+00:00",
    "source": "VentureBeat",
    "summary": "Anthropic的研究強調AI模型需符合人類價值觀，並深入探討模型思考方式。他們的AI模型在編碼方面表現優異，但在數學、創意寫作等領域仍有競爭。Anthropic致力於未來AI在醫學、心理學和法律等領域的應用。這項研究對企業LLM策略有重要啟示價值。",
    "content": "The Interpretable AI playbook: What Anthropic's research means for your enterprise LLM strategy | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nThe Interpretable AI playbook: What Anthropic’s research means for your enterprise LLM strategy\nRoss Teixeira\nJune 17, 2025 4:01 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nVentureBeat/Midjourney\nJoin the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.\nLearn more\nAnthropic\nCEO Dario Amodei made an\nurgent push\nin April for the need to understand how AI models think.\nThis comes at a crucial time. As Anthropic\nbattles\nin global AI rankings, it’s important to note what sets it apart from other top AI labs. Since its founding in 2021, when seven\nOpenAI\nemployees\nbroke off\nover concerns about AI safety, Anthropic has built AI models that adhere to a set of human-valued principles, a system they call\nConstitutional AI\n. These principles ensure that models are “\nhelpful, honest and harmless\n” and generally act in the best interests of society. At the same time, Anthropic’s research arm is\ndiving deep\nto understand how its models think about the world, and\nwhy\nthey produce helpful (and sometimes harmful) answers.\nAnthropic’s flagship model, Claude 3.7 Sonnet,\ndominated\ncoding benchmarks when it launched in February, proving that AI models can excel at both performance and safety. And the recent release of Claude 4.0 Opus and Sonnet again puts Claude at the\ntop of coding benchmarks\n. However, in today’s rapid and hyper-competitive AI market, Anthropic’s rivals like Google’s Gemini 2.5 Pro and Open AI’s o3 have their own impressive showings for coding prowess, while they’re\nalready dominating\nClaude at math, creative writing and overall reasoning across many languages.\nIf Amodei’s thoughts are any indication, Anthropic is planning for the future of AI and its implications in critical fields like medicine, psychology and law, where model safety and human values are imperative. And it shows: Anthropic is the leading AI lab that focuses strictly on developing “interpretable” AI, which are models that let us understand, to some degree of certainty, what the model is thinking and how it arrives at a particular conclusion.\nAmazon and\nGoogle\nhave already invested billions of dollars in Anthropic even as they build their own AI models, so perhaps Anthropic’s competitive advantage is still budding. Interpretable models, as Anthropic suggests, could significantly reduce the long-term operational costs associated with debugging, auditing and mitigating risks in complex AI deployments.\nSayash Kapoor\n, an AI safety researcher, suggests that while interpretability is valuable, it is just one of many tools for managing AI risk. In his view, “interpretability is neither necessary nor sufficient” to ensure models behave safely — it matters most when paired with filters, verifiers and human-centered design. This more expansive view sees interpretability as part of a larger ecosystem of control strategies, particularly in real-world AI deployments where models are components in broader decision-making systems.\nThe need for interpretable AI\nUntil recently, many thought AI was still years from advancements like those that are now helping Claude, Gemini and ChatGPT\nboast\nexceptional market adoption. While these models are already\npushing the frontiers of human knowledge\n, their widespread use is attributable to just how good they are at solving a wide range of practical problems that require creative problem-solving or detailed analysis. As models are put to the task on increasingly critical problems, it is important that they produce accurate answers.\nAmodei fears that when an AI responds to a prompt, “we have no idea… why it chooses certain words over others, or why it occasionally makes a mistake despite usually being accurate.” Such errors — hallucinations of inaccurate information, or responses that do not align with human values — will hold AI models back from reaching their full potential. Indeed, we’ve seen many examples of AI continuing to struggle with\nhallucinations\nand\nunethical behavior\n.\nFor Amodei, the best way to solve these problems is to understand how an AI thinks: “Our inability to understand models’ internal mechanisms means that we cannot meaningfully predict such [harmful] behaviors, and therefore struggle to rule them out … If instead it were possible to look inside models, we might be able to systematically block all jailbreaks, and also characterize what dangerous knowledge the models have.”\nAmodei also sees the opacity of current models as a barrier to deploying AI models in “high-stakes financial or safety-critical settings, because we can’t fully set the limits on their behavior, and a small number of mistakes could be very harmful.” In decision-making that affects humans directly, like medical diagnosis or mortgage assessments, legal\nregulations\nrequire AI to explain its decisions.\nImagine a financial institution using a large language model (LLM) for fraud detection — interpretability could mean explaining a denied loan application to a customer as required by law. Or a manufacturing firm optimizing supply chains — understanding why an AI suggests a particular supplier could unlock efficiencies and prevent unforeseen bottlenecks.\nBecause of this, Amodei explains, “Anthropic is doubling down on interpretability, and we have a goal of getting to ‘interpretability can reliably detect most model problems’ by 2027.”\nTo that end, Anthropic recently participated in a $50 million\ninvestment\nin\nGoodfire\n, an AI research lab making breakthrough progress on AI “brain scans.” Their model inspection platform, Ember, is an agnostic tool that identifies learned concepts within models and lets users manipulate them. In a recent\ndemo\n, the company showed how Ember can recognize individual visual concepts within an image generation AI and then let users\npaint\nthese concepts on a canvas to generate new images that follow the user’s design.\nAnthropic’s investment in Ember hints at the fact that developing interpretable models is difficult enough that Anthropic does not have the manpower to achieve interpretability on their own. Creative interpretable models requires new toolchains and skilled developers to build them\nBroader context: An AI researcher’s perspective\nTo break down Amodei’s perspective and add much-needed context, VentureBeat interviewed Kapoor an AI safety researcher at Princeton. Kapoor co-authored the book\nAI Snake Oil\n, a critical examination of exaggerated claims surrounding the capabilities of leading AI models. He is also a co-author of “\nAI as Normal Technology\n,” in which he advocates for treating AI as a standard, transformational tool like the internet or electricity, and promotes a realistic perspective on its integration into everyday systems.\nKapoor doesn’t dispute that interpretability is valuable. However, he’s skeptical of treating it as the central pillar of AI alignment. “It’s not a silver bullet,” Kapoor told VentureBeat. Many of the most effective safety techniques, such as post-response filtering, don’t require opening up the model at all, he said.\nHe also warns against what researchers call the “fallacy of inscrutability” — the idea that if we don’t fully understand a system’s internals, we can’t use or regulate it responsibly. In practice, full transparency isn’t how most technologies are evaluated. What matters is whether a system performs reliably under real conditions.\nThis isn’t the first time Amodei has warned about the risks of AI outpacing our understanding. In his October 2024\npost\n, “Machines of Loving Grace,” he sketched out a vision of increasingly capable models that could take meaningful real-world actions (and maybe double our lifespans).\nAccording to Kapoor, there’s an important distinction to be made here between a model’s\ncapability\nand its\npower\n. Model capabilities are undoubtedly increasing rapidly, and they may soon develop enough intelligence to find solutions for many complex problems challenging humanity today. But a model is only as powerful as the interfaces we provide it to interact with the real world, including where and how models are deployed.\nAmodei has separately argued that the U.S. should maintain a lead in AI development, in part through\nexport controls\nthat limit access to powerful models. The idea is that authoritarian governments might use frontier AI systems irresponsibly — or seize the geopolitical and economic edge that comes with deploying them first.\nFor Kapoor, “Even the biggest proponents of export controls agree that it will give us at most a year or two.” He thinks we should treat AI as a “\nnormal technology\n” like electricity or the internet. While revolutionary, it took decades for both technologies to be fully realized throughout society. Kapoor thinks it’s the same for AI: The best way to maintain geopolitical edge is to focus on the “long game” of transforming industries to use AI effectively.\nOthers critiquing Amodei\nKapoor isn’t the only one critiquing Amodei’s stance. Last week at VivaTech in Paris, Jansen Huang, CEO of Nvidia,\ndeclared his disagreement\nwith Amodei’s views. Huang questioned whether the authority to develop AI should be limited to a few powerful entities like Anthropic. He said: “If you want things to be done safely and responsibly, you do it in the open … Don’t do it in a dark room and tell me it’s safe.”\nIn response, Anthropic\nstated\n: “Dario has never claimed that ‘only Anthropic’ can build safe and powerful AI. As the public record will show, Dario has advocated for a national transparency standard for AI developers (including Anthropic) so the public and policymakers are aware of the models’ capabilities and risks and can prepare accordingly.”\nIt’s also worth noting that Anthropic isn’t alone in its pursuit of interpretability: Google’s DeepMind interpretability team, led by Neel Nanda, has also made\nserious contributions\nto interpretability research.\nUltimately, top AI labs and researchers are providing strong evidence that interpretability could be a key differentiator in the competitive AI market. Enterprises that prioritize interpretability early may gain a significant competitive edge by building more trusted, compliant, and adaptable AI systems.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nJust Released: 50 New Tickets for VB Transform 2025\nJoin top leaders June 24–25 in San Francisco to tackle real-world AI challenges, share what’s working, and shape what’s next. Claim your spot before they’re gone.\nLearn More\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.150932",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:14.360983",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 222 credits are required for this request."
  },
  {
    "id": "5fd5632c9641f7a289aefb20fc4609cb",
    "title": "Google launches production-ready Gemini 2.5 AI models to challenge OpenAI’s enterprise dominance",
    "url": "https://venturebeat.com/ai/google-launches-production-ready-gemini-2-5-ai-models-to-challenge-openais-enterprise-dominance/",
    "authors": "Michael Nuñez",
    "published_date": "2025-06-17T21:55:56+00:00",
    "source": "VentureBeat",
    "summary": "Google推出了Gemini 2.5 Pro和Flash AI模型，針對企業市場推出了成熟的產品，同時推出了成本效益高的Flash-Lite，挑戰OpenAI在企業領域的主導地位。這表示Google積極進軍AI市場，提供更多選擇給企業用戶，讓他們能夠更有效地應用人工智慧技術，提升業務效率。",
    "content": "Google launches production-ready Gemini 2.5 Pro and Flash AI models for enterprises while introducing cost-efficient Flash-Lite to challenge OpenAI's market dominance.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.197384",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:15.790763",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 243 credits are required for this request."
  },
  {
    "id": "d32ee4c1591554feca6d3878e6fc2d70",
    "title": "OpenAI moves forward with GPT-4.5 deprecation in API, triggering developer anguish and confusion",
    "url": "https://venturebeat.com/ai/openai-moves-forward-with-gpt-4-5-deprecation-in-api-triggering-developer-anguish-and-confusion/",
    "authors": "Carl Franzen",
    "published_date": "2025-06-17T21:52:29+00:00",
    "source": "VentureBeat",
    "summary": "OpenAI宣布停用GPT-4.5 API，讓開發者感到困惑和不滿，其實早在2025年4月就已經公告過這個計畫了。這個消息引起了相當大的反應，讓開發者感到焦慮和困惑。",
    "content": "Despite the strong reaction, OpenAI had in fact already announced the plan to deprecate GPT-4.5 Preview back in April 2025.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.300755",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:16.823578",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 180 credits are required for this request."
  },
  {
    "id": "a0995e8d9491841d5e03c527fc0cbe4f",
    "title": "Treehouse Games on how player feedback shaped Voyagers of Nera",
    "url": "https://venturebeat.com/game-development/treehouse-games-on-how-player-feedback-shaped-voyagers-of-nera/",
    "authors": "Rachel Kaser",
    "published_date": "2025-06-17T21:48:08+00:00",
    "source": "VentureBeat",
    "summary": "Treehouse Games的Michael Chu談到玩家如何幫助引導即將推出的遊戲《Voyagers of Nera》的開發。這篇新聞主要講述玩家的意見和反饋如何影響遊戲的發展，讓遊戲團隊更了解玩家的喜好和需求，進而打造出更符合玩家期待的遊戲作品。通过玩家的參與和回饋，遊戲可以更貼近玩家的心意，提升遊戲品質和玩家體驗。",
    "content": "Treehouse Games' Michael Chu talks about how players helped guide the development of upcoming title Voyagers of Nera.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.389402",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:18.187161",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 226 credits are required for this request."
  },
  {
    "id": "9607305c6fd4adabca305d1effe9b93b",
    "title": "Microsoft partners with AMD on next generation of Xbox",
    "url": "https://venturebeat.com/games/microsoft-partners-with-amd-on-next-generation-of-xbox/",
    "authors": "Dean Takahashi",
    "published_date": "2025-06-17T19:07:00+00:00",
    "source": "VentureBeat",
    "summary": "微軟宣布與AMD合作，共同打造下一代Xbox主機。這個合作讓兩家公司可以一起設計硅片，應用在未來的Xbox主機以及其他設備上。這代表未來的Xbox主機將會擁有更強大的處理器，讓玩家可以享受更流暢、更強大的遊戲體驗。這個消息讓玩家們對未來的遊戲主機更加期待。",
    "content": "Microsoft announced an agreement with AMD to co-engineer silicon across a portfolio of devices, including the next-generation Xbox consoles.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.522471",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:19.508200",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 183 credits are required for this request."
  },
  {
    "id": "c2a3edecf3f0957b7d7e55c6c24efc8e",
    "title": "Bungie delays Marathon indefinitely to rework most of its content",
    "url": "https://venturebeat.com/games/bungie-delays-marathon-indefinitely-to-rework-most-of-its-content/",
    "authors": "Rachel Kaser",
    "published_date": "2025-06-17T18:41:29+00:00",
    "source": "VentureBeat",
    "summary": "遊戲公司Bungie宣布將射擊遊戲《Marathon》的發售日期從原定的9月23日延後，並且沒有確定新的發售日期。開發團隊在部落格中透露，這個決定是基於遊戲Alpha測試玩家的回饋。公司表示將會隨後公布新的發售日期。",
    "content": "Bungie announced today that it is delaying upcoming shooter Marathon from its September 23 release date, with no new date announced. The development team revealed in a blog post that it has taken this step after player feedback from the game&#8217;s alpha test. The company says it will update fans with a new release date&#160;[&#8230;]",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.660334",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:20.797711",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 174 credits are required for this request."
  },
  {
    "id": "8c989791947dc9db200d7ab6f5a486e6",
    "title": "Bruno Mars headlines Fortnite Festival Season 9",
    "url": "https://venturebeat.com/games/bruno-mars-headlines-fortnite-festival-season-9/",
    "authors": "Rachel Kaser",
    "published_date": "2025-06-17T17:51:27+00:00",
    "source": "VentureBeat",
    "summary": "《Fortnite》揭露了下一季的音樂節主角：Bruno Mars，他將帶來多款新的虛擬服飾。這意味著在遊戲中，玩家可以透過Bruno Mars的形象來打造自己的角色，增加遊戲的樂趣和多樣性。這次的消息讓許多玩家期待不已，準備迎接新的遊戲體驗和風格。",
    "content": "Fortnite has revealed the Icon for the next season of Fortnite Festival: Bruno Mars, who joins with several new cosmetics.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.705839",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:22.433513",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 173 credits are required for this request."
  },
  {
    "id": "d45bfc3483022b328b8972cd2b983021",
    "title": "How Disney is using Unreal Engine 5 to add major upgrades to Millennium Falcon: Smugglers Run",
    "url": "https://venturebeat.com/game-development/how-disney-is-using-unreal-engine-5-to-add-major-upgrades-to-millennium-falcon-smugglers-run/",
    "authors": "Giancarlo Valdes",
    "published_date": "2025-06-17T16:21:05+00:00",
    "source": "VentureBeat",
    "summary": "迪士尼正在運用Unreal Engine 5技術對千禧鷹號：走私者之路進行重大升級，這個遊樂設施在2019年開幕時曾是華特迪士尼幻想工程的里程碑。這意味著未來遊客將能夠在更加逼真的虛擬世界中體驗飛行千禧鷹號的刺激。Disney的這項舉措將為遊客帶來更加震撼的遊樂體驗，讓他們彷彿置身於星際大戰的世界中。",
    "content": "Millennium Falcon: Smugglers Run was a landmark moment for Walt Disney Imagineering when it opened in 2019.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.795108",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:24.036083",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 245 credits are required for this request."
  },
  {
    "id": "d277e3c1345d7fb1dca5a216923f3f4f",
    "title": "Team Liquid partners with Zenni Optical on eye health and gamer performance",
    "url": "https://venturebeat.com/games/team-liquid-partners-with-zenni-optical-on-eye-health-and-gamer-performance/",
    "authors": "Dean Takahashi",
    "published_date": "2025-06-17T16:00:00+00:00",
    "source": "VentureBeat",
    "summary": "Team Liquid與Zenni Optical合作，成為官方眼鏡夥伴，關注眼睛健康與玩家表現。這個合作讓玩家可以獲得專業的眼鏡支援，提升遊戲時的視覺品質，同時也重視眼睛健康。這對於電競選手來說是一個很貼心的舉措，讓他們在比賽中能夠更專注、更舒適地發揮實力。",
    "content": "Global esports company Team Liquid announced a new partnership with Zenni Optical, naming the leading online retailer as its official eyewear partner.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-18T08:50:45.853894",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-18T08:51:25.388312",
    "audio_error": "This request exceeds your quota of 30078. You have 91 credits remaining, while 206 credits are required for this request."
  }
]