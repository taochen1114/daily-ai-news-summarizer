[
  {
    "id": "731ed7563df839b896691dd180577990",
    "title": "How Capital One built production multi-agent AI workflows to power enterprise use cases",
    "url": "https://venturebeat.com/ai/how-capital-one-built-production-multi-agent-ai-workflows-to-power-enterprise-use-cases/",
    "authors": "VB Staff",
    "published_date": "2025-07-07T14:50:00+00:00",
    "source": "VentureBeat",
    "summary": "Capital One運用多智能體人工智慧工作流程，強化企業應用案例，提供更好的客戶體驗。他們建立了一個系統，讓多個AI智能體協同工作，不僅提供資訊給買車客戶，還根據客戶需求採取具體行動。這個系統能處理超過1億名客戶的需求，為客戶提供更完善的服務。這項創新技術展示了如何在業務中平衡風險管理、創新和客戶滿意度。",
    "content": "How Capital One built production multi-agent AI workflows to power enterprise use cases | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nVB Event\nHow Capital One built production multi-agent AI workflows to power enterprise use cases\nVB Staff\nJuly 7, 2025 7:50 AM\nShare on Facebook\nShare on X\nShare on LinkedIn\nEmilia David, Milind Naphade,\nHow do you balance risk management and safety with innovation in agentic systems — and how do you grapple with core considerations around data and model selection? In this\nVB Transform\nsession, Milind Naphade, SVP, technology, of AI Foundations at Capital One, offered best practices and lessons learned from real-world experiments and applications for deploying and scaling an agentic workflow.\nCapital One, committed to staying at the forefront of emerging technologies, recently launched a production-grade, state-of-the-art multi-agent AI system to enhance the car-buying experience. In this system, multiple AI agents work together to not only provide information to the car buyer, but to take specific actions based on the customer’s preferences and needs. For example, one agent communicates with the customer. Another creates an action plan based on business rules and the tools it is allowed to use. A third agent evaluates the accuracy of the first two, and a fourth agent explains and validates the action plan with the user. With over 100 million customers using a wide range of other potential Capital One use case applications, the agentic system is built for scale and complexity.\n“When we think of improving the customer experience, delighting the customer, we think of, what are the ways in which that can happen?” Naphade said. “Whether you’re opening an account or you want to know your balance or you’re trying to make a reservation to test a vehicle, there are a bunch of things that customers want to do. At the heart of this, very simply, how do you understand what the customer wants? How do you understand the fulfillment mechanisms at your disposal? How do you bring all the rigors of a regulated entity like Capital One, all the policies, all the business rules, all the constraints, regulatory and otherwise?”\nAgentic AI was clearly the next step, he said, for internal as well as customer-facing use cases.\nDesigning an agentic workflow\nFinancial institutions have particularly stringent requirements when designing any workflow that supports customer journeys. And Capital One’s applications include a number of complex processes as customers raise issues and queries leveraging conversational tools. These two factors made the design process especially complex, requiring a holistic view of the entire journey — including how both customers and human agents respond, react, and reason at every step.\n“When we looked at how humans do reasoning, we were struck by a few salient facts,” Naphade said. “We saw that if we designed it using multiple logical agents, we would be able to mimic human reasoning quite well. But then you ask yourself, what exactly do the different agents do? Why do you have four? Why not three? Why not 20?”\nThey studied customer experiences in the historic data: where those conversations go right, where they go wrong, how long they should take and other salient facts. They learned that it often takes multiple turns of conversation with an agent to understand what the customer wants, and any agentic workflow needs to plan for that, but also be completely grounded in an organization’s systems, available tools, APIs, and organizational policy guardrails.\n“The main breakthrough for us was realizing that this had to be dynamic and iterative,” Naphade said. “If you look at how a lot of people are using LLMs, they’re slapping the LLMs as a front end to the same mechanism that used to exist. They’re just using LLMs for classification of intent. But we realized from the beginning that that was not scalable.”\nTaking cues from existing workflows\nBased on their intuition of how human agents reason while responding to customers, researchers at Capital One developed  a framework in which  a team of expert AI agents, each with different expertise, come together and solve a problem.\nAdditionally, Capital One incorporated robust risk frameworks into the development of the agentic system. As a regulated institution, Naphade noted that in addition to its range of internal risk mitigation protocols and frameworks,”Within Capital One, to manage risk, other entities that are independent observe you, evaluate you, question you, audit you,” Naphade said. “We thought that was a good idea for us, to have an AI agent whose entire job was to evaluate what the first two agents do based on Capital One policies and rules.”\nThe evaluator determines whether the earlier agents were successful, and if not, rejects the plan and requests the planning agent to correct its results based on its judgement of where the problem was. This happens in an iterative process until the appropriate plan is reached. It’s also proven to be a huge boon to the company’s agentic AI approach.\n“The evaluator agent is … where we bring a world model. That’s where we simulate what happens if a series of actions were to be actually executed. That kind of rigor, which we need because we are a regulated enterprise – I think that’s actually putting us on a great sustainable and robust trajectory. I expect a lot of enterprises will eventually go to that point.”\nThe technical challenges of agentic AI\nAgentic systems need to work with fulfillment systems across the organization, all with a variety of permissions. Invoking tools and APIs within a variety of contexts while maintaining high accuracy was also challenging — from disambiguating user intent to generating and executing a reliable plan.\n“We have multiple iterations of experimentation, testing, evaluation, human-in-the-loop, all the right guardrails that need to happen before we can actually come into the market with something like this,” Naphade said. “But one of the biggest challenges was we didn’t have any precedent. We couldn’t go and say, oh, somebody else did it this way. How did that work out? There was that element of novelty. We were doing it for the first time.”\nModel selection and partnering with NVIDIA\nIn terms of models, Capital One is keenly tracking academic and industry research, presenting at conferences and staying abreast of what’s state of the art. In the present use case, they used open-weights models, rather than closed, because that allowed them significant customization. That’s critical to them, Naphade asserts, because competitive advantage in AI strategy relies on proprietary data.\nIn the technology stack itself, they use a combination of tools, including in-house technology, open-source tool chains, and NVIDIA inference stack. Working closely with NVIDIA has helped Capital One get the performance they need, and collaborate on industry-specific  opportunities in NVIDIA’s library, and prioritize features for the Triton server and their TensoRT LLM.\nAgentic AI: Looking ahead\nCapital One continues to deploy, scale, and refine AI agents across their business. Their first multi-agentic workflow was Chat Concierge, deployed through the company’s auto business. It was designed to support both auto dealers and customers with the car-buying process.  And with rich customer data, dealers are identifying serious leads, which has improved their customer engagement metrics significantly — up to 55% in some cases.\n“They’re able to generate much better serious leads through this natural, easier, 24/7 agent working for them,” Naphade said. “We’d like to bring this capability to [more] of our customer-facing engagements. But we want to do it in a well-managed way. It’s a journey.”\nThe Briefing for Tech Decision-Makers\nStay ahead in AI, data, and security with VB Daily—trusted by 100K+ industry leaders.\nSubscribe Here\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-07T23:52:21.194288",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-07T23:52:25.381567",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/731ed7563df839b896691dd180577990.mp3",
    "audio_file": "audio/articles/731ed7563df839b896691dd180577990.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-07-07T23:52:40.360420",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "1e6dc0db4b93d6437117b38381419aa3",
    "title": "Cracking AI’s storage bottleneck and supercharging inference at the edge",
    "url": "https://venturebeat.com/ai/cracking-ais-storage-bottleneck-and-supercharging-inference-at-the-edge/",
    "authors": "VB Staff",
    "published_date": "2025-07-07T12:50:00+00:00",
    "source": "VentureBeat",
    "summary": "這篇新聞講的是如何解決AI在資料儲存上的瓶頸問題，並在邊緣端加速推論運算。透過創新的儲存技術，企業可以更有效運用AI，尤其在醫療影像等領域。一個名為MONAI的醫學影像框架，透過先進的儲存技術，成功儲存了超過兩百萬張全身CT掃描影像。這顯示出隨著企業AI基礎設施的快速演進，儲存硬體需根據不同的使用情境進行調整，以確保效能和效率。",
    "content": "Cracking AI’s storage bottleneck and supercharging inference at the edge | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nVB Event\nCracking AI’s storage bottleneck and supercharging inference at the edge\nVB Staff\nJuly 7, 2025 5:50 AM\nShare on Facebook\nShare on X\nShare on LinkedIn\nGreg Matson, Roger Cummings, Michael Stewart\nWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\nSubscribe Now\nAs AI applications increasingly permeate enterprise operations, from enhancing patient care through advanced medical imaging to powering complex fraud detection models and even aiding wildlife conservation, a critical bottleneck often emerges: data storage.\nDuring VentureBeat’s\nTransform 2025\n, Greg Matson, head of products and marketing, Solidigm and Roger Cummings, CEO of PEAK:AIO spoke with Michael Stewart, managing partner at M12 about how innovations in storage technology enables enterprise AI use cases in healthcare.\nThe MONAI framework is a breakthrough in medical imaging, building it faster, more safely, and more securely. Advances in storage technology is what enables researchers to build on top of this framework, iterate and innovate quickly. PEAK:AIO partnered with Solidgm to integrate power-efficient, performant, and high-capacity storage which enabled MONAI to store more than two million full-body CT scans on a single node within their IT environment.\n“As enterprise AI infrastructure evolves rapidly, storage hardware increasingly needs to be tailored to specific use cases, depending on where they are in the AI data pipeline,” Matson said. “The type of use case we talked about with MONAI, an edge-use case, as well as the feeding of a training cluster, are well served by very high-capacity solid-state storage solutions, but the actual inference and model training need something different. That’s a very high-performance, very high I/O-per-second requirement from the SSD. For us, RAG is bifurcating the types of products that we make and the types of integrations we have to make with the software.”\nImproving AI inference at the edge\nFor peak performance at the edge, it’s critical to scale storage down to a single node, in order to bring inference closer to the data. And what’s key is removing memory bottlenecks. That can be done by making memory a part of the AI infrastructure, in order to scale it along with data and metadata. The proximity of data to compute dramatically increases the time to insight.\n“You see all the huge deployments, the big green field data centers for AI, using very specific hardware designs to be able to bring the data as close as possible to the GPUs,” Matson said. “They’ve been building out their data centers with very high-capacity solid-state storage, to bring petabyte-level storage, very accessible at very high speeds, to the GPUs. Now, that same technology is happening in a microcosm at the edge and in the enterprise.”\nIt’s becoming critical to purchasers of AI systems to ensure you’re getting the most performance out of your system by running it on all solid state. That allows you to bring huge amounts of data, and enables incredible processing power in a small system at the edge.\nThe future of AI hardware\n“It’s imperative that we provide solutions that are open, scalable, and at memory speed, using some of the latest and greatest technology out there to do that,” Cummings said. “That’s our goal as a company, to provide that openness, that speed, and the scale that organizations need. I think you’re going to see the economies match that as well.”\nFor the overall training and inference data pipeline, and within inference itself, hardware needs will keep increasing, whether it’s a very high-speed SSD or a very high-capacity solution that’s power efficient.\n“I would say it’s going to move even further toward very high-capacity, whether it’s a one-petabyte SSD out a couple of years from now that runs at very low power and that can basically replace four times as many hard drives, or a very high-performance product that’s almost near memory speeds,” Matson said. “You’ll see that the big GPU vendors are looking at how to define the next storage architecture, so that it can help augment, very closely, the HBM in the system. What was a general-purpose SSD in cloud computing is now bifurcating into capacity and performance. We’ll keep doing that further out in both directions over the next five or 10 years.”\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nThe Briefing for Tech Decision-Makers\nStay ahead in AI, data, and security with VB Daily—trusted by 100K+ industry leaders.\nSubscribe Here\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-07T23:52:21.424356",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-07T23:52:30.388117",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/1e6dc0db4b93d6437117b38381419aa3.mp3",
    "audio_file": "audio/articles/1e6dc0db4b93d6437117b38381419aa3.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-07-07T23:52:48.408183",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "9ee81605a1397cc2f0d923fe7f63458b",
    "title": "Test2",
    "url": "https://venturebeat.com/business/test2/",
    "authors": "egolovacheva",
    "published_date": "2025-07-07T11:14:44+00:00",
    "source": "VentureBeat",
    "summary": "這則新聞主要介紹了VentureBeat的AI相關內容，包括人工智慧、機器學習、深度學習等議題。文章提到了AI在商業應用上的價值，特別是生成式AI的應用及實際部署。VentureBeat提供了每日商業用例的洞察，讓讀者能夠了解公司如何運用AI技術，從而分享洞察以獲取最大的投資回報。",
    "content": "Test2 | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nTest2\negolovacheva\nJuly 7, 2025 4:14 AM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCredit: VentureBeat made with Midjourney\nTest 2 tets 2 test 2\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe insights you need without the noise\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-07T23:52:21.649472",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-07T23:52:33.257248",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/9ee81605a1397cc2f0d923fe7f63458b.mp3",
    "audio_file": "audio/articles/9ee81605a1397cc2f0d923fe7f63458b.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-07-07T23:52:55.426172",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  }
]