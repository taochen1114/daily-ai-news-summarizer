[
  {
    "id": "281948568c3da2cc71eae81959fc9a70",
    "title": "Hugging Face just launched a $299 robot that could disrupt the entire robotics industry",
    "url": "https://venturebeat.com/ai/hugging-face-just-launched-a-299-robot-that-could-disrupt-the-entire-robotics-industry/",
    "authors": "Michael Nuñez",
    "published_date": "2025-07-09T07:00:00+00:00",
    "source": "VentureBeat",
    "summary": "Hugging Face推出了售價299美元的機器人Reachy Mini，旨在讓AI機器人開發變得更容易且平民化，挑戰傳統高成本的封閉式模式。這款11英吋的桌上型機器人可坐在任何桌子上，解決了機器人開發中的可及性問題。這是Hugging Face自創立以來最重要的硬體擴展，也是該公司對機器人領域的大膽嘗試。",
    "content": "Hugging Face just launched a $299 robot that could disrupt the entire robotics industry | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nHugging Face just launched a $299 robot that could disrupt the entire robotics industry\nMichael Nuñez\n@MichaelFNunez\nJuly 9, 2025 12:00 AM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCredit: VentureBeat made with Midjourney\nWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\nSubscribe Now\nHugging Face\n, the $4.5 billion artificial intelligence platform that has become the GitHub of machine learning, announced Tuesday the launch of\nReachy Mini\n, a $299 desktop robot designed to bring AI-powered robotics to millions of developers worldwide. The 11-inch humanoid companion represents the company’s boldest move yet to democratize robotics development and challenge the industry’s traditional closed-source, high-cost model.\nThe announcement comes as Hugging Face crosses a significant milestone of 10 million AI builders using its platform, with CEO Clément Delangue revealing in an exclusive interview that “more and more of them are building in relation to robotics.” The compact robot, which can sit on any desk next to a laptop, addresses what Delangue calls a fundamental barrier in robotics development: accessibility.\n“One of the challenges with robotics is that you know you can’t just build on your laptop. You need to have some sort of robotics partner to help in your building, and most people won’t be able to buy $70,000 robots,” Delangue explained, referring to traditional industrial robotics systems and even newer humanoid robots like Tesla’s Optimus, which is expected to cost $20,000-$30,000.\nHow a software company is betting big on physical AI robots\nReachy Mini\nemerges from Hugging Face’s April acquisition of French robotics startup\nPollen Robotics\n, marking the company’s most significant hardware expansion since its founding. The robot represents the first consumer product to integrate natively with the\nHugging Face Hub\n, allowing developers to access thousands of pre-built AI models and share robotics applications through the platform’s “\nSpaces\n” feature.\nThe timing appears deliberate as the AI industry grapples with the next frontier: physical AI. While large language models have dominated the past two years, industry leaders increasingly believe that artificial intelligence will need physical embodiment to achieve human-level capabilities.\nGoldman Sachs\nprojects the humanoid robotics market could reach $38 billion by 2035, while the\nWorld Economic Forum\nidentifies robotics as a critical frontier technology for industrial operations.\n“We’re seeing more and more people moving to robotics, which is extremely exciting,” Delangue said. “The idea is to really become the desktop, open-source robot for AI builders.”\nInside the $299 robot that could democratize AI development\nReachy Mini\npacks sophisticated capabilities into its compact form factor. The robot features six degrees of freedom in its moving head, full body rotation, animated antennas, a wide-angle camera, multiple microphones, and a 5-watt speaker. The wireless version includes a\nRaspberry Pi 5\ncomputer and battery, making it fully autonomous.\nThe robot ships as a DIY kit and can be programmed in Python, with JavaScript and Scratch support planned. Pre-installed demonstration applications include face and hand tracking, smart companion features, and dancing moves. Developers can create and share new applications through Hugging Face’s Spaces platform, potentially creating what Delangue envisions as “thousands, tens of thousands, millions of apps.”\nThis approach contrasts sharply with traditional robotics companies that typically release one product annually with limited customization options. “We want to have a model where we release tons of things,” Delangue explained. “Maybe we’ll release 100 prototypes a year. Out of this 100 prototypes, maybe we’ll assemble only 10 ourselves… and maybe fully assembled, fully packaged, fully integrated with all the software stack, maybe there’s going to be just a couple of them.”\nWhy open source hardware might be the future of robotics\nThe launch represents a fascinating test of whether open-source principles can translate successfully to hardware businesses.\nHugging Face\nplans to release all hardware designs, software, and assembly instructions as open source, allowing anyone to build their own version. The company monetizes through convenience, selling pre-assembled units to developers who prefer to pay rather than build from scratch.\n“You try to share as much as possible to really empower the community,” Delangue explained. “There are people who, even if they have all the recipes open source to build their own Reachy Mini, would prefer to pay 300 bucks, 500 bucks, and get it already ready, or easy to assemble at home.”\nThis freemium approach for hardware echoes successful software models but faces unique challenges. Manufacturing costs, supply chain complexity, and physical distribution create constraints that don’t exist in pure software businesses. However, Delangue argues this creates valuable feedback loops: “You learn from the open source community about what they want to build, how they want to build, and you can reintegrate it into what you sell.”\nThe privacy challenge facing AI robots in your home\nThe move into robotics raises new questions about data privacy and security that don’t exist with purely digital AI systems. Robots equipped with cameras, microphones, and the ability to take physical actions in homes and workplaces create unprecedented privacy considerations.\nDelangue positions open source as the solution to these concerns. “One of my personal motivations to do open source robotics is that I think it’s going to fight concentration of power… the natural tendency of creating black box robots that users don’t really understand or really control,” he said. “The idea of ending up in a world where just a few companies are controlling millions of robots that are in people’s homes, being able to take action in real life, is quite scary.”\nThe open-source approach allows users to inspect code, understand data flows, and potentially run AI models locally rather than relying on cloud services. For enterprise customers, Hugging Face’s existing enterprise platform could provide private deployment options for robotics applications.\nFrom prototype to production: Hugging Face’s manufacturing gamble\nHugging Face faces significant manufacturing and scaling challenges as it transitions from a software platform to a hardware company. The company plans to begin shipping Reachy Mini units as early as next month, starting with more DIY-oriented versions where customers complete final assembly.\n“The first versions, the first orders shipping will be a bit DIY, in the sense that we’ll split the weight of assembling with the user,” Delangue explained. “We’ll do some of the assembling ourselves, and then the user will be doing some of the assembling themselves too.”\nThis approach aligns with the company’s goal of engaging the AI builder community in hands-on robotics development while managing manufacturing complexity. The strategy also reflects uncertainty about market demand for the new product category.\nTaking on Tesla and Boston Dynamics with radical transparency\nReachy Mini enters a rapidly evolving robotics landscape.\nTesla’s Optimus program\n,\nFigure’s humanoid robots\n, and\nBoston Dynamics\n‘ commercial offerings represent the high-end of the market, while companies like\nUnitree\nhave introduced more affordable humanoid robots at around $16,000.\nHugging Face’s approach differs fundamentally from these competitors. Rather than creating a single, highly capable robot, the company is building an ecosystem of affordable, modular, open-source robotics components. Previous releases include the\nSO-101 robotic arm\n(starting at $100) and plans for the\nHopeJR humanoid robot\n(around $3,000).\nThe strategy reflects broader trends in AI development, where open-source models from companies like Meta and smaller players have challenged closed-source leaders like OpenAI. In January, Chinese startup DeepSeek shocked the industry by releasing a powerful AI model developed at significantly lower cost than competing systems, demonstrating the potential for open-source approaches to disrupt established players.\nBuilding an ecosystem: The partnerships powering open robotics\nHugging Face’s robotics expansion benefits from strategic partnerships across the industry. The company collaborates with\nNVIDIA on robotics simulation\nand training through Isaac Lab, enabling developers to generate synthetic training data and test robot behaviors in virtual environments before deployment.\nThe recent release of\nSmolVLA\n, a 450-million parameter vision-language-action model, demonstrates the technical foundation underlying Reachy Mini. The model is designed to be efficient enough to run on consumer hardware, including MacBooks, making sophisticated AI capabilities accessible to individual developers rather than requiring expensive cloud infrastructure.\nPhysical Intelligence\n, a startup co-founded by UC Berkeley professor Sergey Levine, has made its\nPi0 robot foundation model\navailable through Hugging Face, creating opportunities for cross-pollination between different robotics approaches. “Making robotics more accessible increases the velocity with which technology advances,” Levine noted in previous statements about open-source robotics.\nWhat a $299 robot means for the billion-dollar AI hardware race\nThe\nReachy Mini\nlaunch signals Hugging Face’s ambition to become the dominant platform for AI development across all modalities, not just text and image generation. With robotics representing a potential $38 billion market by 2035, according to\nGoldman Sachs projections\n, early platform positioning could prove strategically valuable.\nDelangue envisions a future where hardware becomes an integral part of AI development workflows. “We see hardware as part of the AI builder building blocks,” he explained. “Always with our approach of being open, being community driven, integrating everything with as many community members, as many other organizations as possible.”\nThe company’s financial position provides flexibility to experiment with hardware business models. As a profitable company with significant funding,\nHugging Face\ncan afford to prioritize market development over immediate revenue optimization. Delangue mentioned potential subscription models where Hugging Face platform access could include hardware components, similar to how some software companies bundle services.\nHow affordable robots could transform education and research\nBeyond commercial applications,\nReachy Mini\ncould significantly impact robotics education and research. At $299, the robot costs less than many smartphones while providing full programmability and AI integration. Universities, coding bootcamps, and individual learners could use the platform to explore robotics concepts without requiring expensive laboratory equipment.\nThe open-source nature enables educational institutions to modify hardware and software to suit specific curricula. Students could progress from basic programming exercises to sophisticated AI applications using the same platform, potentially accelerating robotics education and workforce development.\nDelangue revealed that community feedback has already influenced product development. A colleague’s five-year-old daughter wanted to carry the robot around the house, leading to the development of the wireless version. “She started to want to take the Reachy Mini and bring it everywhere. That’s when the wires started to be a problem,” he explained.\nThe disruption that could reshape the entire robotics industry\nHugging Face’s approach could fundamentally alter robotics industry dynamics. Traditional robotics companies invest heavily in proprietary technology, limiting innovation to internal teams. The open-source model could unlock distributed innovation across thousands of developers, potentially accelerating advancement while reducing costs.\nThe strategy mirrors successful disruptions in other technology sectors. Linux challenged proprietary operating systems, Android democratized mobile development, and TensorFlow accelerated machine learning adoption. If successful, Hugging Face’s robotics platform could follow a similar trajectory.\nHowever, hardware presents unique challenges compared to software. Manufacturing quality control, supply chain management, and physical safety requirements create complexity that doesn’t exist in purely digital products. The company’s ability to manage these challenges while maintaining its open-source philosophy will determine the platform’s long-term success.\nWhether Reachy Mini succeeds or fails, its launch marks a pivotal moment in robotics development. For the first time, a major AI platform is betting that the future of robotics belongs not in corporate research labs, but in the hands of millions of individual developers armed with affordable, open-source tools. In an industry long dominated by secrecy and six-figure price tags, that might just be the most revolutionary idea of all.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nThe Briefing for Tech Decision-Makers\nStay ahead in AI, data, and security with VB Daily—trusted by 100K+ industry leaders.\nSubscribe Here\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-09T15:52:07.123980",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-09T15:52:25.923801",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/281948568c3da2cc71eae81959fc9a70.mp3",
    "audio_file": "audio/articles/281948568c3da2cc71eae81959fc9a70.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-07-09T15:53:32.674704",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "043eb2d72fa9942d6e933b49b3368acf",
    "title": "MCP isn’t KYC-ready: Why regulated sectors are wary of open agent exchanges",
    "url": "https://venturebeat.com/ai/mcp-isnt-kyc-ready-why-regulated-sectors-are-wary-of-open-agent-exchanges/",
    "authors": "Emilia David",
    "published_date": "2025-07-08T23:33:17+00:00",
    "source": "VentureBeat",
    "summary": "這篇新聞講的是一個叫MCP的系統，雖然吸引了很多使用者，但金融等受監管的行業還是對它持保留態度。這些公司擔心MCP和A2A對他們的合規性和安全性造成風險。雖然許多公司已經在內部使用AI，但要整合MCP還需要花時間確保合規性。簡單來說，MCP雖然受歡迎，但對於受監管的行業來說，還有一些問題需要解決。",
    "content": "MCP isn’t KYC-ready: Why regulated sectors are wary of open agent exchanges | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nFeature\nMCP isn’t KYC-ready: Why regulated sectors are wary of open agent exchanges\nEmilia David\n@miyadavid\nJuly 8, 2025 4:33 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCredit: VentureBeat, generated with MidJourney\nWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\nSubscribe Now\nFor something launched in November, the\nModel Context Protocol (MCP)\nhas begun\namassing a large number of users\n, all but guaranteeing the mass adoption needed to make it an industry standard.\nBut there is a subset of enterprises that are not joining the hype for now: regulated industries, especially financial institutions.\nBanks and other enterprises offering access to loans and financial solutions are not strangers to AI. Many have been pioneers in machine learning and algorithms, even playing an essential role in making the idea of investing using robots extremely popular. However, it doesn’t mean financial services companies want to jump into the MCP and\nAgent2Agent (A2A)\nbandwagon immediately.\nWhile many regulated companies, such as banks, financial institutions, and hospitals, have begun experimenting with AI agents, these are typically internal agents. Regulated companies do have APIs. Still, so much of the integration these companies undertake has taken years of vetting to ensure compliance and safety.\n“It’s very early days in a quickly accelerating domain, but there are some fundamental building blocks that are missing, at least as standards or best practices related to interoperability and communication,” said Sean Neville, cofounder of\nCatena Labs\n. “In the early days of the web, there was no e-commerce because there was no HTTPS, and no way to transact securely, so you can’t build Amazon. You need these basic building blocks in place, and now those building blocks on the web exist, and we don’t even think about them.”\nIncreasingly, enterprises and AI platform providers are establishing\nMCP servers\nas they develop multi-agent systems that interact with agents from external sources. MCP provides the ability to identify an agent, allowing a server to determine the tools and data it has access to. However, many financial institutions want more assurance that they can control the integration and ensure only approved tasks, tools, and information are shared.\nJohn Waldron, senior vice president at\nElavon\n, a subsidiary of\nU.S. Bank\n, told VentureBeat in an interview that while they are exploring the use of MCP, there are a lot of questions around the standard.\n“There are not a lot of standard solutions emerging, so we are still exploring a lot of ways to do that, including maybe doing that connection without an MCP exchange if the agent technology is common between the two and it’s just two different domains,” Waldron said. “But, what is the traceability of the data exchange without another exposure in that message? A lot of what’s happening within MCP evaluation right now is figuring out if the protocol is just handling the exchange and doesn’t provide any further risk leakage. If it is, then it’s a viable path we’ll explore for handling that exchange.”\nModels and agents are different\nFinancial institutions and other regulated businesses are no strangers to AI models. After all, much of passive investing grew when roboadvisers—where algorithms made decisions on financial planning and investments with little to no human intervention—became popular. Many banks and asset managers invested early in natural language processing to enhance document analysis efficiency.\nHowever,\nSalesforce\nVice President and General Manager of Banking Industry Solutions and Strategy, Greg Jacobi, told VentureBeat that some of their financial clients already have a process in place to assess models, and they’re finding it challenging to integrate AI models and agents with their current risk scenarios.\n“Machine learning and predictive models fit pretty well with that risk framework because they’re deterministic and predictable,” Jacobi said. “These firms immediately take LLMs to their model risk committees and found that LLMs produce a non-deterministic outcome. That’s been an existential crisis for these financial services firms.”\nJacobi said these companies have risk management frameworks where, if they give inputs to models, they expect the same output every time. Any variances are considered an issue, so they require a method for quality control. And while regulated companies have embraced APIs, with all the testing involved there, most regulated entities “are afraid of openness, of putting out something so public-facing” that they cannot control.\nElavon’s Waldron, however, doesn’t discount the possibility that financial institutions may work towards supporting MCP or A2A in the future.\n“Looking at it from a business perspective and demand, I think MCP is a very critical part of where I think the business logic is going,” he said.\nWaldron said his team remains in the evaluation stage and “we haven’t built a server for pilot purposes yet, but we’re going to see how to handle that bot-to-bot exchange of messages.”\nAgents can’t KYC another agent\nCatena Lab’s Neville said he is watching the conversation around interoperability protocols like MCP and A2A with great interest, especially since he believes that in the future, AI agents will be as much of a customer for banks as human consumers. Before starting Catena Labs, Neville cofounded Circle, the company that established the USDC stablecoin, so he has firsthand experience with the challenges of bringing new technology to a regulated business.\nSince MCP is open source and new, it is still\nundergoing constant updates\n. Neville said that while MCP offers agent identification, which is key for many companies, there are still some missing features, such as guardrails for communication and, most importantly, an audit trail. These issues could either be solved through MCP, A2A or even an entirely\ndifferent standard like LOKA\n.\nHe said one of the biggest problems with the current MCP revolves around authentication. When agents become part of the financial system, even MCP or A2A, there’s no real way to do “know-your-customer” on agents. Neville said financial institutions need to know that their agents are dealing with licensed entities, so the agent must be able to point to that verifiably.\n“There needs to be a way for an agent to say, ‘this is who I am as an agent, here’s my identity, my risk and who I am operating on behalf of.’ That verifiable identity in a way all these different agentic frameworks can understand would be key.”\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nThe Briefing for Tech Decision-Makers\nStay ahead in AI, data, and security with VB Daily—trusted by 100K+ industry leaders.\nSubscribe Here\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-09T15:52:07.410860",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-09T15:52:29.547990",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/043eb2d72fa9942d6e933b49b3368acf.mp3",
    "audio_file": "audio/articles/043eb2d72fa9942d6e933b49b3368acf.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-07-09T15:53:44.771543",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "369f0ce43027de69dde211c2d74078b7",
    "title": "Chinese researchers unveil MemOS, the first ‘memory operating system’ that gives AI human-like recall",
    "url": "https://venturebeat.com/ai/chinese-researchers-unveil-memos-the-first-memory-operating-system-that-gives-ai-human-like-recall/",
    "authors": "Michael Nuñez",
    "published_date": "2025-07-08T21:57:16+00:00",
    "source": "VentureBeat",
    "summary": "中國研究人員發表了MemOS，這是首個「記憶操作系統」，讓人工智慧具有類似人類記憶的能力。這項創新解決了AI系統長期記憶和學習的限制，讓AI能像人類一樣管理記憶資源，並在時間推理任務中表現出159%的性能提升。這項研究有助於加速人工智慧向更接近人類思維的方向發展。",
    "content": "Chinese researchers unveil MemOS, the first 'memory operating system' that gives AI human-like recall | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nChinese researchers unveil MemOS, the first ‘memory operating system’ that gives AI human-like recall\nMichael Nuñez\n@MichaelFNunez\nJuly 8, 2025 2:57 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCredit: VentureBeat made with Midjourney\nWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\nSubscribe Now\nA team of researchers from leading institutions including\nShanghai Jiao Tong University\nand\nZhejiang University\nhas developed what they’re calling the first “memory operating system” for artificial intelligence, addressing a fundamental limitation that has hindered AI systems from achieving human-like persistent memory and learning.\nThe system, called\nMemOS\n, treats memory as a core computational resource that can be scheduled, shared, and evolved over time — much like how traditional operating systems manage CPU and storage resources. The research,\npublished July 4th on arXiv\n, demonstrates significant performance improvements over existing approaches, including a 159% boost in temporal reasoning tasks compared to OpenAI’s memory systems.\n“Large Language Models (LLMs) have become an essential infrastructure for Artificial General Intelligence (AGI), yet their lack of well-defined memory management systems hinders the development of long-context reasoning, continual personalization, and knowledge consistency,” the researchers write in\ntheir paper\n.\nAI systems struggle with persistent memory across conversations\nCurrent AI systems face what researchers call the “\nmemory silo\n” problem — a fundamental architectural limitation that prevents them from maintaining coherent, long-term relationships with users. Each conversation or session essentially starts from scratch, with models unable to retain preferences, accumulated knowledge, or behavioral patterns across interactions. This creates a frustrating user experience where an AI assistant might forget a user’s dietary restrictions mentioned in one conversation when asked about restaurant recommendations in the next.\nWhile some solutions like\nRetrieval-Augmented Generation (RAG)\nattempt to address this by pulling in external information during conversations, the researchers argue these remain “stateless workarounds without lifecycle control.” The problem runs deeper than simple information retrieval — it’s about creating systems that can genuinely learn and evolve from experience, much like human memory does.\n“Existing models mainly rely on static parameters and short-lived contextual states, limiting their ability to track user preferences or update knowledge over extended periods,” the team explains. This limitation becomes particularly apparent in enterprise settings, where AI systems are expected to maintain context across complex, multi-stage workflows that might span days or weeks.\nNew system delivers dramatic improvements in AI reasoning tasks\nMemOS\nintroduces a fundamentally different approach through what the researchers call “\nMemCubes\n” — standardized memory units that can encapsulate different types of information and be composed, migrated, and evolved over time. These range from explicit text-based knowledge to parameter-level adaptations and activation states within the model, creating a unified framework for memory management that previously didn’t exist.\nTesting on the\nLOCOMO benchmark\n, which evaluates memory-intensive reasoning tasks, MemOS consistently outperformed established baselines across all categories. The system achieved a 38.98% overall improvement compared to OpenAI’s memory implementation, with particularly strong gains in complex reasoning scenarios that require connecting information across multiple conversation turns.\n“MemOS (MemOS-0630) consistently ranks first in all categories, outperforming strong baselines such as mem0, LangMem, Zep, and OpenAI-Memory, with especially large margins in challenging settings like multi-hop and temporal reasoning,” according to the research. The system also delivered substantial efficiency improvements, with up to 94% reduction in time-to-first-token latency in certain configurations through its innovative KV-cache memory injection mechanism.\nThese performance gains suggest that the memory bottleneck has been a more significant limitation than previously understood. By treating memory as a first-class computational resource,\nMemOS\nappears to unlock reasoning capabilities that were previously constrained by architectural limitations.\nThe technology could reshape how businesses deploy artificial intelligence\nThe implications for enterprise AI deployment could be transformative, particularly as businesses increasingly rely on AI systems for complex, ongoing relationships with customers and employees.\nMemOS\nenables what the researchers describe as “\ncross-platform memory migration\n,” allowing AI memories to be portable across different platforms and devices, breaking down what they call “\nmemory islands\n” that currently trap user context within specific applications.\nConsider the current frustration many users experience when insights explored in one AI platform can’t carry over to another. A marketing team might develop detailed customer personas through conversations with ChatGPT, only to start from scratch when switching to a different AI tool for campaign planning. MemOS addresses this by creating a standardized memory format that can move between systems.\nThe research also outlines potential for “\npaid memory modules\n,” where domain experts could package their knowledge into purchasable memory units. The researchers envision scenarios where “a medical student in clinical rotation may wish to study how to manage a rare autoimmune condition. An experienced physician can encapsulate diagnostic heuristics, questioning paths, and typical case patterns into a structured memory” that can be installed and used by other AI systems.\nThis marketplace model could fundamentally alter how specialized knowledge is distributed and monetized in AI systems, creating new economic opportunities for experts while democratizing access to high-quality domain knowledge. For enterprises, this could mean rapidly deploying AI systems with deep expertise in specific areas without the traditional costs and timelines associated with custom training.\nThree-layer design mirrors traditional computer operating systems\nThe\ntechnical architecture of MemOS\nreflects decades of learning from traditional operating system design, adapted for the unique challenges of AI memory management. The system employs a three-layer architecture: an interface layer for API calls, an operation layer for memory scheduling and lifecycle management, and an infrastructure layer for storage and governance.\nThe system’s\nMemScheduler\ncomponent dynamically manages different types of memory — from temporary activation states to permanent parameter modifications — selecting optimal storage and retrieval strategies based on usage patterns and task requirements. This represents a significant departure from current approaches, which typically treat memory as either completely static (embedded in model parameters) or completely ephemeral (limited to conversation context).\n“The focus shifts from how much knowledge the model learns once to whether it can transform experience into structured memory and repeatedly retrieve and reconstruct it,” the researchers note, describing their vision for what they call “\nMem-training\n” paradigms. This architectural philosophy suggests a fundamental rethinking of how AI systems should be designed, moving away from the current paradigm of massive pre-training toward more dynamic, experience-driven learning.\nThe parallels to operating system development are striking. Just as early computers required programmers to manually manage memory allocation, current AI systems require developers to carefully orchestrate how information flows between different components.\nMemOS\nabstracts this complexity, potentially enabling a new generation of AI applications that can be built on top of sophisticated memory management without requiring deep technical expertise.\nResearchers release code as open source to accelerate adoption\nThe team has released\nMemOS\nas an open-source project, with\nfull code available on GitHub\nand integration support for major AI platforms including HuggingFace, OpenAI, and Ollama. This open-source strategy appears designed to accelerate adoption and encourage community development, rather than pursuing a proprietary approach that might limit widespread implementation.\n“We hope MemOS helps advance AI systems from static generators to continuously evolving, memory-driven agents,” project lead Zhiyu Li commented in the GitHub repository. The system currently supports Linux platforms, with Windows and macOS support planned, suggesting the team is prioritizing enterprise and developer adoption over immediate consumer accessibility.\nThe open-source release strategy reflects a broader trend in AI research where foundational infrastructure improvements are shared openly to benefit the entire ecosystem. This approach has historically accelerated innovation in areas like deep learning frameworks and could have similar effects for memory management in AI systems.\nTech giants race to solve AI memory limitations\nThe research arrives as major AI companies grapple with the limitations of current memory approaches, highlighting just how fundamental this challenge has become for the industry. OpenAI recently introduced\nmemory features for ChatGPT\n, while\nAnthropic\n,\nGoogle\n, and other providers have experimented with various forms of persistent context. However, these implementations have generally been limited in scope and often lack the systematic approach that\nMemOS\nprovides.\nThe timing of this research suggests that memory management has emerged as a critical competitive battleground in AI development. Companies that can solve the memory problem effectively may gain significant advantages in user retention and satisfaction, as their AI systems will be able to build deeper, more useful relationships over time.\nIndustry observers have long predicted that the next major breakthrough in AI wouldn’t necessarily come from larger models or more training data, but from architectural innovations that better mimic human cognitive capabilities. Memory management represents exactly this type of fundamental advancement — one that could unlock new applications and use cases that aren’t possible with current stateless systems.\nThe development represents part of a broader shift in AI research toward more stateful, persistent systems that can accumulate and evolve knowledge over time — capabilities seen as essential for artificial general intelligence. For enterprise technology leaders evaluating AI implementations,\nMemOS\ncould represent a significant advancement in building AI systems that maintain context and improve over time, rather than treating each interaction as isolated.\nThe research team indicates they plan to explore cross-model memory sharing, self-evolving memory blocks, and the development of a broader “memory marketplace” ecosystem in future work. But perhaps the most significant impact of MemOS won’t be the specific technical implementation, but rather the proof that treating memory as a first-class computational resource can unlock dramatic improvements in AI capabilities. In an industry that has largely focused on scaling model size and training data, MemOS suggests that the next breakthrough might come from better architecture rather than bigger computers.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nThe Briefing for Tech Decision-Makers\nStay ahead in AI, data, and security with VB Daily—trusted by 100K+ industry leaders.\nSubscribe Here\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-09T15:52:07.803608",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-09T15:52:33.830321",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/369f0ce43027de69dde211c2d74078b7.mp3",
    "audio_file": "audio/articles/369f0ce43027de69dde211c2d74078b7.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-07-09T15:53:56.416300",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  }
]