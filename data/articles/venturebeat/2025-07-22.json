[
  {
    "id": "ef2e7baee0b390f776d79a81ee894f97",
    "title": "Crowdstrike’s massive cyber outage 1-year later: lessons enterprises can learn to improve security",
    "url": "https://venturebeat.com/security/how-crowdstrikes-78-minute-outage-reshaped-enterprise-cybersecurity/",
    "authors": "Louis Columbus",
    "published_date": "2025-07-21T22:46:41+00:00",
    "source": "VentureBeat",
    "summary": "CrowdStrike一年前的大規模網路中斷事件讓企業學到改善安全的教訓。他們在不到80分鐘的故障中，因為一次軟體更新失敗，導致全球850萬台Windows系統當機，造成50億美元損失。這次事件提醒我們，即使沒有惡意攻擊，內部失誤也可能對全球基礎設施造成嚴重影響。企業應該重視網路安全，提升抗攻擊的能力。",
    "content": "How CrowdStrike's 78-minute outage reshaped enterprise cybersecurity | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nAnalysis\nCrowdstrike’s massive cyber outage 1-year later: lessons enterprises can learn to improve security\nLouis Columbus\n@LouisColumbus\nJuly 21, 2025 3:46 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCreated with Imagen\nWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\nSubscribe Now\nAs we wrote in our\ninitial analysis of the CrowdStrike incident\n, the July 19, 2024, outage served as a stark reminder of the importance of cyber resilience. Now, one year later, both\nCrowdStrike\nand the industry have undergone significant transformation, with the catalyst being driven by 78 minutes that changed everything.\n“The first anniversary of July 19 marks a moment that deeply impacted our customers and partners and became one of the most defining chapters in CrowdStrike’s history,” CrowdStrike’s President Mike Sentonas wrote in a\nblog\ndetailing the company’s year-long journey toward enhanced resilience.\nThe incident that shook global infrastructure\nThe numbers remain sobering: A faulty Channel File 291 update, deployed at 04:09 UTC and reverted just 78 minutes later, crashed 8.5 million Windows systems worldwide. Insurance estimates put losses at $5.4 billion for the top 500 U.S. companies alone, with aviation particularly hard hit with 5,078 flights canceled globally.\nSteffen Schreier, senior vice president of product and portfolio at\nTelesign\n, a Proximus Global company, captures why this incident resonates a year later: “One year later, the CrowdStrike incident isn’t just remembered, it’s impossible to forget. A routine software update, deployed with no malicious intent and rolled back in just 78 minutes, still managed to take down critical infrastructure worldwide. No breach. No attack. Just one internal failure with global consequences.”\nThe AI Impact Series Returns to San Francisco - August 5\nThe next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.\nSecure your spot now - space is limited:\nhttps://bit.ly/3GuuPLF\nHis technical analysis reveals uncomfortable truths about modern infrastructure: “That’s the real wake-up call: even companies with strong practices, a staged rollout, fast rollback, can’t outpace the risks introduced by the very infrastructure that enables rapid, cloud-native delivery. The same velocity that empowers us to ship faster also accelerates the blast radius when something goes wrong.”\nUnderstanding what went wrong\nCrowdStrike’s root cause analysis revealed a cascade of technical failures: a mismatch between input fields in their IPC Template Type, missing runtime array bounds checks and a logic error in their Content Validator. These weren’t edge cases but fundamental quality control gaps.\nMerritt Baer, incoming Chief Security Officer at\nEnkrypt AI\nand advisor to companies including Andesite, provides crucial context: “CrowdStrike’s outage was humbling; it reminded us that even really big, mature shops get processes wrong sometimes. This particular outcome was a coincidence on some level, but it should have never been possible. It demonstrated that they failed to instate some basic CI/CD protocols.”\nHer assessment is direct but fair: “Had CrowdStrike rolled out the update in sandboxes and only sent it in production in increments as is best practice, it would have been less catastrophic, if at all.”\nYet Baer also recognizes CrowdStrike’s response: “CrowdStrike’s comms strategy demonstrated good executive ownership. Execs should always take ownership—it’s not the intern’s fault. If your junior operator can get it wrong, it’s my fault. It’s our fault as a company.”\nLeadership’s accountability\nGeorge Kurtz, CrowdStrike’s founder and CEO, exemplified this ownership principle. In a\nLinkedIn post\nreflecting on the anniversary, Kurtz wrote: “One year ago, we faced a moment that tested everything: our technology, our operations, and the trust others placed in us. As founder and CEO, I took that responsibility personally. I always have and always will.”\nHis perspective reveals how the company channeled crisis into transformation: “What defined us wasn’t that moment; it was everything that came next. From the start, our focus was clear: build an even stronger CrowdStrike, grounded in resilience, transparency, and relentless execution. Our North Star has always been our customers.”\nCrowdStrike goes all-in on a new Resilient by Design framework\nCrowdStrike’s response centered on their Resilient by Design framework, which Sentonas describes as going beyond “quick fixes or surface-level improvements.” The framework’s three pillars, including Foundational, Adaptive and Continuous components, represent a comprehensive rethinking of how security platforms should operate.\nKey implementations include:\nSensor Self-Recovery\n: Automatically detects crash loops and transitions to safe mode\nNew Content Distribution System\n: Ring-based deployment with automated safeguards\nEnhanced Customer Control\n: Granular update management and content pinning capabilities\nDigital Operations Center\n: Purpose-built facility for global infrastructure monitoring\nFalcon Super Lab\n: Testing thousands of OS, kernel and hardware combinations\n“We didn’t just add a few content configuration options,” Sentonas emphasized in his blog. “We fundamentally rethought how customers could interact with and control enterprise security platforms.”\nIndustry-wide supply chain awakening\nThe incident forced a broader reckoning about vendor dependencies. Baer frames the lesson starkly: “One huge practical lesson was just that your vendors are part of your supply chain. So, as a CISO, you should test the risk to be aware of it, but simply speaking, this issue fell on the provider side of the shared responsibility model. A customer wouldn’t have controlled it.”\nCrowdStrike’s outage has permanently altered vendor evaluation: “I see effective CISOs and CSOs taking lessons from this, around the companies they want to work with and the security they receive as a product of doing business together. I will only ever work with companies that I respect from a security posture lens. They don’t need to be perfect, but I want to know that they are doing the right processes, over time.”\nSam Curry, CISO at\nZscaler,\nadded, “What happened to CrowdStrike was unfortunate, but it could have happened to many, so perhaps we don’t put the blame on them with the benefit of hindsight. What I will say is that the world has used this to refocus and has placed more attention to resilience as a result, and that’s a win for everyone, as our collective goal is to make the internet safer and more secure for all.”\nUnderscores the need for a new security paradigm\nSchreier’s analysis extends beyond CrowdStrike to fundamental security architecture: “Speed at scale comes at a cost. Every routine update now carries the weight of potential systemic failure. That means more than testing, it means safeguards built for resilience: layered defenses, automatic rollback paths and fail-safes that assume telemetry might disappear exactly when you need it most.”\nHis most critical insight addresses a scenario many hadn’t considered: “And when telemetry goes dark, you need fail-safes that assume visibility might vanish.”\nThis represents a paradigm shift. As Schreier concludes: “Because security today isn’t just about keeping attackers out—it’s about making absolutely sure your own systems never become the single point of failure.”\nLooking forward: AI and future challenges\nBaer sees the next evolution already emerging: “Ever since cloud has enabled us to build using infrastructure as code, but especially now that AI is enabling us to do security differently, I am looking at how infrastructure decisions are layered with autonomy from humans and AI. We can and should layer on reasoning as well as effective risk mitigation for processes like forced updates, especially at high levels of privilege.”\nCrowdStrike’s forward-looking initiatives include:\nHiring a Chief Resilience Officer reporting directly to the CEO\nProject Ascent, exploring capabilities beyond kernel space\nCollaboration with Microsoft on the Windows Endpoint Security Platform\nISO 22301 certification for business continuity management\nA stronger ecosystem\nOne year later, the transformation is evident. Kurtz reflects: “We’re a stronger company today than we were a year ago. The work continues. The mission endures. And we’re moving forward: stronger, smarter, and even more committed than ever.”\nTo his credit, Kurtz also acknowledges those who stood by the company: “To every customer who stayed with us, even when it was hard, thank you for your enduring trust. To our incredible partners who stood by us and rolled up their sleeves, thank you for being our extended family.”\nThe incident’s legacy extends far beyond CrowdStrike. Organizations now implement staged rollouts, maintain manual override capabilities and—crucially—plan for when security tools themselves might fail. Vendor relationships are evaluated with new rigor, recognizing that in our interconnected infrastructure, every component is critical.\nAs Sentonas acknowledges: “This work isn’t finished and never will be. Resilience isn’t a milestone; it’s a discipline that requires continuous commitment and evolution.” The CrowdStrike incident of July 19, 2024, will be remembered not just for the disruption it caused but for catalyzing an industry-wide evolution toward true resilience.\nIn facing their greatest challenge, CrowdStrike and the broader security ecosystem have emerged with a deeper understanding: protecting against threats means ensuring the protectors themselves can do no harm. That lesson, learned through 78 difficult minutes and a year of transformation, may prove to be the incident’s most valuable legacy.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nAI Impact Series Returns to SF – Aug 5\nExplore the future of AI on August 5 in San Francisco—join Block, GSK, and SAP at Autonomous Workforces to discover how enterprises are scaling multi-agent systems with real-world results.\nClaim Your Spot\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe insights you need without the noise\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-22T14:49:20.580154",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-22T14:49:39.027744",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "ea8255e5bd9bc97119d42fc9799c63b2",
    "title": "Google DeepMind makes AI history with gold medal win at world’s toughest math competition",
    "url": "https://venturebeat.com/ai/google-deepmind-makes-ai-history-with-gold-medal-win-at-worlds-toughest-math-competition/",
    "authors": "Michael Nuñez",
    "published_date": "2025-07-21T22:33:34+00:00",
    "source": "VentureBeat",
    "summary": "Google DeepMind在全球最難的數學競賽中獲得金牌，創造了AI歷史。他們的Gemini人工智慧模型成功解決了五道六道極難的問題，成為首個獲得官方金牌評分的AI系統。這次勝利推動了AI推理領域的發展，讓Google在下一代人工智慧的競爭中處於領先地位。更重要的是，這顯示出AI現在可以使用自然語言理解來應對複雜的數學問題，而不需要專門的編程語言。",
    "content": "Google DeepMind makes AI history with gold medal win at world's toughest math competition | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nGoogle DeepMind makes AI history with gold medal win at world’s toughest math competition\nMichael Nuñez\n@MichaelFNunez\nJuly 21, 2025 3:33 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCredit: VentureBeat made with Midjourney\nWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\nSubscribe Now\nGoogle DeepMind\nannounced Monday that an advanced version of its Gemini artificial intelligence model has officially achieved\ngold medal-level performance\nat the\nInternational Mathematical Olympiad\n, solving five of six exceptionally difficult problems and earning recognition as the first AI system to receive official gold-level grading from competition organizers.\nThe victory advances the field of AI reasoning and puts Google ahead in the intensifying battle between tech giants building next-generation artificial intelligence. More importantly, it demonstrates that AI can now tackle complex mathematical problems using natural language understanding rather than requiring specialized programming languages.\n“Official results are in — Gemini achieved gold-medal level in the International Mathematical Olympiad!”\nDemis Hassabis\n, CEO of Google DeepMind, wrote on social media platform X Monday morning. “An advanced version was able to solve 5 out of 6 problems. Incredible progress.”\nOfficial results are in – Gemini achieved gold-medal level in the International Mathematical Olympiad! ? An advanced version was able to solve 5 out of 6 problems. Incredible progress – huge congrats to\n@lmthang\nand the team!\nhttps://t.co/pp9bXF7rVj\n— Demis Hassabis (@demishassabis)\nJuly 21, 2025\nThe\nInternational Mathematical Olympiad\n, held annually since 1959, is widely considered the world’s most prestigious mathematics competition for pre-university students. Each participating country sends six elite young mathematicians to compete in solving six exceptionally challenging problems spanning algebra, combinatorics, geometry, and number theory. Only about 8% of human participants typically earn gold medals.\nThe AI Impact Series Returns to San Francisco - August 5\nThe next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.\nSecure your spot now - space is limited:\nhttps://bit.ly/3GuuPLF\nHow Google DeepMind’s Gemini Deep Think cracked math’s toughest problems\nGoogle’s latest success far exceeds its 2024 performance, when the company’s combined\nAlphaProof\nand\nAlphaGeometry\nsystems earned silver medal status by solving four of six problems. That earlier system required human experts to first translate natural language problems into domain-specific programming languages and then interpret the AI’s mathematical output.\nThis year’s breakthrough came through\nGemini Deep Think\n, an enhanced reasoning system that employs what researchers call “\nparallel thinking\n.” Unlike traditional AI models that follow a single chain of reasoning, Deep Think simultaneously explores multiple possible solutions before arriving at a final answer.\n“Our model operated end-to-end in natural language, producing rigorous mathematical proofs directly from the official problem descriptions,”\nHassabis explained\nin a follow-up post on the social media site X, emphasizing that the system completed its work within the competition’s standard 4.5-hour time limit.\nWe achieved this year’s impressive result using an advanced version of Gemini Deep Think (an enhanced reasoning mode for complex problems). Our model operated end-to-end in natural language, producing rigorous mathematical proofs directly from the official problem descriptions –…\n— Demis Hassabis (@demishassabis)\nJuly 21, 2025\nThe model achieved 35 out of a possible 42 points, comfortably exceeding the gold medal threshold. According to IMO President Prof. Dr. Gregor Dolinar, the solutions were “\nastonishing in many respects\n” and found to be “clear, precise and most of them easy to follow” by competition graders.\nOpenAI faces backlash for bypassing official competition rules\nThe announcement comes amid growing tension in the AI industry over competitive practices and transparency. Google DeepMind’s measured approach to releasing its results has drawn praise from the AI community, particularly in contrast to rival OpenAI’s handling of similar achievements.\n“We didn’t announce on Friday because we respected the IMO Board’s original request that all AI labs share their results only after the official results had been verified by independent experts & the students had rightly received the acclamation they deserved,”\nHassabis wrote\n, appearing to reference OpenAI’s earlier announcement of its own olympiad performance.\nBtw as an aside, we didn’t announce on Friday because we respected the IMO Board's original request that all AI labs share their results only after the official results had been verified by independent experts & the students had rightly received the acclamation they deserved\n— Demis Hassabis (@demishassabis)\nJuly 21, 2025\nSocial media users were quick to note the distinction. “You see? OpenAI ignored the IMO request. Shame. No class. Straight up disrespect,”\nwrote one user\n. “Google DeepMind acted with integrity, aligned with humanity.”\nThe criticism stems from OpenAI’s decision to announce its own mathematical olympiad results without participating in the official IMO evaluation process. Instead, OpenAI had a panel of former IMO participants grade its AI’s performance, a approach that some in the community view as lacking credibility.\n“OpenAI is quite possibly the worst company on the planet right now,” wrote one critic, while others suggested the company needs to “take things seriously” and “be more credible.”\nYou see?\nOpenAI ignored the IMO request. Shame. No class. Straight up disrespect.\nGoogle DeepMind acted with integrity, aligned with humanity.\nTRVTHNUKE\npic.twitter.com/8LAOak6XUE\n— NIK (@ns123abc)\nJuly 21, 2025\nInside the training methods that powered Gemini’s mathematical mastery\nGoogle DeepMind’s success appears to stem from novel training techniques that go beyond traditional approaches. The team used advanced reinforcement learning methods designed to leverage multi-step reasoning, problem-solving, and theorem-proving data. The model was also provided access to a curated collection of high-quality mathematical solutions and received specific guidance on approaching IMO-style problems.\nThe technical achievement impressed AI researchers who noted its broader implications. “Not just solving math… but understanding language-described problems and applying abstract logic to novel cases,” wrote AI observer\nElyss Wren\n. “This isn’t rote memory — this is emergent cognition in motion.”\nEthan Mollick\n, a professor at the Wharton School who studies AI, emphasized the significance of using a general-purpose model rather than specialized tools. “Increasing evidence of the ability of LLMs to generalize to novel problem solving,” he wrote, highlighting how this differs from previous approaches that required specialized mathematical software.\nIt wasn't just OpenAI.\nGoogle also used a general purpose model to solve the very hard math problems of the International Math Olympiad in plain language. Last year they used specialized tool use\nIncreasing evidence of the ability of LLMs to generalize to novel problem solving\nhttps://t.co/Ve72fFmx2b\n— Ethan Mollick (@emollick)\nJuly 21, 2025\nThe model demonstrated particularly impressive reasoning in one problem where many human competitors applied graduate-level mathematical concepts. According to DeepMind researcher Junehyuk Jung, Gemini “made a brilliant observation and used only elementary number theory to create a self-contained proof,” finding a more elegant solution than many human participants.\nWhat Google DeepMind’s victory means for the $200 billion AI race\nThe breakthrough comes at a critical moment in the AI industry, where companies are racing to demonstrate superior reasoning capabilities. The success has immediate practical implications: Google plans to make a version of this\nDeep Think model\navailable to mathematicians for testing before rolling it out to Google AI Ultra subscribers, who pay $250 monthly for access to the company’s most advanced AI models.\nThe timing also highlights the intensifying competition between major AI laboratories. While Google celebrated its methodical, officially-verified approach, the controversy surrounding OpenAI’s announcement reflects broader tensions about transparency and credibility in AI development.\nThis competitive dynamic extends beyond just mathematical reasoning. Recent weeks have seen various AI companies announce breakthrough capabilities, though not all have been received positively. Elon Musk’s xAI recently launched\nGrok 4\n, which the company claimed was the “smartest AI in the world,” though\nleaderboard scores showed it trailing\nbehind models from Google and OpenAI. Additionally, Grok has faced criticism for controversial features including\nsexualized AI companions\nand episodes of generating\nantisemitic content\n.\nThe dawn of AI that thinks like humans—with real-world consequences\nThe mathematical olympiad victory goes beyond competitive bragging rights. Gemini’s performance demonstrates that AI systems can now match human-level reasoning in complex tasks requiring creativity, abstract thinking, and the ability to synthesize insights across multiple domains.\n“This is a significant advance over last year’s breakthrough result,” the\nDeepMind team noted\nin their technical announcement. The progression from requiring specialized formal languages to operating entirely in natural language suggests that AI systems are becoming more intuitive and accessible.\nFor businesses, this development signals that AI may soon tackle complex analytical problems across various industries without requiring specialized programming or domain expertise. The ability to reason through intricate challenges using everyday language could democratize sophisticated analytical capabilities across organizations.\nHowever, questions persist about whether these reasoning capabilities will translate effectively to messier real-world challenges. The mathematical olympiad provides well-defined problems with clear success criteria — a far cry from the ambiguous, multifaceted decisions that define most business and scientific endeavors.\nGoogle DeepMind plans to return to next year’s competition “\nin search of a perfect score\n.” The company believes AI systems combining natural language fluency with rigorous reasoning “will become invaluable tools for mathematicians, scientists, engineers, and researchers, helping us advance human knowledge on the path to AGI.”\nBut perhaps the most telling detail emerged from the competition itself: when faced with the contest’s most difficult problem, Gemini started from an incorrect hypothesis and never recovered. Only five human students solved that problem correctly. In the end, it seems, even gold medal-winning AI still has something to learn from teenage mathematicians.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nAI Impact Series Returns to SF – Aug 5\nExplore the future of AI on August 5 in San Francisco—join Block, GSK, and SAP at Autonomous Workforces to discover how enterprises are scaling multi-agent systems with real-world results.\nClaim Your Spot\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-22T14:49:20.845798",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-22T14:49:40.578200",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "d76488fc2d86e58c8934cb39050570cf",
    "title": "Chinese startup Manus challenges ChatGPT in data visualization: which should enterprises use?",
    "url": "https://venturebeat.com/data-infrastructure/chinese-startup-manus-challenges-chatgpt-in-data-visualization-which-should-enterprises-use/",
    "authors": "Ujas Patel",
    "published_date": "2025-07-21T21:38:23+00:00",
    "source": "VentureBeat",
    "summary": "一家中國初創公司Manus推出了最新的數據可視化功能，可以將混亂的CSV檔案轉換成互動圖表，但在透明度方面仍有不足。儘管Manus處理混亂數據比ChatGPT更好，但目前仍不夠成熟以用於會議簡報。企業普遍依賴Excel處理數據，而Manus正致力填補數據處理的空白。這項技術有望幫助企業更有效地處理數據並製作專業報告。",
    "content": "Chinese startup Manus challenges ChatGPT in data visualization: which should enterprises use? | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nAnalysis\nChinese startup Manus challenges ChatGPT in data visualization: which should enterprises use?\nUjas Patel\nJuly 21, 2025 2:38 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCreated by VentureBeat using Gemini\nWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\nSubscribe Now\nThe promise sounds almost too good to be true: drop a messy comma separated values (CSV) file into an AI agent, wait two minutes, and get back a polished, interactive chart ready for your next board presentation.\nBut that’s exactly what Chinese startup\nM\nanus.im\nis delivering with its latest data visualization feature, launched this month.\nUnfortunately, my initial hands-on testing with corrupted datasets reveals a fundamental enterprise problem: impressive capabilities paired with insufficient transparency about data transformations. While Manus handles messy data better than ChatGPT, neither tool is yet ready for boardroom-ready slides.\nThe spreadsheet problem plaguing enterprise analytics\nRossums’\nsurvey of 470 finance leaders found 58% still rely primarily on Excel for monthly KPIs, despite owning BI licenses. Another\nTechRadar\nstudy estimates that overall spreadsheet dependence affects roughly 90% of organizations — creating a “last-mile data problem” between governed warehouses and hasty CSV exports that land in analysts’ inboxes hours before critical meetings.\nThe AI Impact Series Returns to San Francisco - August 5\nThe next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.\nSecure your spot now - space is limited:\nhttps://bit.ly/3GuuPLF\nManus targets this exact gap. Upload your CSV, describe what you want in natural language, and the agent automatically cleans the data, selects the appropriate Vega-Lite grammar and returns a PNG chart ready for export—no pivot tables required.\nWhere Manus beats ChatGPT: 4x slower but more accurate with messy data\nI tested both Manus and ChatGPT’s Advanced Data Analysis using three datasets (113k-row\necommerce orders\n, 200k-row\nmarketing funnel\n10k-row\nSaaS MRR\n), first clean, then corrupted with 5% error injection including nulls, mixed-format dates and duplicates.\nFor example, testing the same prompt — \"Show me a month-by-month revenue trend for the past year and highlight any unusual spikes or dips\" — across clean and corrupted 113k-row e-commerce data revealed some stark differences.\nTool\nData Quality\nTime\nCleans Nulls\nParses Dates\nHandles Duplicates\nComments\nManus\nClean\n1:46\nN/A\n✓\nN/A\nCorrect trend, standard presentation, but incorrect numbers\nManus\nMessy\n3:53\n✓\n✓\n✗\nCorrect trend despite inaccurate data\nChatGPT\nClean\n0:57\nN/A\n✓\nN/A\nFast, but incorrect visualisation\nChatGPT\nMessy\n0:59\n✗\n✗\n✗\nIncorrect trend from unclean data\nFor context: DeepSeek could only handle 1% of the file size, while Claude and Grok took over 5 minutes each but produced interactive charts without PNG export options.\nOutputs:\nFigure 1-2: Chart outputs from the same revenue trend prompt on messy e-commerce data. Manus (bottom) produces a coherent trend despite data corruption, while ChatGPT (top) shows distorted patterns from unclean date formatting.\nManus behaves like a cautious junior analyst\n— automatically tidying data before charting, successfully parsing date inconsistencies and handling nulls without explicit instructions. When I requested the same revenue trend analysis on corrupted data, Manus took nearly 4 minutes but produced a coherent visualization despite the data quality issues.\nChatGPT operates like a speed coder\n— prioritizing fast output over data hygiene. The same request took just 59 seconds but produced misleading visualizations because it didn’t automatically clean formatting inconsistencies.\nHowever, both tools failed in terms of “executive readiness.” Neither produced board-ready axis scaling or readable labels without follow-up prompts. Data labels were frequently overlapping or too small, bar charts lacked proper gridlines and number formatting was inconsistent.\nThe transparency crisis enterprises can’t ignore\nHere’s where Manus becomes problematic for enterprise adoption:\nthe agent never surfaces cleaning steps it applies\n. An auditor reviewing the final chart has no way to confirm whether outliers were dropped, imputed or transformed.\nWhen a CFO presents quarterly results based on a Manus-generated chart, what happens when someone asks, “How did you handle the duplicate transactions from the Q2 system integration?” The answer is silence.\nChatGPT, Claude and Grok all show their Python code, though transparency through code review isn’t scalable for business users lacking programming experience. What enterprises need is a simpler audit trail, which builds trust.\nWarehouse-native AI is racing ahead\nWhile Manus focuses on CSV uploads, major platforms are building chart generation directly into enterprise data infrastructure:\nGoogle’s Gemini in BigQuery\nbecame generally available in August 2024, enabling the generation of SQL queries and inline visualizations on live tables while respecting row-level security.\nMicrosoft’s Copilot in Fabric\nreached GA in the Power BI experience in May 2024, creating visuals inside Fabric notebooks while working directly with Lakehouse datasets.\nGoodData’s AI Assistant\n, launched in June 2025, operates within customer environments and respects existing semantic models, allowing users to ask questions in plain language while receiving answers that align with predefined metrics and business terms.\nThese warehouse-native solutions eliminate CSV exports entirely, preserve complete data lineage and leverage existing security models — advantages file-upload tools like Manus struggle to match.\nCritical gaps for enterprise adoption\nMy testing revealed several blockers:\nLive data connectivity\nremains absent — Manus supports file uploads only, with no Snowflake, BigQuery or S3 connectors. Manus.im says connectors are “on the roadmap” but offers no timeline.\nAudit trail transparency\nis completely missing. Enterprise data teams need transformation logs showing exactly how AI cleaned their data and whether its interpretation of the fields are correct.\nExport flexibility\nis limited to PNG outputs. While adequate for quick slide decks, enterprises need customizable, interactive export options.\nThe verdict: impressive tech, premature for enterprise use cases\nFor SMB executives drowning in ad-hoc CSV analysis, Manus’s drag-and-drop visualisation seems to be doing the job.\nThe autonomous data cleaning handles real-world messiness that would otherwise require manual preprocessing, cutting turnaround from hours to minutes when you have reasonably complete data.\nAdditionally, it offers a significant runtime advantage over Excel or Google Sheets, which require manual pivots and incur substantial load times due to local compute power limitations.\nBut regulated enterprises with governed data lakes should wait for warehouse-native agents like Gemini or Fabric Copilot, which keep data inside security perimeters and maintain complete lineage tracking.\nBottom line:\nManus proves one-prompt charting works and handles messy data impressively. But for enterprises, the question isn’t whether the charts look good — it’s whether you can stake your career on data transformations you can’t audit or verify. Until AI agents can plug directly into governed tables with rigorous audit trails, Excel will continue to hold its starring role in quarterly presentations.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nAI Impact Series Returns to SF – Aug 5\nExplore the future of AI on August 5 in San Francisco—join Block, GSK, and SAP at Autonomous Workforces to discover how enterprises are scaling multi-agent systems with real-world results.\nClaim Your Spot\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe insights you need without the noise\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-22T14:49:21.137777",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-22T14:49:42.968216",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  }
]