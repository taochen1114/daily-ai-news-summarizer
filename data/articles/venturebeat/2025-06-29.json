[
  {
    "id": "afc0f17f2552ee17353573dcabc5dbb6",
    "title": "From hallucinations to hardware: Lessons from a real-world computer vision project gone sideways",
    "url": "https://venturebeat.com/ai/from-hallucinations-to-hardware-lessons-from-a-real-world-computer-vision-project-gone-sideways/",
    "authors": "Vadiraj Kulkarni, Dell Technologies",
    "published_date": "2025-06-28T19:05:00+00:00",
    "source": "VentureBeat",
    "summary": "這篇新聞講述了一個真實世界的電腦視覺專案出了些問題，從幻覺到硬體，讓專案走向了不尋常的方向。他們原本想建立一個模型，可以辨識照片中筆記型電腦的損壞情況，但卻遇到了幻覺、不可靠的輸出和非筆記型電腦的圖片等問題。最後他們採用了一種不尋常的方法來改善模型的表現。這個故事告訴我們在AI專案中，常常會遇到挑戰，需要不斷嘗試不同方法才能找到可靠的解決方案。",
    "content": "From hallucinations to hardware: Lessons from a real-world computer vision project gone sideways | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nGuest\nFrom hallucinations to hardware: Lessons from a real-world computer vision project gone sideways\nShruti Tiwari, Dell Technologies\nVadiraj Kulkarni, Dell Technologies\nJune 28, 2025 12:05 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nVentureBeat/Midjourney\nJoin the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.\nLearn more\nComputer vision projects rarely go exactly as planned, and this one was no exception. The idea was simple: Build a model that could look at a photo of a laptop and identify any physical damage — things like cracked screens, missing keys or broken hinges. It seemed like a straightforward use case for image models and\nlarge language model\ns (LLMs), but it quickly turned into something more complicated.\nAlong the way, we ran into issues with hallucinations, unreliable outputs and images that were not even laptops. To solve these, we ended up applying an agentic framework in an atypical way — not for task automation, but to improve the model’s performance.\nIn this post, we will walk through what we tried, what didn’t work and how a combination of approaches eventually helped us build something reliable.\nWhere we started: Monolithic prompting\nOur initial approach was fairly standard for a multimodal model. We used a single, large prompt to pass an image into an\nimage-capable LLM\nand asked it to identify visible damage. This monolithic prompting strategy is simple to implement and works decently for clean, well-defined tasks. But real-world data rarely plays along.\nWe ran into three major issues early on:\nHallucinations\n: The model would sometimes invent damage that did not exist or mislabel what it was seeing.\nJunk image detection\n: It had no reliable way to flag images that were not even laptops, like pictures of desks, walls or people occasionally slipped through and received nonsensical damage reports.\nInconsistent accuracy\n: The combination of these problems made the model too unreliable for operational use.\nThis was the point when it became clear we would need to iterate.\nFirst fix: Mixing image resolutions\nOne thing we noticed was how much image quality affected the model’s output. Users uploaded all kinds of images ranging from sharp and high-resolution to blurry. This led us to refer to\nresearch\nhighlighting how image resolution impacts deep learning models.\nWe trained and tested the model using a mix of high-and low-resolution images. The idea was to make the model more resilient to the wide range of image qualities it would encounter in practice. This helped improve consistency, but the core issues of hallucination and junk image handling persisted.\nThe multimodal detour: Text-only LLM goes multimodal\nEncouraged by recent experiments in combining image captioning with text-only LLMs — like the technique covered in\nThe Batch\n, where captions are generated from images and then interpreted by a language model, we decided to give it a try.\nHere’s how it works:\nThe LLM begins by generating multiple possible captions for an image.\nAnother model, called a multimodal embedding model, checks how well each caption fits the image. In this case, we used SigLIP to score the similarity between the image and the text.\nThe system keeps the top few captions based on these scores.\nThe LLM uses those top captions to write new ones, trying to get closer to what the image actually shows.\nIt repeats this process until the captions stop improving, or it hits a set limit.\nWhile clever in theory, this approach introduced new problems for our use case:\nPersistent hallucinations\n: The captions themselves sometimes included imaginary damage, which the LLM then confidently reported.\nIncomplete coverage\n: Even with multiple captions, some issues were missed entirely.\nIncreased complexity, little benefit\n: The added steps made the system more complicated without reliably outperforming the previous setup.\nIt was an interesting experiment, but ultimately not a solution.\nA creative use of agentic frameworks\nThis was the turning point. While agentic frameworks are usually used for orchestrating task flows (think agents coordinating calendar invites or customer service actions), we wondered if breaking down the image interpretation task into smaller,\nspecialized agents\nmight help.\nWe built an agentic framework structured like this:\nOrchestrator agent\n: It checked the image and identified which laptop components were visible (screen, keyboard, chassis, ports).\nComponent agents\n: Dedicated agents inspected each component for specific damage types; for example, one for cracked screens, another for missing keys.\nJunk detection agent\n: A separate agent flagged whether the image was even a laptop in the first place.\nThis modular, task-driven approach produced much more precise and explainable results. Hallucinations dropped dramatically, junk images were reliably flagged and each agent’s task was simple and focused enough to control quality well.\nThe blind spots: Trade-offs of an agentic approach\nAs effective as this was, it was not perfect. Two main limitations showed up:\nIncreased latency\n: Running multiple sequential agents added to the total inference time.\nCoverage gaps\n: Agents could only detect issues they were explicitly programmed to look for. If an image showed something unexpected that no agent was tasked with identifying, it would go unnoticed.\nWe needed a way to balance precision with coverage.\nThe hybrid solution: Combining agentic and monolithic approaches\nTo bridge the gaps, we created a hybrid system:\nThe\nagentic framework\nran first, handling precise detection of known damage types and junk images. We limited the number of agents to the most essential ones to improve latency.\nThen, a\nmonolithic image LLM prompt\nscanned the image for anything else the agents might have missed.\nFinally, we\nfine-tuned the model\nusing a curated set of images for high-priority use cases, like frequently reported damage scenarios, to further improve accuracy and reliability.\nThis combination gave us the precision and explainability of the agentic setup, the broad coverage of monolithic prompting and the confidence boost of targeted fine-tuning.\nWhat we learned\nA few things became clear by the time we wrapped up this project:\nAgentic frameworks are more versatile than they get credit for\n: While they are usually associated with workflow management, we found they could meaningfully boost model performance when applied in a structured, modular way.\nBlending different approaches beats relying on just one\n: The combination of precise, agent-based detection alongside the broad coverage of LLMs, plus a bit of fine-tuning where it mattered most, gave us far more reliable outcomes than any single method on its own.\nVisual models are prone to hallucinations\n: Even the more advanced setups can jump to conclusions or see things that are not there. It takes a thoughtful system design to keep those mistakes in check.\nImage quality variety makes a difference\n: Training and testing with both clear, high-resolution images and everyday, lower-quality ones helped the model stay resilient when faced with unpredictable, real-world photos.\nYou need a way to catch junk images\n: A dedicated check for junk or unrelated pictures was one of the simplest changes we made, and it had an outsized impact on overall system reliability.\nFinal thoughts\nWhat started as a simple idea, using an LLM prompt to detect physical damage in laptop images, quickly turned into a much deeper experiment in combining different AI techniques to tackle unpredictable, real-world problems. Along the way, we realized that some of the most useful tools were ones not originally designed for this type of work.\nAgentic frameworks, often seen as workflow utilities, proved surprisingly effective when repurposed for tasks like structured damage detection and image filtering. With a bit of creativity, they helped us build a system that was not just more accurate, but easier to understand and manage in practice.\nShruti Tiwari is an AI product manager at Dell Technologies.\nVadiraj Kulkarni is a data scientist at Dell Technologies.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nJust Released: 50 New Tickets for VB Transform 2025\nJoin top leaders June 24–25 in San Francisco to tackle real-world AI challenges, share what’s working, and shape what’s next. Claim your spot before they’re gone.\nLearn More\nDataDecisionMakers\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-29T15:24:41.819319",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-29T15:24:45.387711",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/afc0f17f2552ee17353573dcabc5dbb6.mp3",
    "audio_file": "audio/articles/afc0f17f2552ee17353573dcabc5dbb6.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-06-29T15:25:03.112328",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "1febd75b83fb97dac1d9bf4535020277",
    "title": "AI agents are hitting a liability wall. Mixus has a plan to overcome it using human overseers on high-risk workflows",
    "url": "https://venturebeat.com/ai/ai-agents-are-hitting-a-liability-wall-mixus-has-a-plan-to-overcome-it-using-human-overseers-on-high-risk-workflows/",
    "authors": "Ben Dickson",
    "published_date": "2025-06-28T14:27:45+00:00",
    "source": "VentureBeat",
    "summary": "最近AI代理程式在處理高風險工作時遇到責任瓶頸，Mixus提出了一個計畫，透過人類監督員來解決這個問題。企業發現將人類重新納入控制是防止AI失敗的有效策略。一些事件顯示完全自主的AI代理程式存在高風險，因此需要人類監督以確保任務的可靠性。",
    "content": "AI agents are hitting a liability wall. Mixus has a plan to overcome it using human overseers on high-risk workflows | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nAI agents are hitting a liability wall. Mixus has a plan to overcome it using human overseers on high-risk workflows\nBen Dickson\n@BenDee983\nJune 28, 2025 7:27 AM\nShare on Facebook\nShare on X\nShare on LinkedIn\nImage credit: VentureBeat with ChatGPT\nJoin the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.\nLearn more\nWhile enterprises face the challenges of deploying AI agents in critical applications, a new, more pragmatic model is emerging that puts humans back in control as a strategic safeguard against AI failure.\nOne such example is\nMixus\n, a platform that uses a “colleague-in-the-loop” approach to make AI agents reliable for mission-critical work.\nThis approach is a response to the growing evidence that fully autonomous agents are a high-stakes gamble.\nThe high cost of unchecked AI\nThe problem of\nAI hallucinations\nhas become a tangible risk as companies explore AI applications. In a recent incident, the AI-powered code editor Cursor saw its own support bot\ninvent a fake policy\nrestricting subscriptions, sparking a wave of public customer cancellations.\nSimilarly, the fintech company Klarna famously\nreversed course\non replacing customer service agents with AI after admitting the move resulted in lower quality. In a more alarming case, New York City’s AI-powered business chatbot advised entrepreneurs to\nengage in illegal practices\n, highlighting the catastrophic compliance risks of unmonitored agents.\nThese incidents are symptoms of a larger capability gap. According to a May 2025 Salesforce\nresearch paper\n, today’s leading agents succeed only 58% of the time on single-step tasks and just 35% of the time on multi-step ones, highlighting “a significant gap between current LLM capabilities and the multifaceted demands of real-world enterprise scenarios.”\nThe colleague-in-the-loop model\nTo bridge this gap, a new approach focuses on structured human oversight. “An AI agent should act at your direction and on your behalf,” Mixus co-founder Elliot Katz told VentureBeat. “But without built-in organizational oversight, fully autonomous agents often create more problems than they solve.”\nThis philosophy underpins Mixus’s colleague-in-the-loop model, which embeds human verification directly into automated workflows. For example, a large retailer might receive weekly reports from thousands of stores that contain critical operational data (e.g., sales volumes, labor hours, productivity ratios, compensation requests from headquarters). Human analysts must spend hours manually reviewing the data and making decisions based on heuristics. With Mixus, the AI agent automates the heavy lifting, analyzing complex patterns and flagging anomalies like unusually high salary requests or productivity outliers.\nFor high-stakes decisions like payment authorizations or policy violations — workflows defined by a human user as “high-risk” — the agent pauses and requires human approval before proceeding. The division of labor between AI and humans has been integrated into the agent creation process.\n“This approach means humans only get involved when their expertise actually adds value — typically the critical 5-10% of decisions that could have significant impact — while the remaining 90-95% of routine tasks flow through automatically,” Katz said. “You get the speed of full automation for standard operations, but human oversight kicks in precisely when context, judgment, and accountability matter most.”\nIn a demo that the Mixus team showed to VentureBeat, creating an agent is an intuitive process that can be done with plain-text instructions. To build a fact-checking agent for reporters, for example, co-founder Shai Magzimof simply described the multi-step process in natural language and instructed the platform to embed human verification steps with specific thresholds, such as when a claim is high-risk and can result in reputational damage or legal consequences.\nOne of the platform’s core strengths is its integrations with tools like Google Drive, email, and Slack, allowing enterprise users to bring their own data sources into workflows and interact with agents directly from their communication platform of choice, without having to switch contexts or learn a new interface (for example, the fact-checking agent was instructed to send approval requests to the editor’s email).\nThe platform’s integration capabilities extend further to meet specific enterprise needs. Mixus supports the\nModel Context Protocol\n(MCP), which enables businesses to connect agents to their bespoke tools and APIs, avoiding the need to reinvent the wheel for existing internal systems. Combined with integrations for other enterprise software like Jira and Salesforce, this allows agents to perform complex, cross-platform tasks, such as checking on open engineering tickets and reporting the status back to a manager on Slack.\nHuman oversight as a strategic multiplier\nThe enterprise AI space is currently undergoing a reality check as companies move from experimentation to production. The consensus among many industry leaders is that humans in the loop are a practical necessity for agents to perform reliably.\nAI Agents will likely follow a self driving trajectory, where you need a human in the loop for a long tail of tasks for a while. The big difference is we’ll get a growing number of autonomous agents along the way, where full self driving is an all or nothing proposition.\nhttps://t.co/5dR7cGS7jn\n— Aaron Levie (@levie)\nJune 20, 2025\nMixus’s collaborative model changes the economics of scaling AI. Mixus predicts that by 2030, agent deployment may grow 1000x and each human overseer will become 50x more efficient as AI agents become more reliable. But the total need for human oversight will still grow.\n“Each human overseer manages exponentially more AI work over time, but you still need more total oversight as AI deployment explodes across your organization,” Katz said.\nFor enterprise leaders, this means human skills will evolve rather than disappear. Instead of being replaced by AI, experts will be promoted to roles where they orchestrate fleets of AI agents and handle the high-stakes decisions flagged for their review.\nIn this framework, building a strong human oversight function becomes a competitive advantage, allowing companies to deploy AI more aggressively and safely than their rivals.\n“Companies that master this multiplication will dominate their industries, while those chasing full automation will struggle with reliability, compliance, and trust,” Katz said.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nJust Released: 50 New Tickets for VB Transform 2025\nJoin top leaders June 24–25 in San Francisco to tackle real-world AI challenges, share what’s working, and shape what’s next. Claim your spot before they’re gone.\nLearn More\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-29T15:24:42.090948",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-29T15:24:46.815754",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/1febd75b83fb97dac1d9bf4535020277.mp3",
    "audio_file": "audio/articles/1febd75b83fb97dac1d9bf4535020277.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-06-29T15:25:11.644126",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "3f40b1a3331b8d9dd9a2406a612d2ef9",
    "title": "CTGT wins Best Presentation Style award at VB Transform 2025",
    "url": "https://venturebeat.com/ai/ctgt-wins-best-presentation-style-award-at-vb-transform-2025/",
    "authors": "James Thomason",
    "published_date": "2025-06-28T00:48:46+00:00",
    "source": "VentureBeat",
    "summary": "一家名為CTGT的新創公司在VB Transform 2025中贏得了最佳演示風格獎。他們專注於通過定制模型功能來使人工智慧更加可信，而非傳統的微調或提示工程方法。CTGT的技術有助企業克服人工智慧信任障礙，這在業界引起了極大關注。他們的方法與傳統人工智慧定制技術有顯著不同，並且被認為是突破了人工智慧的計算障礙。這項創新有望改變企業對人工智慧的看法，提高其可信度。",
    "content": "CTGT wins Best Presentation Style award at VB Transform 2025 | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nCTGT wins Best Presentation Style award at VB Transform 2025\nJames Thomason\n@jathomason\nJune 27, 2025 5:48 PM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCTGT won best presentation at VB Transform's Innovation Showcase in SF on June 25, 2025. Photo: Michael O'Donnell Photography\nJoin the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.\nLearn more\nSan Francisco-based\nCTGT\n, a startup focused on making AI more trustworthy through feature-level model customization, won the Best Presentation Style award at\nVB Transform 2025\nin San Francisco. Founded by 23-year-old Cyril Gorlla, the company showcased how its technology helps enterprises overcome AI trust barriers by directly modifying model features instead of using traditional fine-tuning or prompt engineering methods.\nDuring his presentation, Gorlla highlighted the “AI Doom Loop” faced by many enterprises: 54% of businesses cite AI as their highest tech risk according to Deloitte, while McKinsey reports 44% of organizations have experienced negative consequences from AI implementation.\n“A large part of this conference has been about the AI doom loop” Gorlla explained during his presentation. “Unfortunately, a lot of these [AI investments] don’t pan out.\nJ&J just canceled\nhundreds of AI pilots because they didn’t really deliver ROI due to no fundamental trust in these systems.”\nBreaking the AI compute wall\nCTGT’s approach represents a significant departure from conventional AI customization techniques. The company was founded on research Gorlla conducted while holding an endowed chair at the University of California San Diego.\nIn 2023, Gorlla\npublished a paper\nat the International Conference on Learning Representations (ICLR) describing a method for evaluating and training AI models that was up to 500 times faster than existing approaches while achieving “three nines” (99.9%) of accuracy.\nRather than relying on brute-force scaling or traditional deep learning methods, CTGT has developed what it calls an “entirely new AI stack” that fundamentally reimagines how neural networks learn. The company’s innovation focuses on understanding and intervening at the feature level of AI models.\nThe company’s approach differs fundamentally from standard interpretability solutions that rely on secondary AI systems for monitoring. Instead, CTGT offers mathematically verifiable interpretability capabilities that eliminate the need for supplemental models, significantly lowering computational requirements in the process.\nThe technology works by identifying specific latent variables (neurons or directions in the feature space) that drive behaviors like censorship or hallucinations, then dynamically modifying these variables at inference time without altering the model’s weights. This approach allows companies to customize model behavior on the fly without taking systems offline for retraining.\nReal-world applications\nDuring his Transform presentation, Gorlla demonstrated two enterprise applications already deployed at a Fortune 20 financial institution:\nAn email compliance workflow that trains models to understand company-specific acceptable content, allowing analysts to check their emails against compliance standards in real-time. The system highlights potentially problematic content and provides specific explanations.\nA brand alignment tool that helps marketers develop copy consistent with brand values. The system can suggest personalized advice on why certain phrases work well for a specific brand and how to improve content that doesn’t align.\n“If a company has 900 use cases, they no longer have to fine-tune 900 models,” Gorlla explained. “We’re model-agnostic, so they can just plug us in.”\nA real-world example of CTGT’s technology in action was its work with\nDeepSeek models\n, where it successfully identified and modified the features responsible for censorship behaviors. By isolating and adjusting these specific activation patterns, CTGT was able to achieve a 100% response rate on sensitive queries without degrading the model’s performance on neutral tasks like reasoning, mathematics and coding.\nImages:\nCTGT presentation at VB Transform 2025\nDemonstrated ROI\nCTGT’s technology appears to be delivering measurable results. During the Q&A session, Gorlla noted that in the first week of deployment with “one of the leading AI-powered insurers, we saved $5 million of liability from them.”\nAnother early customer, Ebrada Financial, has used CTGT to improve the factual accuracy of customer service chatbots. “Previously, hallucinations and other errors in chatbot responses drove a high volume of requests for live support agents as customers sought to clarify responses,” said Ley Ebrada, Founder and Tax Strategist. “CTGT has helped improve chatbot accuracy tremendously, eliminating most of those agent requests.”\nIn another case study, CTGT worked with an unnamed Fortune 10 company to enhance on-device AI capabilities in computationally constrained environments. The company also helped a leading computer vision firm achieve 10x faster model performance while maintaining comparable accuracy.\nThe company claims its technology can reduce hallucinations by 80-90% and enable AI deployments with 99.9% reliability, a critical factor for enterprises in regulated industries like healthcare and finance.\nFrom Hyderabad to Silicon Valley\nGorlla’s journey is itself remarkable. Born in Hyderabad, India, he\nmastered coding\nat age 11 and was disassembling laptops in high school to squeeze out more performance for training AI models. He came to the United States to study at the University of California, San Diego, where he received the Endowed Chair’s Fellowship.\nHis research there focused on understanding the fundamental mechanisms of how neural networks learn, which led to his ICLR paper and eventually CTGT. In late 2024, Gorlla and co-founder Trevor Tuttle, an expert in hyperscalable ML systems, were selected for Y Combinator’s Fall 2024 batch.\nThe startup has attracted notable investors beyond its institutional backers, including Mark Cuban and other prominent technology leaders drawn to its vision of making AI more efficient and trustworthy.\nFunding and future\nFounded in mid-2024 by Gorlla and Tuttle, CTGT\nraised $7.2 million\nin February 2025 in an oversubscribed seed round led by Gradient, Google’s early-stage AI fund. Other investors include General Catalyst, Y Combinator, Liquid 2, Deepwater, and notable angels such as François Chollet (creator of Keras), Michael Seibel (Y Combinator, co-founder of Twitch), and Paul Graham (Y Combinator).\n“CTGT’s launch is timely as the industry struggles with how to scale AI within the current confines of computing limits,” said Darian Shirazi, Managing Partner at Gradient. “CTGT removes those limits, enabling companies to rapidly scale their AI deployments and run advanced AI models on devices like smartphones. This technology is critical to the success of high-stakes AI deployments at large enterprises.”\nWith AI model size outpacing Moore’s Law and advances in AI training chips, CTGT aims to focus on a more foundational understanding of AI that can cope with both inefficiency and increasingly complex model decisions. The company plans to use its seed funding to expand its engineering team and refine its platform.\nEach finalist presented to an audience of 600 industry decision-makers and received feedback from a panel of venture capital judges from Salesforce Ventures, Menlo Ventures, and Amex Ventures.\nRead about the other winners\nCatio\nand Solo.io. The other finalists were\nKumo\n,\nSuperduper.io\n,\nSutro\nand\nQdrant\n.\nEditor’s note: As a thank-you to our readers, we’ve opened up early bird registration for VB Transform 2026 — just $200. This is where AI ambition meets operational reality, and you’re going to want to be in the room.\nReserve your spot now\n.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nJust Released: 50 New Tickets for VB Transform 2025\nJoin top leaders June 24–25 in San Francisco to tackle real-world AI challenges, share what’s working, and shape what’s next. Claim your spot before they’re gone.\nLearn More\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-06-29T15:24:42.371736",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-06-29T15:24:50.878369",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/3f40b1a3331b8d9dd9a2406a612d2ef9.mp3",
    "audio_file": "audio/articles/3f40b1a3331b8d9dd9a2406a612d2ef9.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-06-29T15:25:22.704816",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  }
]