[
  {
    "id": "dd9febbfbe3bc8d4d5d2fc9910a96d0b",
    "title": "Confidence in agentic AI: Why eval infrastructure must come first",
    "url": "https://venturebeat.com/ai/confidence-in-agentic-ai-why-eval-infrastructure-must-come-first/",
    "authors": "VB Staff",
    "published_date": "2025-07-02T15:41:49+00:00",
    "source": "VentureBeat",
    "summary": "這篇新聞談的是在AI領域中，如何先建立評估基礎設施，增加對AI代理人的信心。一些公司利用AI代理人來提升網站轉換率，甚至自動化專業任務，節省大量成本和時間。這顯示AI代理人的潛力不僅在於節省人力成本，更能帶來業務轉型和效率提升。這些實際案例突顯了AI代理人在商業應用上的價值和優勢。",
    "content": "Confidence in agentic AI: Why eval infrastructure must come first | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nVB Event\nConfidence in agentic AI: Why eval infrastructure must come first\nVB Staff\nJuly 2, 2025 8:41 AM\nShare on Facebook\nShare on X\nShare on LinkedIn\nThys Waanders, Shailesh Nalawadi, Shawn Malhotra, Joanne Chen,\nAs AI agents enter real-world deployment, organizations are under pressure to define where they belong, how to build them effectively, and how to operationalize them at scale. At VentureBeat’s\nTransform 2025\n, tech leaders gathered to talk about how they’re transforming their business with agents: Joanne Chen, general partner at Foundation Capital; Shailesh Nalawadi, VP of project management with Sendbird; Thys Waanders, SVP of AI transformation at Cognigy; and Shawn Malhotra, CTO, Rocket Companies.\nA few top agentic AI use cases\n“The initial attraction of any of these deployments for AI agents tends to be around saving human capital — the math is pretty straightforward,” Nalawadi said. “However, that undersells the transformational capability you get with AI agents.”\nAt Rocket, AI agents have proven to be powerful tools in increasing website conversion.\n“We’ve found that with our agent-based experience, the conversational experience on the website, clients are three times more likely to convert when they come through that channel,” Malhotra said.\nBut that’s just scratching the surface. For instance, a Rocket engineer built an agent in just two days to automate a highly specialized task: calculating transfer taxes during mortgage underwriting.\n“That two days of effort saved us a million dollars a year in expense,” Malhotra said. “In 2024, we saved more than a million team member hours, mostly off the back of our AI solutions. That’s not just saving expense. It’s also allowing our team members to focus their time on people making what is often the largest financial transaction of their life.”\nAgents are essentially supercharging individual team members. That million hours saved isn’t the entirety of someone’s job replicated many times. It’s fractions of the job that are things employees don’t enjoy doing, or weren’t adding value to the client. And that million hours saved gives Rocket the capacity to handle more business.\n“Some of our team members were able to handle 50% more clients last year than they were the year before,” Malhotra added. “It means we can have higher throughput, drive more business, and again, we see higher conversion rates because they’re spending the time understanding the client’s needs versus doing a lot of more rote work that the AI can do now.”\nTackling agent complexity\n“Part of the journey for our engineering teams is moving from the mindset of software engineering – write once and test it and it runs and gives the same answer 1,000 times – to the more probabilistic approach, where you ask the same thing of an LLM and it gives different answers through some probability,” Nalawadi said. “A lot of it has been bringing people along. Not just software engineers, but product managers and UX designers.”\nWhat’s helped is that LLMs have come a long way, Waanders said. If they built something 18 months or two years ago, they really had to pick the right model, or the agent would not perform as expected. Now, he says, we’re now at a stage where most of the mainstream models behave very well. They’re more predictable. But today the challenge is combining models, ensuring responsiveness, orchestrating the right models in the right sequence and weaving in the right data.\n“We have customers that push tens of millions of conversations per year,” Waanders said. “If you automate, say, 30 million conversations in a year, how does that scale in the LLM world? That’s all stuff that we had to discover, simple stuff, from even getting the model availability with the cloud providers. Having enough quota with a ChatGPT model, for example. Those are all learnings that we had to go through, and our customers as well. It’s a brand-new world.”\nA layer above orchestrating the LLM is orchestrating a network of agents, Malhotra said. A conversational experience has a network of agents under the hood, and the orchestrator is deciding which agent to farm the request out to from those available.\n“If you play that forward and think about having hundreds or thousands of agents who are capable of different things, you get some really interesting technical problems,” he said. “It’s becoming a bigger problem, because latency and time matter. That agent routing is going to be a very interesting problem to solve over the coming years.”\nTapping into vendor relationships\nUp to this point, the first step for most companies launching agentic AI has been building in-house, because specialized tools didn’t yet exist. But you can’t differentiate and create value by building generic LLM infrastructure or AI infrastructure, and you need specialized expertise to go beyond the initial build, and debug, iterate, and improve on what’s been built, as well as maintain the infrastructure.\n“Often we find the most successful conversations we have with prospective customers tend to be someone who’s already built something in-house,” Nalawadi said. “They quickly realize that getting to a 1.0 is okay, but as the world evolves and as the infrastructure evolves and as they need to swap out technology for something new, they don’t have the ability to orchestrate all these things.”\nPreparing for agentic AI complexity\nTheoretically, agentic AI will only grow in complexity — the number of agents in an organization will rise, and they’ll start learning from each other, and the number of use cases will explode. How can organizations prepare for the challenge?\n“It means that the checks and balances in your system will get stressed more,” Malhotra said. “For something that has a regulatory process, you have a human in the loop to make sure that someone is signing off on this. For critical internal processes or data access, do you have observability? Do you have the right alerting and monitoring so that if something goes wrong, you know it’s going wrong? It’s doubling down on your detection, understanding where you need a human in the loop, and then trusting that those processes are going to catch if something does go wrong. But because of the power it unlocks, you have to do it.”\nSo how can you have confidence that an AI agent will behave reliably as it evolves?\n“That part is really difficult if you haven’t thought about it at the beginning,” Nalawadi said. “The short answer is, before you even start building it, you should have an eval infrastructure in place. Make sure you have a rigorous environment in which you know what good looks like, from an AI agent, and that you have this test set. Keep referring back to it as you make improvements. A very simplistic way of thinking about eval is that it’s the unit tests for your agentic system.”\nThe problem is, it’s non-deterministic, Waanders added. Unit testing is critical, but the biggest challenge is you don’t know what you don’t know — what incorrect behaviors an agent could possibly display, how it might react in any given situation.\n“You can only find that out by simulating conversations at scale, by pushing it under thousands of different scenarios, and then analyzing how it holds up and how it reacts,” Waanders said.\nThe Briefing for Tech Decision-Makers\nStay ahead in AI, data, and security with VB Daily—trusted by 100K+ industry leaders.\nSubscribe Here\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-03T16:26:14.113899",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-03T16:26:27.789798",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/dd9febbfbe3bc8d4d5d2fc9910a96d0b.mp3",
    "audio_file": "audio/articles/dd9febbfbe3bc8d4d5d2fc9910a96d0b.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-07-03T16:27:39.590809",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "62ea94355f1cdfadb0aa9329525e3663",
    "title": "Transform 2025: Why observability is critical for AI agent ecosystems",
    "url": "https://venturebeat.com/ai/transform-2025-why-observability-is-critical-for-ai-agent-ecosystems/",
    "authors": "VB Staff",
    "published_date": "2025-07-02T13:50:00+00:00",
    "source": "VentureBeat",
    "summary": "這篇新聞談到了AI代理生態系統中的觀測性對於系統的重要性。通過觀測性，可以即時捕捉應用程式、日誌和基礎設施的數據，幫助團隊理解、解決問題並優化系統。隨著AI的應用不斷擴大，觀測性變得更加複雜，需要監控各種模型的效能。這對企業來說是個挑戰，但也是機遇，因為觀測性可以幫助他們更好地應對不斷變化的AI環境，提升效率並降低風險。",
    "content": "Transform 2025: Why observability is critical for AI agent ecosystems | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nVB Event\nTransform 2025: Why observability is critical for AI agent ecosystems\nVB Staff\nJuly 2, 2025 6:50 AM\nShare on Facebook\nShare on X\nShare on LinkedIn\nAshan Willy, Sam Witteveen\nThe autonomous software revolution is coming. At\nTransform 2025\n, Ashan Willy, CEO of New Relic and Sam Witteveen, CEO and co-founder of Red Dragon AI, talked about how they’re instrumenting agentic systems for measurable ROI and charting the infrastructure roadmap to maximize agentic AI.\nNew Relic provides observability to customers by capturing and correlating application, log, and infrastructure telemetry in real time. Observability goes beyond monitoring — it’s about equipping teams with the context and insight needed to understand, troubleshoot, and optimize complex systems, even in the face of unexpected issues. Today that’s become a considerably more complex undertaking now that generative and agentic AI are in the mix. And observability for the company now includes monitoring everything from Nvidia NIM, DeepSeek, ChatGPT and so on — use of its AI monitoring is up roughly 30%, quarter over quarter, reflecting the acceleration of adoption.\n“The other thing we see is a huge diversity in models,” Willy said. “Enterprises started with GPT, but are starting to use a whole bunch of models. We’ve seen about a 92% increase in variance of models that are being used. And we’re starting to see enterprises adopt more models. The question is, how do you measure the effectiveness?”\nObservability in an agentic world\nIn other words, how is observability evolving? That’s a big question. The use cases vary wildly across industries, and the functionality is fundamentally different for each individual company, depending on size and goals. A financial firm might be focused on maximizing EBITDA margins, while a product-focused company is measuring speed to market alongside quality control.\nWhen New Relic was founded in 2008, the center of gravity for observability was application monitoring for SaaS, mobile, and then eventually cloud infrastructure. The rise of AI and agentic AI is bringing observability back to applications, as agents, micro-agents, and nano-agents are running and producing AI-written code.\nAI for observability\nAs the number of services and microservices rises, especially for digitally native organizations, the cognitive load for any human handling observability tasks becomes overwhelming. Of course, AI can help that, Willy says.\n“The way it’s going to work is you’re going to have enough information where you’ll work in cooperative mode,” he explained. “The promise of agents in observability is to take some of those automatic workloads and make them happen. That will democratize it to more people.”\nSingle platform agentic observability\nA single platform for observability takes advantage of the agentic world. Agents automate workflows, but they form deep integrations into the entire ecosystem, across all the multiple tools an organization has in play, like Harness, GitHub, ServiceNow, and so on. With agentic AI, developers can be alerted to what’s happening with code errors anywhere in the ecosystem and fix them immediately, without leaving their coding platform.\nIn other words, if there’s an issue with code deployed in GitHub, an observability platform powered by agents can detect it, determine how to solve it, and then alert the engineer — or automate the process entirely.\n“Our agent is fundamentally looking at every piece of information we have on our platform,” Willy said. “That could be anything from how the application’s performing, how the underlying Azure or AWS structure is performing — anything we think is relevant to that code deployment. We call it agentic skills. We don’t rely on a third party to know APIs and so on.”\nIn GitHub for example, they let a developer know when code is running fine, where errors are being handled, or even when a software rollback is necessary, and then automate that rollback, with developer approval. The next step, which New Relic announced last month, is working with Copilot coding agent to tell the developer exactly which lines of code it’s seeing the issue with. Copilot then goes back, corrects the issue, and then gets a version ready to deploy again.\nThe future of agentic AI\nAs organizations adopt agentic AI and start to adapt to it, they’re going to find that observability is a critical part of its functionality, Willy says.\n“As you start to build all these agentic integrations and pieces, you’re going to want to know what the agent does,” he says. “This is sort of reasoning for the infrastructure. Reasoning to find out what’s going on in your production. That’s what observability will bring, and we’re on the forefront of that.”\nThe Briefing for Tech Decision-Makers\nStay ahead in AI, data, and security with VB Daily—trusted by 100K+ industry leaders.\nSubscribe Here\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-03T16:26:14.407811",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-03T16:26:31.507892",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/62ea94355f1cdfadb0aa9329525e3663.mp3",
    "audio_file": "audio/articles/62ea94355f1cdfadb0aa9329525e3663.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-07-03T16:27:50.128009",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  },
  {
    "id": "c04c6a5a2c09cd51500c0371bcab4661",
    "title": "Bright Data beat Elon Musk and Meta in court — now its $100M AI platform is taking on Big Tech",
    "url": "https://venturebeat.com/ai/bright-data-beat-elon-musk-and-meta-in-court-now-its-100m-ai-platform-is-taking-on-big-tech/",
    "authors": "Michael Nuñez",
    "published_date": "2025-07-02T13:00:00+00:00",
    "source": "VentureBeat",
    "summary": "以色列網路爬蟲公司Bright Data在法庭上擊敗了Elon Musk和Meta，現在他們推出了價值1億美元的AI平台，挑戰大科技公司。這個平台讓人工智慧系統可以即時獲取網路數據，讓AI公司更容易取得所需資訊。Bright Data CEO表示，他們致力於爭取對公開網路數據的開放存取，這次推出的新產品將帶來更多機會和發展。這次推出是在他們在2024年在法庭上勝訴後的重要一步。",
    "content": "Bright Data beat Elon Musk and Meta in court — now its $100M AI platform is taking on Big Tech | VentureBeat\nSkip to main content\nEvents\nVideo\nSpecial Issues\nJobs\nVentureBeat Homepage\nSubscribe\nArtificial Intelligence\nView All\nAI, ML and Deep Learning\nAuto ML\nData Labelling\nSynthetic Data\nConversational AI\nNLP\nText-to-Speech\nSecurity\nView All\nData Security and Privacy\nNetwork Security and Privacy\nSoftware Security\nComputer Hardware Security\nCloud and Data Storage Security\nData Infrastructure\nView All\nData Science\nData Management\nData Storage and Cloud\nBig Data and Analytics\nData Networks\nAutomation\nView All\nIndustrial Automation\nBusiness Process Automation\nDevelopment Automation\nRobotic Process Automation\nTest Automation\nEnterprise Analytics\nView All\nBusiness Intelligence\nDisaster Recovery Business Continuity\nStatistical Analysis\nPredictive Analysis\nMore\nData Decision Makers\nVirtual Communication\nTeam Collaboration\nUCaaS\nVirtual Reality Collaboration\nVirtual Employee Experience\nProgramming & Development\nProduct Development\nApplication Development\nTest Management\nDevelopment Languages\nSubscribe\nEvents\nVideo\nSpecial Issues\nJobs\nBright Data beat Elon Musk and Meta in court — now its $100M AI platform is taking on Big Tech\nMichael Nuñez\n@MichaelFNunez\nJuly 2, 2025 6:00 AM\nShare on Facebook\nShare on X\nShare on LinkedIn\nCredit: VentureBeat made with Midjourney\nWant smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.\nSubscribe Now\nBright Data\n, the Israeli web scraping company that\ndefeated both Meta and Elon Musk’s X\nin federal court, unveiled a comprehensive AI infrastructure suite Wednesday designed to give artificial intelligence systems unfettered access to real-time web data — a capability the company argues Big Tech platforms are trying to monopolize.\nThe announcement of\nDeep Lookup\n,\nBrowser.ai\n, and enhanced data collection protocols represents a dramatic expansion for the decade-old company, which has transformed from a specialized web scraping service into what CEO Or Lenchner calls “a unique infrastructure layer for AI companies.” The move comes as artificial intelligence companies increasingly struggle to access current web information needed to power chatbots, autonomous agents, and other AI applications.\n“The intelligence of today’s LLMs is no longer its limiting factor; access is,” Lenchner said in an exclusive interview with VentureBeat. “We’ve spent the last decade fighting for open access to public web data, and these new offerings bring us to the next chapter in our journey, one characterized by truly accessible data and the subsequent rise of contextually-aware agents.”\nThe launch follows Bright Data’s\nhigh-profile legal victories\nin 2024, when federal judges dismissed lawsuits from both\nMeta\nand\nX\nalleging the company illegally scraped their platforms. Those rulings established crucial legal precedent defining what constitutes “\npublic data\n” on the internet — information that can be viewed without logging in and therefore can be legally collected and used.\nCourt wins against Meta and X establish legal precedent for web scraping rights\nThe court cases revealed that both\nMeta\nand\nX\nhad been\nBright Data\ncustomers even while suing the company, highlighting the contradictory stance many tech giants have taken toward web scraping. The rulings have broader implications for the AI industry, which relies heavily on web data to train and operate language models.\n“It was revealed in court that both of them were a Bright Data customer, because everyone needs data, everyone, especially those who are building models,” Lenchner explained. “We are the only company that has the financial resources, and I would even say the courage to do that.”\nJudge William Alsup\n, who presided over the X case, wrote that giving social media companies “free rein to decide, on any basis, who can collect and use data” risks creating “information monopolies that would disserve the public interest.” The ruling established that data viewable without login credentials constitutes public information that can be legally scraped.\nBright Data had previously filed a\ncountersuit against X\n, alleging the platform violated antitrust laws by trying to create a data monopoly to benefit Musk’s AI company, xAI. However, that case has since been settled. “Though the terms confidential, Bright Data has never backed down from its fundamental belief that public data should be available to the public. Consistent with that belief, we are pleased to report that Bright Data will continue to provide the same industry-leading services that it always has and that our customers have come to expect,” Lenchner said.\nDeep Lookup and Browser.ai target AI companies struggling with data access\nThe company’s new products address what Lenchner identifies as the three core requirements for AI systems: algorithms, compute power, and data access. While\nBright Data\ndoesn’t develop AI algorithms or provide computing resources, it aims to become the definitive solution for the third requirement.\nDeep Lookup\nfunctions as a natural language research engine designed to answer complex, multi-layered business questions in real-time. Unlike general-purpose search engines or AI chatbots that provide summaries, Deep Lookup specializes in comprehensive results for queries beginning with “find all.” For example, users can ask for “all shipping companies that went through the Panama and Suez canals in 2023 whose Q3 revenues declined by over 2 percent.”\nThe system draws from Bright Data’s massive web archive, which currently contains over 200 billion HTML pages and adds 15 billion monthly. By next year, the archive is expected to exceed 500 billion pages. “It’s not just random web pages, it’s actually what the world cares about, because our 20,000 customers represent billions of internet users,” Lenchner noted.\nBrowser.ai\nrepresents what the company calls “the industry’s first unblockable, AI-native browser.” Designed specifically for autonomous AI agents, the cloud-based service mimics human behavior to access websites without triggering bot detection systems. It supports natural language commands and can perform complex web interactions like booking flights or making restaurant reservations.\nThe browser infrastructure already processes over 150 million web actions daily, according to the company. “Almost all of them are customers,” Lenchner said of AI agent companies that have raised significant funding. “Because what we figured out, and they figured out, is that we solve that problem of entering a website without being blocked and executing web actions on the website.”\nMCP Servers\n(Model Context Protocol) provides a low-latency control layer enabling AI agents to search, crawl, and extract live data in real-time. The protocol allows developers to build AI systems that can act on current information rather than relying solely on training data.\nPatent portfolio and proxy network create competitive moat against blocking\nBright Data’s competitive advantage stems from what Lenchner describes as an “obsession” with overcoming website blocking mechanisms. The company holds over 5,500 patent claims on its technology and operates the world’s largest proxy network with more than 150 million IP addresses across 195 countries.\n“We have such a good look into the internet,” Lenchner explained. “For a long time now, we have been mapping the internet, and for a long time now, we’re also archiving big chunks of the internet.”\nThe company’s approach involves sophisticated techniques to mimic human behavior, using real devices, IP addresses, and browser fingerprints rather than simple automated scripts. This makes detection and blocking extremely difficult for websites.\n“The only way to block us, practically, is to put the data behind the login, then we won’t even try,” Lenchner said. “Sometimes there is a new blocking logic that we won’t solve immediately. It will take our research team 12 hours, three days that’s like the most it was, and we will unlock it.”\nRevenue surpasses $100 million as AI demand explodes post-ChatGPT\nWhile\nBright Data\nremains privately held by a private equity firm, Lenchner confirmed with VentureBeat the company’s annual recurring revenue surpassed $100 million several years ago. The business has experienced explosive growth since the launch of ChatGPT in late 2022, as AI companies scrambled to access training data and real-time information.\n“Starting March 2023, which is pretty much when GPT-3 changed the world, the AI, or what we call the data for AI, use case just absolutely exploded for us as a company,” Lenchner said. “Everything else is also growing, because everyone needs more data, period. But this use case is just like nothing we’ve seen before.”\nThe company serves over 20,000 businesses, including Fortune 500 companies and major AI laboratories. Traditional customers include e-commerce platforms tracking competitor pricing, financial services firms seeking market intelligence, and enterprises conducting business research.\nGDPR compliance and ethical practices differentiate from competitors\nBright Data\nhas invested heavily in compliance infrastructure to address privacy concerns around data collection. The company follows\nEuropean GDPR\nand\nCalifornia CCPA\nregulations, automatically notifying individuals when their personal information is collected from public sources and providing deletion options.\n“The regulation and the legislation are clear since the European GDPR and at least California and CCPA regulations came to play,” Lenchner explained. “If we collected your email address, for example, we will automatically send you an email saying, ‘Hey, this is who we are. We collected your personal information from the public domain. Here’s a huge button you can click if you want to review it, and you can obviously ask to delete it.'”\nThe company maintains a large compliance team and extensive documentation of its practices, which proved valuable during court proceedings. “Enterprises especially love us because we have our ethical stand that was scrutinized in US courts twice,” Lenchner said.\nWeb access wars intensify as tech giants seek data monopolies\nThe battle over web data access reflects broader tensions in the AI industry about information control and competitive advantage. As AI systems become more sophisticated, access to current, comprehensive web data becomes increasingly valuable — and contentious.\nLenchner predicts the web will become “more closed” over time, similar to how Google maintains exclusive access to its web crawling capabilities while others must use alternative services. “A few tech giants are gonna get free access to every website with their agents,” he said. “The rest will need to use our infrastructure or someone else’s infrastructure.”\nThe company is also observing new trends, including businesses scraping AI chatbots for marketing purposes and the emergence of new protocols like MCP that enable AI agents to interact with web services more effectively.\n“All of these guys that are consuming massive amounts of data, and all of us are using them, it’s all going towards building the brains of the robots,” Lenchner said. “It’s okay that you have a chatbot that is talking to a human, because that’s eventually what a robot will do.”\nRobot brains and agent economy drive next phase of growth\nBright Data’s transformation from web scraping service to AI infrastructure provider reflects the rapidly evolving needs of the artificial intelligence industry. As companies rush to deploy AI agents and autonomous systems, access to real-time web data becomes as crucial as computing power and algorithmic sophistication.\nThe legal precedents established through Bright Data’s court victories may prove as significant as its technical innovations, potentially shaping how the entire AI industry accesses and uses web information. With major tech platforms increasingly restricting data access while simultaneously developing their own AI systems, independent infrastructure providers like Bright Data may become essential for maintaining competitive balance in the AI ecosystem.\n“We’re an infrastructure company,” Lenchner emphasized. “We’re very talented engineers that hardly go anywhere, just sit with our computers and write code. We’re doing it well. We have no intentions to do anything else.”\nThe\nDeep Lookup\nbeta launches Tuesday for business customers, with general public access available through a waitlist.\nBrowser.ai\nand\nMCP Servers\nare already available to enterprise clients through Bright Data’s existing platform.\nDaily insights on business use cases with VB Daily\nIf you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.\nSubscribe Now\nRead our\nPrivacy Policy\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.\nThe Briefing for Tech Decision-Makers\nStay ahead in AI, data, and security with VB Daily—trusted by 100K+ industry leaders.\nSubscribe Here\nVentureBeat Homepage\nFollow us on Facebook\nFollow us on X\nFollow us on LinkedIn\nFollow us on RSS\nPress Releases\nContact Us\nAdvertise\nShare a News Tip\nContribute to DataDecisionMakers\nPrivacy Policy\nTerms of Service\nDo Not Sell My Personal Information\n© 2025\nVentureBeat\n. All rights reserved.\n×\nThe AI insights you need to lead\nSubmit\nThanks for subscribing. Check out more\nVB newsletters here\n.\nAn error occured.",
    "content_type": "news",
    "processed": true,
    "fetch_date": "2025-07-03T16:26:14.690522",
    "summary_model": "gpt-3.5-turbo",
    "processed_date": "2025-07-03T16:26:34.319025",
    "audio_path": "https://lqozyncypoyfxhyannqb.supabase.co/storage/v1/object/public/ai-news-storage/audio/articles/c04c6a5a2c09cd51500c0371bcab4661.mp3",
    "audio_file": "audio/articles/c04c6a5a2c09cd51500c0371bcab4661.mp3",
    "audio_generated": true,
    "audio_generated_date": "2025-07-03T16:27:58.595520",
    "audio_error": "[Errno 66] Directory not empty: '/Users/yuntao/Documents/AI_Developer/daily-ai-news-summarizer/temp_audio'"
  }
]